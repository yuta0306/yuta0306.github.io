<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>【論文まとめ】Prediction of Shared Laughter for Human-Robot Dialogue<!-- --> | <!-- -->ゆうぼうの書跡棚</title><meta name="description" content="Prediction of Shared Laughter for Human-Robot Dialogueのまとめ"/><meta name="og:description" content="Prediction of Shared Laughter for Human-Robot Dialogueのまとめ"/><meta property="og:type" content="website"/><meta property="og:title" content="【論文まとめ】Prediction of Shared Laughter for Human-Robot Dialogue"/><meta property="og:image" content="https://yuta0306.github.io/images/thumbnails/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue.png"/><meta property="og:url" content="https://yuta0306.github.io/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue"/><script src="/js/toc.js"></script><meta name="next-head-count" content="10"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/75506965150cde8a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/75506965150cde8a.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a6e19106a865540a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a6e19106a865540a.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/%5Bslug%5D-b275297c06761584.js" defer=""></script><script src="/_next/static/E8FLmEv3Sqrq87IaqjCxm/_buildManifest.js" defer=""></script><script src="/_next/static/E8FLmEv3Sqrq87IaqjCxm/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="Home_container__bCOhY"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><div class="header_header__title__uoTF0">ゆうぼうの書跡棚</div></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__V_9fG"><div itemscope="" itemType="http://schema.org/BlogPosting"><div style="background:url(/images/thumbnails/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue.png);overflow:hidden"><div class="Home_thumbnail__xs1Hd" itemscope="" itemProp="image" itemType="https://schema.org/ImageObject"><img src="/images/thumbnails/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue.png" alt="【論文まとめ】Prediction of Shared Laughter for Human-Robot Dialogue" loading="lazy" style="height:100%;width:auto;margin:0 auto;display:block"/></div></div><time dateTime="2023-05-21" style="color:rgb(144, 144, 144)">2023-05-21</time><h1>【論文まとめ】Prediction of Shared Laughter for Human-Robot Dialogue</h1><div id="TOC__mobile"></div><article style="margin-top:4rem" itemscope="" itemProp="text"><p>本記事において使用される図表は，原著論文内の図表を引用しています．</p>
<p>また，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．</p>
<h2>論文情報</h2>
<p>タイトル: Prediction of Shared Laughter for Human-Robot Dialogue</p>
<p>研究会: ICMI</p>
<p>年度: 2020</p>
<p>キーワード: laughter, shared laughter</p>
<p>URL: <a href="http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/LAL-ICMI20.pdf">http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/LAL-ICMI20.pdf</a></p>
<p>DOI: <a href="https://doi.org/10.1145/3395035.3425265">https://doi.org/10.1145/3395035.3425265</a></p>
<p>データセット:</p>
<h2>提案手法</h2>
<p>会話ロボットがshared laughterを自動生成することを目的にする</p>
<h3>Shared Laughter Model</h3>
<p><img src="/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/ktkpx7fr.png" alt=""></p>
<p>ユーザの最初の笑いを検知して，システムが笑うモデル</p>
<p>3種類のモジュールが存在する</p>
<ol>
<li>ユーザの最初の笑いを検出</li>
<li>shared laughterを生成するかどうかを決定</li>
<li>どのタイプの笑いをするべきか決定</li>
</ol>
<h3>Data Collection and Analysis</h3>
<p>収集方法：ERICA</p>
<p>teleoperateしたのは女性</p>
<p>対象：61人の男性</p>
<p>シナリオ：speed dating</p>
<p>好きな趣味，好きなこと，嫌いなことに関してカジュアルなチャット</p>
<p>アノテーション：</p>
<p>2種類のタイプに笑いを分けた</p>
<ol>
<li>isolated laugh
1. 笑い単体で起こる笑い</li>
<li>speech laugh
1. 話しながら起こる笑い
<img src="/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/ztqx5kie.png" alt=""></li>
</ol>
<p><img src="/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/pncunm6h.png" alt=""></p>
<p>集まったデータの中で，1206件のinitial laughが確認</p>
<p>698件がself laughで508件がshared laugh</p>
<h3>Model Creation</h3>
<p>特徴量2種類：</p>
<p><strong>Audio-based features</strong></p>
<p>40のacoustic メルフィルタバンクの平均と標準偏差</p>
<p><strong>Prosodic features</strong></p>
<p>全IPUにまたがるピッチとパワーの値を使った合計で14つの以下の指標</p>
<p>平均／中央値／標準偏差／最大値／最小値／範囲</p>
<p><strong>モデル</strong>：</p>
<p>LR／SVM</p>
<p>データサンプルが小さかったからか，deep learningの手法は弱かった</p>
<h2>新規性</h2>
<p>ユーザに合わせて毎回笑いを生成するのではなく，適切なタイミングでshared laughterを自動生成することをロボットに持たせたいという目的をもった研究</p>
<h2>評価方法</h2>
<p><img src="/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/1mjd5yfi.png" alt=""></p>
<p>オフラインとオンラインの二つのタイプで評価</p>
<p><img src="/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/my7ehxxr.png" alt=""></p>
<p><img src="/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/5m9f1ed7.png" alt=""></p>
<p>特徴量としてlaughter typeを加えることでrecallが改善する傾向</p>
<p>負に歪んだピッチの分布の時は笑いがシェアされがちで笑いが長く続きがち</p>
<p>laughter detectionとlaugh type classificationのエラーによってパフォーマンスが落ちることは明らかだが，それでもベースラインをoutperform</p>
<p>最もよかったonline modelはacousticとprosodicの特徴量を両方使ったもの</p>
<h2>何がすごかった？</h2>
<p>prosodicの分析からわかったことが，initial laughのacousiticsはresponse laughを呼び起こすいくつかの特徴があること</p>
<p>まだ改善の余地はあるものの，acousticとprosodicの特徴量の両方を使うことはパフォーマンスの改善に役立った</p>
<p>shared laughterのタイミングについてはかけた研究である</p>
<p>今後の課題である</p>
<h2>次に読みたい論文</h2>
<h2>引用</h2>
<blockquote>
<p><em>@inproceedings{10.1145/3395035.3425265,
author = {Lala, Divesh and Inoue, Koji and Kawahara, Tatsuya},
title = {Prediction of Shared Laughter for Human-Robot Dialogue},
year = {2020},
isbn = {9781450380027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {<a href="https://doi.org/10.1145/3395035.3425265%7D">https://doi.org/10.1145/3395035.3425265}</a>,
doi = {10.1145/3395035.3425265},
abstract = {Shared laughter is a phenomenon in face-to-face human dialogue which increases engagement and rapport, and so should be considered for conversation robots and agents. Our aim is to create a model of shared laughter generation for conversational robots. As part of this system, we train models which predict if shared laughter will occur, given that the user has laughed. Models trained using combinations of acoustic, prosodic features and laughter type were compared with online versions considered to better quantify their performance in a real system. We find that these models perform better than the random chance, with the multimodal combination of acoustic and prosodic features performing the best.},
booktitle = {Companion Publication of the 2020 International Conference on Multimodal Interaction},
pages = {62–66},
numpages = {5},
keywords = {shared laughter, machine learning, human-robot dialogue, conversation},
location = {Virtual Event, Netherlands},
series = {ICMI '20 Companion}
}</em></p>
</blockquote></article><div class="socialshare_container__SSXJE"><h3>タメになったらSHARE!!!</h3><div class="socialshare_container__links__JZs4j"><a target="_blank" href="https://twitter.com/share?url=https://yuta0306.github.io/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue"><img src="/icons/twitter.png" loading="lazy" alt="https://yuta0306.github.io/Prediction-of-Shared-Laughter-for-Human-Robot-DialogueをTwitterに共有する"/></a><a target="_blank" href="https://www.facebook.com/share.php?u=https://yuta0306.github.io/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue"><img src="/icons/facebook.png" loading="lazy" alt="https://yuta0306.github.io/Prediction-of-Shared-Laughter-for-Human-Robot-DialogueをFacebookに共有する"/></a><a target="_blank" href="http://b.hatena.ne.jp/entry/https:/yuta0306.github.io/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue"><img src="/icons/hatenablog.png" loading="lazy" alt="https://yuta0306.github.io/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogueをはてなブログに共有する"/></a></div></div></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET/1">COMET</a><a class="tags_container__link__1Ts3a" href="/tag/commonsense/1">commonsense</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/Contrasive%20Learning/1">Contrasive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/Contrastive%20Learning/1">Contrastive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/Dialogue%20Structure%20Learning/1">Dialogue Structure Learning</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/DST/1">DST</a><a class="tags_container__link__1Ts3a" href="/tag/empathetic%20dialogue%20system/1">empathetic dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/encyclopedic/1">encyclopedic</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Gating%20Mechanism/1">Gating Mechanism</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/Highway%20Transformer/1">Highway Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection/1">humor detection</a><a class="tags_container__link__1Ts3a" href="/tag/Internet-Augmented/1">Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/KC-Net/1">KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/knowledge-base/1">knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/Knowledge-Intensive%20NLP/1">Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/laughter/1">laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20health/1">mental health</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20state%20knowledge/1">mental state knowledge</a><a class="tags_container__link__1Ts3a" href="/tag/mentalisation/1">mentalisation</a><a class="tags_container__link__1Ts3a" href="/tag/MentalRoBERTa/1">MentalRoBERTa</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/MT/1">MT</a><a class="tags_container__link__1Ts3a" href="/tag/Multi-Hop%20Transformer/1">Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/multi-modal/1">multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLG/1">NLG</a><a class="tags_container__link__1Ts3a" href="/tag/NLI/1">NLI</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/persona/1">persona</a><a class="tags_container__link__1Ts3a" href="/tag/PLMKE/1">PLMKE</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Prompt-Tuning/1">Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/Self-Dependency-Units%20(SDU)/1">Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/shared%20laughter/1">shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey/1">survey</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/transformer/1">transformer</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%81%9E%E3%81%8D%E6%89%8B%E5%8F%8D%E5%BF%9C/1">聞き手反応</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"contentHtml":"\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: Prediction of Shared Laughter for Human-Robot Dialogue\u003c/p\u003e\n\u003cp\u003e研究会: ICMI\u003c/p\u003e\n\u003cp\u003e年度: 2020\u003c/p\u003e\n\u003cp\u003eキーワード: laughter, shared laughter\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/LAL-ICMI20.pdf\"\u003ehttp://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/LAL-ICMI20.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDOI: \u003ca href=\"https://doi.org/10.1145/3395035.3425265\"\u003ehttps://doi.org/10.1145/3395035.3425265\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e会話ロボットがshared laughterを自動生成することを目的にする\u003c/p\u003e\n\u003ch3\u003eShared Laughter Model\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/ktkpx7fr.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eユーザの最初の笑いを検知して，システムが笑うモデル\u003c/p\u003e\n\u003cp\u003e3種類のモジュールが存在する\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eユーザの最初の笑いを検出\u003c/li\u003e\n\u003cli\u003eshared laughterを生成するかどうかを決定\u003c/li\u003e\n\u003cli\u003eどのタイプの笑いをするべきか決定\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eData Collection and Analysis\u003c/h3\u003e\n\u003cp\u003e収集方法：ERICA\u003c/p\u003e\n\u003cp\u003eteleoperateしたのは女性\u003c/p\u003e\n\u003cp\u003e対象：61人の男性\u003c/p\u003e\n\u003cp\u003eシナリオ：speed dating\u003c/p\u003e\n\u003cp\u003e好きな趣味，好きなこと，嫌いなことに関してカジュアルなチャット\u003c/p\u003e\n\u003cp\u003eアノテーション：\u003c/p\u003e\n\u003cp\u003e2種類のタイプに笑いを分けた\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eisolated laugh\n1. 笑い単体で起こる笑い\u003c/li\u003e\n\u003cli\u003espeech laugh\n1. 話しながら起こる笑い\n\u003cimg src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/ztqx5kie.png\" alt=\"\"\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/pncunm6h.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e集まったデータの中で，1206件のinitial laughが確認\u003c/p\u003e\n\u003cp\u003e698件がself laughで508件がshared laugh\u003c/p\u003e\n\u003ch3\u003eModel Creation\u003c/h3\u003e\n\u003cp\u003e特徴量2種類：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAudio-based features\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e40のacoustic メルフィルタバンクの平均と標準偏差\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eProsodic features\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e全IPUにまたがるピッチとパワーの値を使った合計で14つの以下の指標\u003c/p\u003e\n\u003cp\u003e平均／中央値／標準偏差／最大値／最小値／範囲\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eモデル\u003c/strong\u003e：\u003c/p\u003e\n\u003cp\u003eLR／SVM\u003c/p\u003e\n\u003cp\u003eデータサンプルが小さかったからか，deep learningの手法は弱かった\u003c/p\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cp\u003eユーザに合わせて毎回笑いを生成するのではなく，適切なタイミングでshared laughterを自動生成することをロボットに持たせたいという目的をもった研究\u003c/p\u003e\n\u003ch2\u003e評価方法\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/1mjd5yfi.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eオフラインとオンラインの二つのタイプで評価\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/my7ehxxr.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/5m9f1ed7.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e特徴量としてlaughter typeを加えることでrecallが改善する傾向\u003c/p\u003e\n\u003cp\u003e負に歪んだピッチの分布の時は笑いがシェアされがちで笑いが長く続きがち\u003c/p\u003e\n\u003cp\u003elaughter detectionとlaugh type classificationのエラーによってパフォーマンスが落ちることは明らかだが，それでもベースラインをoutperform\u003c/p\u003e\n\u003cp\u003e最もよかったonline modelはacousticとprosodicの特徴量を両方使ったもの\u003c/p\u003e\n\u003ch2\u003e何がすごかった？\u003c/h2\u003e\n\u003cp\u003eprosodicの分析からわかったことが，initial laughのacousiticsはresponse laughを呼び起こすいくつかの特徴があること\u003c/p\u003e\n\u003cp\u003eまだ改善の余地はあるものの，acousticとprosodicの特徴量の両方を使うことはパフォーマンスの改善に役立った\u003c/p\u003e\n\u003cp\u003eshared laughterのタイミングについてはかけた研究である\u003c/p\u003e\n\u003cp\u003e今後の課題である\u003c/p\u003e\n\u003ch2\u003e次に読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003e@inproceedings{10.1145/3395035.3425265,\nauthor = {Lala, Divesh and Inoue, Koji and Kawahara, Tatsuya},\ntitle = {Prediction of Shared Laughter for Human-Robot Dialogue},\nyear = {2020},\nisbn = {9781450380027},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {\u003ca href=\"https://doi.org/10.1145/3395035.3425265%7D\"\u003ehttps://doi.org/10.1145/3395035.3425265}\u003c/a\u003e,\ndoi = {10.1145/3395035.3425265},\nabstract = {Shared laughter is a phenomenon in face-to-face human dialogue which increases engagement and rapport, and so should be considered for conversation robots and agents. Our aim is to create a model of shared laughter generation for conversational robots. As part of this system, we train models which predict if shared laughter will occur, given that the user has laughed. Models trained using combinations of acoustic, prosodic features and laughter type were compared with online versions considered to better quantify their performance in a real system. We find that these models perform better than the random chance, with the multimodal combination of acoustic and prosodic features performing the best.},\nbooktitle = {Companion Publication of the 2020 International Conference on Multimodal Interaction},\npages = {62–66},\nnumpages = {5},\nkeywords = {shared laughter, machine learning, human-robot dialogue, conversation},\nlocation = {Virtual Event, Netherlands},\nseries = {ICMI '20 Companion}\n}\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e","Title":"【論文まとめ】Prediction of Shared Laughter for Human-Robot Dialogue","Date":"2023-05-21","Category":"論文","Tags":["laughter","shared laughter"],"Authos":"ゆうぼう","Slug":"Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue","Thumbnail":"/images/thumbnails/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue.png","Description":"Prediction of Shared Laughter for Human-Robot Dialogueのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","Contrastive Learning","CSS","Dialogue Structure Learning","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLG","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","聞き手反応","超解像"]},"__N_SSG":true},"page":"/[slug]","query":{"slug":"Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue"},"buildId":"E8FLmEv3Sqrq87IaqjCxm","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>