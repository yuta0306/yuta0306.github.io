<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models<!-- --> | <!-- -->ゆうぼうの書跡棚</title><meta name="description" content="A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ"/><meta name="og:description" content="A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ"/><meta property="og:title" content="【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models"/><meta property="og:image" content="https://yuta0306.github.iohttps://s3.us-west-2.amazonaws.com/secure.notion-static.com/72a3a885-7a2d-4363-ba6b-3371efd274e7/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.49.18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20230521T181845Z&amp;X-Amz-Expires=3600&amp;X-Amz-Signature=4f2395f9c9ae855d53990b80015353bf52b3381b31b93d31fe5fd92cdd60b7a5&amp;X-Amz-SignedHeaders=host&amp;x-id=GetObject"/><meta property="og:url" content="https://yuta0306.github.io/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models"/><script src="/js/toc.js"></script><meta name="next-head-count" content="9"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta property="og:title" content="ゆうぼうの書跡棚"/><meta property="og:type" content="website"/><meta property="og:url" content="https://yuta0306.github.io"/><meta property="og:image" content="https://yuta0306.github.io/images/default.png"/><meta property="og:site_name" content="ゆうぼうの書跡棚"/><meta property="og:description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/b31a7883dd1db9d4.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b31a7883dd1db9d4.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a6e19106a865540a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a6e19106a865540a.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/%5Bslug%5D-cf387ad3e4ca362b.js" defer=""></script><script src="/_next/static/jHxrKA87gf2fNs0dDanBG/_buildManifest.js" defer=""></script><script src="/_next/static/jHxrKA87gf2fNs0dDanBG/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="Home_container__bCOhY"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><div class="header_header__title__uoTF0">ゆうぼうの書跡棚</div></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__V_9fG"><div itemscope="" itemType="http://schema.org/BlogPosting"><div style="background:url(https://s3.us-west-2.amazonaws.com/secure.notion-static.com/72a3a885-7a2d-4363-ba6b-3371efd274e7/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.49.18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20230521T181845Z&amp;X-Amz-Expires=3600&amp;X-Amz-Signature=4f2395f9c9ae855d53990b80015353bf52b3381b31b93d31fe5fd92cdd60b7a5&amp;X-Amz-SignedHeaders=host&amp;x-id=GetObject);overflow:hidden"><div class="Home_thumbnail__xs1Hd" itemscope="" itemProp="image" itemType="https://schema.org/ImageObject"><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/72a3a885-7a2d-4363-ba6b-3371efd274e7/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.49.18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20230521T181845Z&amp;X-Amz-Expires=3600&amp;X-Amz-Signature=4f2395f9c9ae855d53990b80015353bf52b3381b31b93d31fe5fd92cdd60b7a5&amp;X-Amz-SignedHeaders=host&amp;x-id=GetObject" alt="【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models" loading="lazy" style="height:100%;width:auto;margin:0 auto;display:block"/></div></div><time dateTime="2023-05-21" style="color:rgb(144, 144, 144)">2023-05-21</time><h1>【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models</h1><div id="TOC__mobile"></div><article style="margin-top:4rem" itemscope="" itemProp="text"><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css">
</head>
<body>
<p>まとめること</p>
<ol>
<li>Knowledge-Intensive NLPの概要</li>
<li>Knowledge Sources</li>
<li>Encyclopedic Knowledge</li>
<li>Commonsense Knowledge</li>
<li>最近のKnowledge Sourcesの特徴</li>
<li>Knowledge-Intensive NLP Task</li>
<li>Knowledge-Intensive NLP Taskの概要</li>
<li>Knowledge-Intensive NLP Taskの特徴</li>
<li>Knowledge Fusion Methodsについて</li>
<li>Pre-Fusion Methods</li>
<li>Post-Fusion Methods</li>
<li>Hybrid-Fusion Methods</li>
<li>代表的なモデルの紹介</li>
<li>Challengingなことと今後の方向性</li>
<li>Unified PLMKEs Across Tasks and Domains</li>
<li>Reliability of Knowledge Sources</li>
<li>Reasoning Module Design</li>
</ol>
<h2>概要</h2>
<p>事前学習済みモデルにより，モデルのcapacityは増加傾向にあるが，encyclopedicやcommonsenseを用いた，knowledgeableなNLPモデルの需要の高まりが生じている</p>
<p>**PLMKEs (Pre-trained Language Model-based Knowledge-Enhanced models)**についてまとめたsurvey論文</p>
<p>linguistic or factual knowledgeは暗示的にモデルのパラメータに保存される</p>
<p>→事前学習済みのNLPモデルがより汎用的な能力を持つことを一部ではあるが説明できる</p>
<p>今のpre-trained LMは，明示的なencyclopedicやcommonsenseのレバレッジ能力に欠けている</p>
<p>PLMKEsは，関連する外部知識を取り出すモジュールと知識を混ぜるモジュールがある</p>
<p>PLMKEsに関連した重要な3つの要素がある</p>
<ol>
<li>Knowledge Sources</li>
<li>Knowledge-Intensive NLP Tasks</li>
<li>Knowledge Fusion Methods</li>
</ol>
<h2>Knowledge Sources</h2>
<h3>Encyclopedic knowledge</h3>
<p>エンティティに関する属性とエンティティ間の関係性をもった知識</p>
<p>Entity: person → Attributes: age → Relations: educated at</p>
<p>Wikipediaは大量のencyclopedicな知識を持っている</p>
<p>人物の経歴やイベントの背景などを含んでいる</p>
<p>一般的にはtripletsで構成されていることが多い</p>
<p>e.g. &#x3C;Tom Hanks, occupation, actor></p>
<p>Wikidataのような知識データがPLMKEsに広く使用されている</p>
<h3>Commonsense Knowledge</h3>
<p>日常生活のなかでの状況に関する知識</p>
<p>イベントとその影響を記す</p>
<p>e.g. mop up the floor if we split food over it / study hard to win scholarship / goat has four legs</p>
<p>commonsenseの特徴</p>
<p>多くの人の間で共有されている知識であり，コミュニケーションの中で暗示的に想定されている知識である</p>
<p>commonsenseもtripletsで表現される</p>
<p>最近のPLMKEsでは，ConceptNetとATOMICが外部知識として使用されることが多い</p>
<h3>Knowledge Sourcesの特徴</h3>
<p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/30b21e96-66e9-4c93-b612-2a5ec35b43c9/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_16.42.16.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181930Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a08e0cc46127ef5b006be5eca7349c3b4f203325cb4dd1c39cb9757131c24c8e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject" alt=""></p>
<p>large-scaleでdiverse</p>
<p>現在のソースはより正確で安定的に作られている</p>
<p>アノテーションのプロセスは部分的に自動化されていて，非エキスパートにもaccessibleになっている</p>
<p>知識データがカバーするドメインは多様</p>
<p>オープンドメインのものもあれば，specificなドメインのものも</p>
<p>Wikipedia, DBPedia, Freebaseなどはオープンドメイン</p>
<p>UMLSやAMinerなどはbiomedicineやscienceの特定ドメイン</p>
<p>domain-specificなアプリケーションをブーストできる知識</p>
<p>commonsenseに関しては</p>
<p>ConceptNetやTransOMCSは複数のドメインのcommonsenseをカバー</p>
<p>ATOMICやASERはある特定のタイプのcommonsenseにフォーカスした知識ソース</p>
<h2>Knowledge-Intensive NLP Task</h2>
<h3>概要</h3>
<p>Knowledge-intensive NLP taskは必要とする知識ソースの種類で2つに分けられ，さらに詳細に分けることができる</p>
<p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ab23c756-9f8e-4f3c-a76c-cdd674276022/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.02.12.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181947Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b76560af21a3c08235665cc245c16fb63334660f36a2530535b06fa485395991&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject" alt=""></p>
<ul>
<li>encyclopedic knowledge-intensive NLP task</li>
</ul>
<p>encyclopedicの知識ソースを利用する</p>
<ul>
<li>open-domain QA</li>
<li>fact verification</li>
<li>entity linking</li>
</ul>
<p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/28ba511c-8fa2-4031-9624-7a7460f25913/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.02.31.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181952Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b0c31adc0b4a7f7ea85b0fe08456ba8559910988866d93f039288cbd4421f3a6&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject" alt=""></p>
<ul>
<li>commonsense knowledge-intensive NLP task</li>
</ul>
<p>commonsenseの知識ソースを利用する</p>
<p>commonsenseの多様性のために，タスクのタイプ自体も多様化している</p>
<p>モデルが正確に日常のシナリオを理解し，応答するか否かのテストにフォーカスしたタスク</p>
<ul>
<li>General Commonsense</li>
<li>Social Commonsense</li>
<li>Physical Commonsense</li>
<li>Temporal Commonsense</li>
</ul>
<h3>Knowledge-Intensive Taskの特徴</h3>
<p>実際は，モデルにとってだけではなく，人間にとってもいかなる知識の参照なしに問題に答えるのは難しい．（バラクオバマの誕生日はいつ？など</p>
<p>しかも，外部知識が必要なのにinputとして必要な外部知識が渡されないため，とてもチャレンジングなタスクになっている</p>
<p>そもそも必要な外部知識にグラウンディングするモジュールをPLMKEsの設計に加えることを考慮するようになっている</p>
<h2>Knowledge Fusion Methods</h2>
<p>モデルが知識を統合するステージは二箇所あり，</p>
<ul>
<li>Pre-fusion; pre-training</li>
<li>Post-fusion; fine-tuning</li>
</ul>
<p>の二通りが考えられる（もしくはその両方のステージ</p>
<h3>Pre-Fusion Methods</h3>
<p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ddeea37a-3062-47f7-b3ac-15057b8a1349/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.11.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182017Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=914d261462ed9d88bc35c4edfa5d080b2ffe29c48a555d3ffe8d9407c9fc70a8&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject" alt=""></p>
<p>pre-trainingのステージで知識を統合する手法</p>
<p>モデルに知識を入力するため，構造化された知識データを非構造化データのテキストコーパスへと処理→モデルに入力</p>
<p>テキストデータとして知識を入力するため，大きくモデルのアーキテクチャを変更する必要はない</p>
<p>ただし，知識グラフのような構造化データを非構造化データへ変えることは難しいこともある</p>
<p>簡単な対処法はエンティティと関係性を結合するか，流暢な文章をconditional text generation modelに生成させるか</p>
<p>Zhang et al. 2019 | Agarwal et al. 2021 を参照（必要になれば読む</p>
<h3>Post-Fusion Methods</h3>
<p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a978299c-4851-41c8-a702-a3aafb0f9323/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.37.53.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182027Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=e4e8f6a6703612a8f1118eb67304d93279f45d48fff78fd6f0b2c2d8b2b5a063&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject" alt=""></p>
<p>まず，関連知識をキャプチャする</p>
<p>次に取得した関連知識をGNNなどのエンコーダでembeddingを得る</p>
<ul>
<li>それを追加特徴量としてpre-trained LMに与える（図でいうA）</li>
<li>直接pre-trained LMに入力する（図でいうB）</li>
</ul>
<h3>Hybrid-Fusion Methods</h3>
<p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b696904a-be2b-4bd8-9d93-ca87a47ecc5e/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_19.38.22.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182031Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=8c309aba75c92d449b843fead794f87d2bd0340923faeef77c381a33ab5eb82e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject" alt=""></p>
<p>pre-trainingとfine-tuningの両方のステージで知識を統合する</p>
<p>追加の学習されるretrieverによりaugmentされたpre-trained modelは，fine-tuningのステージでより効果的にretrieverからの知識を活用できる</p>
<p>retrieval-augmented pre-trainingでhybrid-fusionが広く使われている</p>
<h3>代表的なモデル</h3>
<p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ce1f044a-ba15-4c30-8d61-eab525800d9d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_19.39.00.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182039Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2bfc9853f1a4e6bff019baa7c3effe98a1c01a806e603f05131576021c53bf3e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject" alt=""></p>
<p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/81d13c12-2379-4709-bc00-97fd4185fd4b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-31_12.00.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182039Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=3f15cc31ed578332b99f8185529710bceec9e12123b9b990b31a909b1da89850&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject" alt=""></p>
<p>Table4/5はSOTAモデルを示す</p>
<p>encyclopedic knowledge-intensive taskにおいては，BOOLQをのぞき，全てpost-fusionを採用</p>
<p>commonsense knowledge-intensive taskにおいては，CommonsenseQAをのぞき，全てpre-fusionを採用</p>
<p>pre-fusionとpost-fusionの違いは何？</p>
<p>pre-fusionは，知識を事前学習のパラメータに暗示的に保存数る</p>
<p>最終的にどの知識がパラメータに保存するのかを決定するのは難しい</p>
<p>知識の引き出しや利用の難しさが増す</p>
</body>
</html>
</article><div class="socialshare_container__SSXJE"><h3>タメになったらSHARE!!!</h3><div class="socialshare_container__links__JZs4j"><a target="_blank" href="https://twitter.com/share?url=https://yuta0306.github.io/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models"><img src="/icons/twitter.png" loading="lazy" alt="https://yuta0306.github.io/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-ModelsをTwitterに共有する"/></a><a target="_blank" href="https://www.facebook.com/share.php?u=https://yuta0306.github.io/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models"><img src="/icons/facebook.png" loading="lazy" alt="https://yuta0306.github.io/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-ModelsをFacebookに共有する"/></a><a target="_blank" href="http://b.hatena.ne.jp/entry/https:/yuta0306.github.io/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models"><img src="/icons/hatenablog.png" loading="lazy" alt="https://yuta0306.github.io/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Modelsをはてなブログに共有する"/></a></div></div></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET,mental%20health,NLP,mental%20state%20knowledge,mentalisation,Contrasive%20Learning,MentalRoBERTa,KC-Net/1">COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system,Internet-Augmented/1">dialogue system,Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system,knowledge-base/1">dialogue system,knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system,NLI/1">dialogue system,NLI</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system,persona,Prompt-Tuning/1">dialogue system,persona,Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system,survey,DST/1">dialogue system,survey,DST</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection,multi-modal/1">humor detection,multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/laughter,shared%20laughter/1">laughter,shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/MT,transformer,Multi-Hop%20Transformer/1">MT,transformer,Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey,dialogue%20system/1">survey,dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive%20NLP/1">survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/transformer,Highway%20Transformer,Gating%20Mechanism,Self-Dependency-Units%20(SDU)/1">transformer,Highway Transformer,Gating Mechanism,Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003eまとめること\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eKnowledge-Intensive NLPの概要\u003c/li\u003e\n\u003cli\u003eKnowledge Sources\u003c/li\u003e\n\u003cli\u003eEncyclopedic Knowledge\u003c/li\u003e\n\u003cli\u003eCommonsense Knowledge\u003c/li\u003e\n\u003cli\u003e最近のKnowledge Sourcesの特徴\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Task\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Taskの概要\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Taskの特徴\u003c/li\u003e\n\u003cli\u003eKnowledge Fusion Methodsについて\u003c/li\u003e\n\u003cli\u003ePre-Fusion Methods\u003c/li\u003e\n\u003cli\u003ePost-Fusion Methods\u003c/li\u003e\n\u003cli\u003eHybrid-Fusion Methods\u003c/li\u003e\n\u003cli\u003e代表的なモデルの紹介\u003c/li\u003e\n\u003cli\u003eChallengingなことと今後の方向性\u003c/li\u003e\n\u003cli\u003eUnified PLMKEs Across Tasks and Domains\u003c/li\u003e\n\u003cli\u003eReliability of Knowledge Sources\u003c/li\u003e\n\u003cli\u003eReasoning Module Design\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e事前学習済みモデルにより，モデルのcapacityは増加傾向にあるが，encyclopedicやcommonsenseを用いた，knowledgeableなNLPモデルの需要の高まりが生じている\u003c/p\u003e\n\u003cp\u003e**PLMKEs (Pre-trained Language Model-based Knowledge-Enhanced models)**についてまとめたsurvey論文\u003c/p\u003e\n\u003cp\u003elinguistic or factual knowledgeは暗示的にモデルのパラメータに保存される\u003c/p\u003e\n\u003cp\u003e→事前学習済みのNLPモデルがより汎用的な能力を持つことを一部ではあるが説明できる\u003c/p\u003e\n\u003cp\u003e今のpre-trained LMは，明示的なencyclopedicやcommonsenseのレバレッジ能力に欠けている\u003c/p\u003e\n\u003cp\u003ePLMKEsは，関連する外部知識を取り出すモジュールと知識を混ぜるモジュールがある\u003c/p\u003e\n\u003cp\u003ePLMKEsに関連した重要な3つの要素がある\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eKnowledge Sources\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Tasks\u003c/li\u003e\n\u003cli\u003eKnowledge Fusion Methods\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eKnowledge Sources\u003c/h2\u003e\n\u003ch3\u003eEncyclopedic knowledge\u003c/h3\u003e\n\u003cp\u003eエンティティに関する属性とエンティティ間の関係性をもった知識\u003c/p\u003e\n\u003cp\u003eEntity: person → Attributes: age → Relations: educated at\u003c/p\u003e\n\u003cp\u003eWikipediaは大量のencyclopedicな知識を持っている\u003c/p\u003e\n\u003cp\u003e人物の経歴やイベントの背景などを含んでいる\u003c/p\u003e\n\u003cp\u003e一般的にはtripletsで構成されていることが多い\u003c/p\u003e\n\u003cp\u003ee.g. \u0026#x3C;Tom Hanks, occupation, actor\u003e\u003c/p\u003e\n\u003cp\u003eWikidataのような知識データがPLMKEsに広く使用されている\u003c/p\u003e\n\u003ch3\u003eCommonsense Knowledge\u003c/h3\u003e\n\u003cp\u003e日常生活のなかでの状況に関する知識\u003c/p\u003e\n\u003cp\u003eイベントとその影響を記す\u003c/p\u003e\n\u003cp\u003ee.g. mop up the floor if we split food over it / study hard to win scholarship / goat has four legs\u003c/p\u003e\n\u003cp\u003ecommonsenseの特徴\u003c/p\u003e\n\u003cp\u003e多くの人の間で共有されている知識であり，コミュニケーションの中で暗示的に想定されている知識である\u003c/p\u003e\n\u003cp\u003ecommonsenseもtripletsで表現される\u003c/p\u003e\n\u003cp\u003e最近のPLMKEsでは，ConceptNetとATOMICが外部知識として使用されることが多い\u003c/p\u003e\n\u003ch3\u003eKnowledge Sourcesの特徴\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/30b21e96-66e9-4c93-b612-2a5ec35b43c9/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_16.42.16.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026#x26;X-Amz-Date=20230521T181930Z\u0026#x26;X-Amz-Expires=3600\u0026#x26;X-Amz-Signature=a08e0cc46127ef5b006be5eca7349c3b4f203325cb4dd1c39cb9757131c24c8e\u0026#x26;X-Amz-SignedHeaders=host\u0026#x26;x-id=GetObject\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003elarge-scaleでdiverse\u003c/p\u003e\n\u003cp\u003e現在のソースはより正確で安定的に作られている\u003c/p\u003e\n\u003cp\u003eアノテーションのプロセスは部分的に自動化されていて，非エキスパートにもaccessibleになっている\u003c/p\u003e\n\u003cp\u003e知識データがカバーするドメインは多様\u003c/p\u003e\n\u003cp\u003eオープンドメインのものもあれば，specificなドメインのものも\u003c/p\u003e\n\u003cp\u003eWikipedia, DBPedia, Freebaseなどはオープンドメイン\u003c/p\u003e\n\u003cp\u003eUMLSやAMinerなどはbiomedicineやscienceの特定ドメイン\u003c/p\u003e\n\u003cp\u003edomain-specificなアプリケーションをブーストできる知識\u003c/p\u003e\n\u003cp\u003ecommonsenseに関しては\u003c/p\u003e\n\u003cp\u003eConceptNetやTransOMCSは複数のドメインのcommonsenseをカバー\u003c/p\u003e\n\u003cp\u003eATOMICやASERはある特定のタイプのcommonsenseにフォーカスした知識ソース\u003c/p\u003e\n\u003ch2\u003eKnowledge-Intensive NLP Task\u003c/h2\u003e\n\u003ch3\u003e概要\u003c/h3\u003e\n\u003cp\u003eKnowledge-intensive NLP taskは必要とする知識ソースの種類で2つに分けられ，さらに詳細に分けることができる\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ab23c756-9f8e-4f3c-a76c-cdd674276022/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.02.12.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026#x26;X-Amz-Date=20230521T181947Z\u0026#x26;X-Amz-Expires=3600\u0026#x26;X-Amz-Signature=b76560af21a3c08235665cc245c16fb63334660f36a2530535b06fa485395991\u0026#x26;X-Amz-SignedHeaders=host\u0026#x26;x-id=GetObject\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eencyclopedic knowledge-intensive NLP task\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eencyclopedicの知識ソースを利用する\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eopen-domain QA\u003c/li\u003e\n\u003cli\u003efact verification\u003c/li\u003e\n\u003cli\u003eentity linking\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/28ba511c-8fa2-4031-9624-7a7460f25913/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.02.31.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026#x26;X-Amz-Date=20230521T181952Z\u0026#x26;X-Amz-Expires=3600\u0026#x26;X-Amz-Signature=b0c31adc0b4a7f7ea85b0fe08456ba8559910988866d93f039288cbd4421f3a6\u0026#x26;X-Amz-SignedHeaders=host\u0026#x26;x-id=GetObject\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecommonsense knowledge-intensive NLP task\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ecommonsenseの知識ソースを利用する\u003c/p\u003e\n\u003cp\u003ecommonsenseの多様性のために，タスクのタイプ自体も多様化している\u003c/p\u003e\n\u003cp\u003eモデルが正確に日常のシナリオを理解し，応答するか否かのテストにフォーカスしたタスク\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGeneral Commonsense\u003c/li\u003e\n\u003cli\u003eSocial Commonsense\u003c/li\u003e\n\u003cli\u003ePhysical Commonsense\u003c/li\u003e\n\u003cli\u003eTemporal Commonsense\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eKnowledge-Intensive Taskの特徴\u003c/h3\u003e\n\u003cp\u003e実際は，モデルにとってだけではなく，人間にとってもいかなる知識の参照なしに問題に答えるのは難しい．（バラクオバマの誕生日はいつ？など\u003c/p\u003e\n\u003cp\u003eしかも，外部知識が必要なのにinputとして必要な外部知識が渡されないため，とてもチャレンジングなタスクになっている\u003c/p\u003e\n\u003cp\u003eそもそも必要な外部知識にグラウンディングするモジュールをPLMKEsの設計に加えることを考慮するようになっている\u003c/p\u003e\n\u003ch2\u003eKnowledge Fusion Methods\u003c/h2\u003e\n\u003cp\u003eモデルが知識を統合するステージは二箇所あり，\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePre-fusion; pre-training\u003c/li\u003e\n\u003cli\u003ePost-fusion; fine-tuning\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eの二通りが考えられる（もしくはその両方のステージ\u003c/p\u003e\n\u003ch3\u003ePre-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ddeea37a-3062-47f7-b3ac-15057b8a1349/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.11.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026#x26;X-Amz-Date=20230521T182017Z\u0026#x26;X-Amz-Expires=3600\u0026#x26;X-Amz-Signature=914d261462ed9d88bc35c4edfa5d080b2ffe29c48a555d3ffe8d9407c9fc70a8\u0026#x26;X-Amz-SignedHeaders=host\u0026#x26;x-id=GetObject\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epre-trainingのステージで知識を統合する手法\u003c/p\u003e\n\u003cp\u003eモデルに知識を入力するため，構造化された知識データを非構造化データのテキストコーパスへと処理→モデルに入力\u003c/p\u003e\n\u003cp\u003eテキストデータとして知識を入力するため，大きくモデルのアーキテクチャを変更する必要はない\u003c/p\u003e\n\u003cp\u003eただし，知識グラフのような構造化データを非構造化データへ変えることは難しいこともある\u003c/p\u003e\n\u003cp\u003e簡単な対処法はエンティティと関係性を結合するか，流暢な文章をconditional text generation modelに生成させるか\u003c/p\u003e\n\u003cp\u003eZhang et al. 2019 | Agarwal et al. 2021 を参照（必要になれば読む\u003c/p\u003e\n\u003ch3\u003ePost-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a978299c-4851-41c8-a702-a3aafb0f9323/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.37.53.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026#x26;X-Amz-Date=20230521T182027Z\u0026#x26;X-Amz-Expires=3600\u0026#x26;X-Amz-Signature=e4e8f6a6703612a8f1118eb67304d93279f45d48fff78fd6f0b2c2d8b2b5a063\u0026#x26;X-Amz-SignedHeaders=host\u0026#x26;x-id=GetObject\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eまず，関連知識をキャプチャする\u003c/p\u003e\n\u003cp\u003e次に取得した関連知識をGNNなどのエンコーダでembeddingを得る\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eそれを追加特徴量としてpre-trained LMに与える（図でいうA）\u003c/li\u003e\n\u003cli\u003e直接pre-trained LMに入力する（図でいうB）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHybrid-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b696904a-be2b-4bd8-9d93-ca87a47ecc5e/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_19.38.22.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026#x26;X-Amz-Date=20230521T182031Z\u0026#x26;X-Amz-Expires=3600\u0026#x26;X-Amz-Signature=8c309aba75c92d449b843fead794f87d2bd0340923faeef77c381a33ab5eb82e\u0026#x26;X-Amz-SignedHeaders=host\u0026#x26;x-id=GetObject\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epre-trainingとfine-tuningの両方のステージで知識を統合する\u003c/p\u003e\n\u003cp\u003e追加の学習されるretrieverによりaugmentされたpre-trained modelは，fine-tuningのステージでより効果的にretrieverからの知識を活用できる\u003c/p\u003e\n\u003cp\u003eretrieval-augmented pre-trainingでhybrid-fusionが広く使われている\u003c/p\u003e\n\u003ch3\u003e代表的なモデル\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ce1f044a-ba15-4c30-8d61-eab525800d9d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_19.39.00.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026#x26;X-Amz-Date=20230521T182039Z\u0026#x26;X-Amz-Expires=3600\u0026#x26;X-Amz-Signature=2bfc9853f1a4e6bff019baa7c3effe98a1c01a806e603f05131576021c53bf3e\u0026#x26;X-Amz-SignedHeaders=host\u0026#x26;x-id=GetObject\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/81d13c12-2379-4709-bc00-97fd4185fd4b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-31_12.00.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026#x26;X-Amz-Date=20230521T182039Z\u0026#x26;X-Amz-Expires=3600\u0026#x26;X-Amz-Signature=3f15cc31ed578332b99f8185529710bceec9e12123b9b990b31a909b1da89850\u0026#x26;X-Amz-SignedHeaders=host\u0026#x26;x-id=GetObject\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eTable4/5はSOTAモデルを示す\u003c/p\u003e\n\u003cp\u003eencyclopedic knowledge-intensive taskにおいては，BOOLQをのぞき，全てpost-fusionを採用\u003c/p\u003e\n\u003cp\u003ecommonsense knowledge-intensive taskにおいては，CommonsenseQAをのぞき，全てpre-fusionを採用\u003c/p\u003e\n\u003cp\u003epre-fusionとpost-fusionの違いは何？\u003c/p\u003e\n\u003cp\u003epre-fusionは，知識を事前学習のパラメータに暗示的に保存数る\u003c/p\u003e\n\u003cp\u003e最終的にどの知識がパラメータに保存するのかを決定するのは難しい\u003c/p\u003e\n\u003cp\u003e知識の引き出しや利用の難しさが増す\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","Date":"2023-05-21","Category":"論文","Tags":"survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP","Authos":"ゆうぼう","Slug":"A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/72a3a885-7a2d-4363-ba6b-3371efd274e7/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.49.18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Content-Sha256=UNSIGNED-PAYLOAD\u0026X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20230521T181845Z\u0026X-Amz-Expires=3600\u0026X-Amz-Signature=4f2395f9c9ae855d53990b80015353bf52b3381b31b93d31fe5fd92cdd60b7a5\u0026X-Amz-SignedHeaders=host\u0026x-id=GetObject","Description":"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net","conda","CSS","dialogue system","dialogue system,Internet-Augmented","dialogue system,knowledge-base","dialogue system,NLI","dialogue system,persona,Prompt-Tuning","dialogue system,survey,DST","ESPNet","ffmpeg","Flask","Go","Google Colaboratory","Heroku","HTML","humor detection,multi-modal","JavaScript","JSON","Kaggle","laughter,shared laughter","Linux","Mac","make","map","MeCab","ML","MT,transformer,Multi-Hop Transformer","MySQL","NLP","Node","node.js","npm","Pandas","Poetry","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","SISR","subprocess","Super-Resolution","survey,dialogue system","survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP","tensorflow","Tkinter","transformer,Highway Transformer,Gating Mechanism,Self-Dependency-Units (SDU)","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"]},"__N_SSG":true},"page":"/[slug]","query":{"slug":"A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models"},"buildId":"jHxrKA87gf2fNs0dDanBG","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>