<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>「<!-- -->ML<!-- -->」<!-- -->1<!-- -->ページ目 | <!-- -->ゆうぼうの書跡棚</title><meta name="next-head-count" content="3"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/75506965150cde8a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/75506965150cde8a.css" data-n-g=""/><link rel="preload" href="/_next/static/css/71fbbc4c2f48f099.css" as="style"/><link rel="stylesheet" href="/_next/static/css/71fbbc4c2f48f099.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/tag/%5Btag%5D/%5Bpage%5D-f9e21eb9aa12ee31.js" defer=""></script><script src="/_next/static/UjM4J72D9SDl7y9VZwM4B/_buildManifest.js" defer=""></script><script src="/_next/static/UjM4J72D9SDl7y9VZwM4B/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><h1 class="header_header__title__uoTF0">ゆうぼうの書跡棚</h1></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"><a class="header_category__item__0CmfH" href="/category/%E8%AB%96%E6%96%87/1"><li>論文</li></a><a class="header_category__item__0CmfH" href="/category/Web/1"><li>Web</li></a><a class="header_category__item__0CmfH" href="/category/JavaScript/1"><li>JavaScript</li></a><a class="header_category__item__0CmfH" href="/category/Competition/1"><li>Competition</li></a><a class="header_category__item__0CmfH" href="/category/Cloud/1"><li>Cloud</li></a><a class="header_category__item__0CmfH" href="/category/Linux/1"><li>Linux</li></a><a class="header_category__item__0CmfH" href="/category/Python/1"><li>Python</li></a><a class="header_category__item__0CmfH" href="/category/ML/1"><li>ML</li></a><a class="header_category__item__0CmfH" href="/category/Go/1"><li>Go</li></a><a class="header_category__item__0CmfH" href="/category/SQL/1"><li>SQL</li></a></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__grid__Bpzhl"><div class="card_card__container__PrCEE"><a href="/pytorch-collate_fn-args"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/pytorch-logo.jpg" alt="collate_fnで複数の引数を取りたい!!" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2021-12-24" itemProp="published">2021-12-24</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">collate_fnで複数の引数を取りたい!!</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/logistic-with-l1"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/network.jpg" alt="ロジスティック回帰でL1正則化を利用できない問題の解決法" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2020-08-01" itemProp="published">2020-08-01</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">ロジスティック回帰でL1正則化を利用できない問題の解決法</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/prefer-to-make_blobs"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/python.jpg" alt="scikit-learnのmake_blobsに乗り換えよう!!" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2020-07-21" itemProp="published">2020-07-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">scikit-learnのmake_blobsに乗り換えよう!!</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/corpus"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/network.jpg" alt="自然言語処理(NLP)のコーパスって何なん？" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2020-07-11" itemProp="published">2020-07-11</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">自然言語処理(NLP)のコーパスって何なん？</h2></div></div></a></div><div class="paginager_container____vsL"><ul class="paginager_container__pagers__1zmK9"><a class="paginager_container__pager__GaEzu" href="/tag/ML/1"><li class="paginager_container__pager__page__2YOZs">&lt;&lt;</li></a><li class="paginager_container__pager_deactive__Gjmav">&lt;</li><li class="paginager_container__pager_active__k3Sib">1</li><li class="paginager_container__pager_deactive__Gjmav">&gt;</li><a class="paginager_container__pager__GaEzu" href="/tag/ML/1"><li class="paginager_container__pager__page__2YOZs">&gt;&gt;</li></a></ul></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET/1">COMET</a><a class="tags_container__link__1Ts3a" href="/tag/commonsense/1">commonsense</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/Contrasive%20Learning/1">Contrasive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/DST/1">DST</a><a class="tags_container__link__1Ts3a" href="/tag/empathetic%20dialogue%20system/1">empathetic dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/encyclopedic/1">encyclopedic</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Gating%20Mechanism/1">Gating Mechanism</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/Highway%20Transformer/1">Highway Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection/1">humor detection</a><a class="tags_container__link__1Ts3a" href="/tag/Internet-Augmented/1">Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/KC-Net/1">KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/knowledge-base/1">knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/Knowledge-Intensive%20NLP/1">Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/laughter/1">laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20health/1">mental health</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20state%20knowledge/1">mental state knowledge</a><a class="tags_container__link__1Ts3a" href="/tag/mentalisation/1">mentalisation</a><a class="tags_container__link__1Ts3a" href="/tag/MentalRoBERTa/1">MentalRoBERTa</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/MT/1">MT</a><a class="tags_container__link__1Ts3a" href="/tag/Multi-Hop%20Transformer/1">Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/multi-modal/1">multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLI/1">NLI</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/persona/1">persona</a><a class="tags_container__link__1Ts3a" href="/tag/PLMKE/1">PLMKE</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Prompt-Tuning/1">Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/Self-Dependency-Units%20(SDU)/1">Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/shared%20laughter/1">shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey/1">survey</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/transformer/1">transformer</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"TaggedPostData":[{"contentHtml":"\u003cp\u003eTransformersを使って入力テキストをtokenizeするときに，データセットのサイズが大きかったので，バッチ単位でエンコードしたかった時がありました．\u003c/p\u003e\n\u003cp\u003eこの時，collate_fnに対して複数の引数を与えたかった状況の時の対処法です．(日本語変か?)\u003c/p\u003e\n\u003ch2\u003eやりたかったこと\u003c/h2\u003e\n\u003cp\u003eDataLoaderを定義するときに，\u003ccode\u003ecollate_fn\u003c/code\u003eのところで自作collate_fnを指定して，batch単位で流れてくるデータに対してエンコードすること．\u003c/p\u003e\n\u003cp\u003eこれがやりたいことになります．つまりこんな感じ\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.utils \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Dataset, DataLoader\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eMyDataset\u003c/span\u003e(\u003cspan class=\"hljs-title class_ inherited__\"\u003eDataset\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, *args, **kwargs\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e().__init__()\n        ...\n    \n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__len__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        ...\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__getitem__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, idx: \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e\u003c/span\u003e):\n        ...\n\ndataloader = DataLoader(dataset=MyDataset(), batch_size=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e, shuffle=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n            num_workers=os.cpu_count(),\n            collate_fn=custom_collate_fn)  \u003cspan class=\"hljs-comment\"\u003e# \u0026#x3C;--- ここで自作collate_fnを指定して制御\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eやってうまくいかなかったこと\u003c/h2\u003e\n\u003cp\u003e先にやってうまくいかなかったことを共有しておきます．\u003c/p\u003e\n\u003cp\u003e自分が使っているのが，\u003ccode\u003epytorch-lightning\u003c/code\u003eなのでそのせいもあるかもしれません．なので，もしかしたら普通に素のPytorchならうまくいくかもしれません．\u003c/p\u003e\n\u003cp\u003e教えてください🙏\u003c/p\u003e\n\u003ch3\u003elambda式で制御する (functools.partialを使う)\u003c/h3\u003e\n\u003cp\u003eこんなことをしました．\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.utils \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Dataset, DataLoader\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e AutoTokenizer\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eMyDataset\u003c/span\u003e(\u003cspan class=\"hljs-title class_ inherited__\"\u003eDataset\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, *args, **kwargs\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e().__init__()\n        ...\n    \n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__len__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        ...\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__getitem__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, idx: \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e\u003c/span\u003e):\n        ...\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e text, label\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecustom_collate_fn\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003edata, tokenizer, max_length\u003c/span\u003e):\n    texts, labels = \u003cspan class=\"hljs-built_in\"\u003ezip\u003c/span\u003e(*data)\n    texts = \u003cspan class=\"hljs-built_in\"\u003elist\u003c/span\u003e(texts)\n    texts = tokenizer.batch_encode_plus(\n        texts,\n        padding=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n        truncation=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n        max_length=max_length,\n        return_tensors=\u003cspan class=\"hljs-string\"\u003e'pt'\u003c/span\u003e,\n    )\n    labels = torch.LongTensor(labels)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e texts, labels\n\ntokenizer = AutoTokenizer.from_pretrained(...)\nmax_length = \u003cspan class=\"hljs-number\"\u003e256\u003c/span\u003e\ndataloader = DataLoader(dataset=MyDataset(), batch_size=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e, shuffle=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n            num_workers=os.cpu_count(),\n            collate_fn=\u003cspan class=\"hljs-keyword\"\u003elambda\u003c/span\u003e data: custom_collate_fn(data, tokenizer, max_length))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003epytorch-lightning\u003c/code\u003eの仕様だとは思うのですが，\u003ccode\u003epickle\u003c/code\u003eで圧縮するらしくそのタイミングでエラーを吐かれました．\u003c/p\u003e\n\u003cp\u003eなぜだろう...有識者の方教えてください...\u003c/p\u003e\n\u003ch2\u003e【解決策】 classで定義する\u003c/h2\u003e\n\u003cp\u003elambda式でダメだったので，もうクラスの内部に必要なものを保持させておこうということになりました．(僕の中では)\u003c/p\u003e\n\u003cp\u003e次のコードのような感じで解決しました．\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.utils \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Dataset, DataLoader\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e AutoTokenizer\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eMyDataset\u003c/span\u003e(\u003cspan class=\"hljs-title class_ inherited__\"\u003eDataset\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, *args, **kwargs\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e().__init__()\n        ...\n    \n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__len__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        ...\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__getitem__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, idx: \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e\u003c/span\u003e):\n        ...\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e text, label\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eCollateFn\u003c/span\u003e:\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, tokenizer, max_length: \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e\u003c/span\u003e) -\u003e \u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e:\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        os.environ[\u003cspan class=\"hljs-string\"\u003e\"TOKENIZERS_PARALLELISM\"\u003c/span\u003e] = \u003cspan class=\"hljs-string\"\u003e\"true\"\u003c/span\u003e  \u003cspan class=\"hljs-comment\"\u003e# \u0026#x3C;--- 多分これを明示的に指定しないと怒られます (true|false)\u003c/span\u003e\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__call__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, data\u003c/span\u003e):\n        texts, labels = \u003cspan class=\"hljs-built_in\"\u003ezip\u003c/span\u003e(*data)\n        texts = \u003cspan class=\"hljs-built_in\"\u003elist\u003c/span\u003e(texts)\n        texts = self.tokenizer.batch_encode_plus(\n            texts,\n            padding=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n            truncation=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n            max_length=self.max_length,\n            return_tensors=\u003cspan class=\"hljs-string\"\u003e'pt'\u003c/span\u003e,\n        )\n        labels = torch.LongTensor(labels)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e texts, labels\n\ntokenizer = AutoTokenizer.from_pretrained(...)\nmax_length = \u003cspan class=\"hljs-number\"\u003e256\u003c/span\u003e\ndataloader = DataLoader(dataset=MyDataset(), batch_size=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e, shuffle=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e,\n            num_workers=os.cpu_count(),\n            collate_fn=CollateFn(tokenizer, max_length))\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e素のPytorchで組めば問題なかったのかもしれませんが，\u003ccode\u003epytorch-lightning\u003c/code\u003eを使っている方は同じ状況になるかもしれません．\u003c/p\u003e\n\u003cp\u003eその時は，ぜひ参考にclassでcollate_fnで実装してみて解決の一助となれたら幸いです．\u003c/p\u003e","Title":"collate_fnで複数の引数を取りたい!!","Date":"2021-12-24","Category":"Python","Tags":["ML","Python","Pytorch"],"Authors":"ゆうぼう","Slug":"pytorch-collate_fn-args","Thumbnail":"/images/thumbnails/pytorch-logo.jpg","Description":"Transformersを使って入力テキストをtokenizeするときに，データセットのサイズが大きかったので，バッチ単位でエンコードしたかった時がありました．この時，collate_fnに対して複数の引数を与えたかった状況の時の対処法です．(日本語変かも)","Published":true},{"contentHtml":"\u003cp\u003eロジスティック回帰をscikit-learnで実装していると、デフォルトはL2正則化でペナルティを与えています。\u003c/p\u003e\n\u003cp\u003eそこで、もっとスパースにしてやろうとL1正則化を行おうとしたのだが、エラーを吐かれた。その時の解決策を共有します。\u003c/p\u003e\n\u003ch2\u003eエラーを吐かれた時のバージョン\u003c/h2\u003e\n\u003cp\u003e一応最近開発が立て込んでいるので、Anacondaを使って開発環境を分けているのですが、\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e(base)$ conda activate ML\n(ML)$ conda list    (pip listでも行ける)\n......\n......\nscikit-learn           0.23.1    \n......\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eということで、scikit-learnのバージョンは\u003cem\u003e0.23.1\u003c/em\u003eでした。\u003c/p\u003e\n\u003ch2\u003e実装してみる\u003c/h2\u003e\n\u003cp\u003eそれでは実装してみます。至ってシンプルなスクリプトで動く想定でやっていきます。こちらで変化させるハイパーパラメータは以下になります。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eパラメータ\u003c/th\u003e\n\u003cth\u003e値\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eC(正則化のつよさ)\u003c/td\u003e\n\u003ctd\u003e1(デフォルト)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epenalty\u003c/td\u003e\n\u003ctd\u003eL1正則化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emax_iter(イテレーションの上限)\u003c/td\u003e\n\u003ctd\u003e100000\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eまた、訓練データ(X_train, y_train)とテストデータ(X_test, y_test)に分けてあることにします。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.linear_model \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e LogisticRegression\n\nlr_l1 = LogisticRegression(penalty=\u003cspan class=\"hljs-string\"\u003e'l1'\u003c/span\u003e, max_iter=\u003cspan class=\"hljs-number\"\u003e100000\u003c/span\u003e).fit(X_train, y_train)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eするとこんなエラーが返ってきます。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e~/opt/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e fit(self, X, y, sample_weight)\n1302         The SAGA solver supports both float64 and float32 bit arrays.\n1303         \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"hljs-string\"\u003e\"\n-\u003e 1304         solver = _check_solver(self.solver, self.penalty, self.dual)\n1305 \n1306         if not isinstance(self.C, numbers.Number) or self.C \u0026#x3C; 0:\n\n~/opt/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py in _check_solver(solver, penalty, dual)\n441     if solver not in ['liblinear', 'saga'] and penalty not in ('l2', 'none'):\n442         raise ValueError(\"\u003c/span\u003eSolver %s supports only \u003cspan class=\"hljs-string\"\u003e'l2'\u003c/span\u003e or \u003cspan class=\"hljs-string\"\u003e'none'\u003c/span\u003e penalties, \u003cspan class=\"hljs-string\"\u003e\"\n--\u003e 443                          \"\u003c/span\u003egot %s penalty.\u003cspan class=\"hljs-string\"\u003e\" % (solver, penalty))\n444     if solver != 'liblinear' and dual:\n445         raise ValueError(\"\u003c/span\u003eSolver %s supports only \u003cspan class=\"hljs-string\"\u003e\"\n\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eファイルのありかは人それぞれですが、エラーは返ってきます。\u003cbr\u003e\nデフォルトの\u003cstrong\u003eSolverがlbfgs\u003c/strong\u003eに変わっていたそうで、l2またはnoneしかペナルティをサポートしていないそうです。\u003c/p\u003e\n\u003cp\u003eというわけで、Solverに\u003cstrong\u003eliblinear\u003c/strong\u003eを指定しないといけないようですね。\u003c/p\u003e\n\u003ch2\u003eliblinearを指定する\u003c/h2\u003e\n\u003cp\u003e先ほどのエラーをなくすため、新たにパラメータを足します。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eパラメータ\u003c/th\u003e\n\u003cth\u003e値\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eC(正則化のつよさ)\u003c/td\u003e\n\u003ctd\u003e1(デフォルト)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epenalty\u003c/td\u003e\n\u003ctd\u003eL1正則化\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emax_iter(イテレーションの上限)\u003c/td\u003e\n\u003ctd\u003e100000\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esolver\u003c/td\u003e\n\u003ctd\u003eliblinear\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003eでは足します。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.linear_model \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e LogisticRegression\n\nlr_l1 = LogisticRegression(penalty=\u003cspan class=\"hljs-string\"\u003e'l1'\u003c/span\u003e, solver=\u003cspan class=\"hljs-string\"\u003e'liblinear'\u003c/span\u003e, max_iter=\u003cspan class=\"hljs-number\"\u003e100000\u003c/span\u003e).fit(X_train, y_train)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eこれで無事動くようになりました!!!\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003eまとめです。\u003cbr\u003e\nscikit-learnを用いて、ロジスティック回帰を使う時、さらにL1正則化をかけたい時は**solver='liblinear'**を引数に追加しましょう。\u003c/p\u003e\n\u003cp\u003eこの周りは色々と変化が早いので、本を買う際にも初版等も確認しつつ買った方が良い気がしました。バージョン確認も大切に。\u003c/p\u003e","Title":"ロジスティック回帰でL1正則化を利用できない問題の解決法","Date":"2020-08-01","Category":"Python","Tags":["ML","Python","Scikit-learn"],"Authors":"ゆうぼう","Slug":"logistic-with-l1","Thumbnail":"/images/thumbnails/network.jpg","Description":"ロジスティック回帰をscikit-learnで実装していると、デフォルトはL2正則化でペナルティを与えています。そこで、もっとスパースにしてやろうとL1正則化を行おうとしたのだが、エラーを吐かれた。その時の解決策を共有します。","Published":true},{"contentHtml":"\u003cp\u003e一応参考書通りに学習するのだが、基本的にはいつも最新版をインストールして使う人間なもので、Warning及びErrorとの戦いはよくあることです。ので、Warningとかが出るとうっと身構えてしまうので、困らないように備忘録かつ反面教師として残しておきます。\u003c/p\u003e\n\u003ch2\u003eとりあえずmake_forge()をやってみようか\u003c/h2\u003e\n\u003cp\u003eとりあえずmake_forge()でforgeデータを生成し、Warningさせてみますかね。。。\u003c/p\u003e\n\u003cp\u003eライブラリはmglearnを使うのでpip環境がある人は、\u003cstrong\u003epip install mglearn\u003c/strong\u003eをしてください。その上で、\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e mglearn    \u003cspan class=\"hljs-comment\"\u003e# mglearnのインポート\u003c/span\u003e\nX, y = mglearn.datasets.make_forge()    \u003cspan class=\"hljs-comment\"\u003e# make_forgeメソッドで生成\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e以下がアウトプットです。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-bash\"\u003e/Users/user/opt/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function make_blobs is deprecated; Please import make_blobs directly from scikit-learn\nwarnings.warn(msg, category=FutureWarning)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eなんだかWarningで怒られましたorz\u003c/p\u003e\n\u003cp\u003e将来的にsklearn.datasets.makeblobs()と被るよってことを言いたいらしいです。\u003cem\u003escikit-learnから直接make_blobsをインポートしろ\u003c/em\u003eとか言ってますね。\n次からWarningを避けて行きます。\u003c/p\u003e\n\u003ch2\u003emake_blobsに乗り換える\u003c/h2\u003e\n\u003cp\u003emake_blobsメソッドに乗り換えて行きます。これはscikit-learnのdatasetsモジュールに含まれているみたいなので、こいつをインポートして行きます。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.datasets \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_blobs    \u003cspan class=\"hljs-comment\"\u003e# これでインポート完了\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eインポートがうまくいったら次はメソッドを呼び出します。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eX, y = make_blobs()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eこれでデータがうまく生成されたようです。無事Warningも出てきません!!!\n念のため、Xの型をみて行きます。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"X.shape: {}\"\u003c/span\u003e.\u003cspan class=\"hljs-built_in\"\u003eformat\u003c/span\u003e(X.shape))\n\n\u003cspan class=\"hljs-comment\"\u003e# -\u003e X.shape: (100, 2)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e詰まるところ、2つの特徴量を持つデータが100個生成されました。100*2の行列ですね。\nmake_forge()のときは2つの特徴量のデータが26個を期待していたようなので、データ量が増えたみたいですね。\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003emglearn.datasets.make_forge()でWarningを回避する方法のまとめがこちらです。\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.datasets \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e make_blobs    \u003cspan class=\"hljs-comment\"\u003e# インポート\u003c/span\u003e\nX, y = make_blobs()    \u003cspan class=\"hljs-comment\"\u003e# make_blobsメソッドの実行\u003c/span\u003e\n\n\u003cspan class=\"hljs-string\"\u003e\"\"\"\n確認のおまけ\n\"\"\"\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"X.shape: {}\"\u003c/span\u003e.\u003cspan class=\"hljs-built_in\"\u003eformat\u003c/span\u003e(X.shape))\n\n\u003cspan class=\"hljs-comment\"\u003e#-\u003e X.shape: (100, 2)    # 特徴量を2つ持つ100個のデータ\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003escikit-learn周りは、アップデートが早いので少し古い技術書なだけでも、Future Warningが出たり、Errorが出たりすることが多々あります。\n気をつけながら学習をする必要がありそうですね。では、今回はここまで！\u003c/p\u003e","Title":"scikit-learnのmake_blobsに乗り換えよう!!","Date":"2020-07-21","Category":"Python","Tags":["ML","Python","Scikit-learn"],"Authors":"ゆうぼう","Slug":"prefer-to-make_blobs","Thumbnail":"/images/thumbnails/python.jpg","Description":"Pythonではじめる機械学習をやっている最中に、mglearnというライブラリからmake_forge()メソッドでデータを生成することがあったのですが、Warningが出て怒られたので、推奨される形に戻すために互換性のあるコードに直します。","Published":true},{"contentHtml":"\u003ch2\u003eコーパスとは\u003c/h2\u003e\n\u003cp\u003e**コーパス(corpus)**とは、集めた文書のことをいいます。\u003c/p\u003e\n\u003cp\u003eもともとの原義としては、ある主題とかある作者に関する文書を集めたものがコーパスと呼ばれていたそうです。\u003c/p\u003e\n\u003cp\u003e現在はもう少し広義で捉えられ、\u003cstrong\u003e文書や音声を集めたデータそのもの、あるいはデータに情報を付与して加工したもの\u003c/strong\u003eを総称してコーパスというそうです。\u003c/p\u003e\n\u003cp\u003e最近の自然言語処理のタスクの進展は、このコーパスに活用による部分が多いです。\u003c/p\u003e\n\u003ch2\u003e生コーパス(raw corpus)\u003c/h2\u003e\n\u003cp\u003e前のセクションで話したように、コーパスには加工を加えたものと、そのまま生データのものと二通り考えられました。\u003c/p\u003e\n\u003cp\u003eそこで、生データのままの文章や音声を「\u003cstrong\u003e生コーパス(raw corpus)\u003c/strong\u003e」と呼ぶことができます。\u003c/p\u003e\n\u003ch2\u003e翻訳に関するコーパスの分類\u003c/h2\u003e\n\u003cp\u003e生コーパスの中でも、その種はいくつか存在します。\nこのトピックでは機械翻訳で扱われるようなコーパスの分類についてお話します。\u003c/p\u003e\n\u003ch2\u003e#対訳コーパス／パラレルコーパス\u003c/h2\u003e\n\u003cp\u003eまずは、「\u003cstrong\u003e対訳コーパス(bilingual corpus)\u003c/strong\u003e」または「\u003cstrong\u003eパラレルコーパス(parallel corpus)\u003c/strong\u003e」です。\u003c/p\u003e\n\u003cp\u003eこの対訳コーパスとは、翻訳関係にある2言語の文書対を収集した生コーパスになります。このコーパスは、非常に貴重ではありますが、なかなか入手しにくい希少なデータです。しかし、この対訳コーパスは機械翻訳においてとても重要な知識源となっていることは確かです。\u003c/p\u003e\n\u003ch2\u003e#コンパラブルコーパス\u003c/h2\u003e\n\u003cp\u003e対訳コーパスでは、希少なコーパスであったのに対して、  「\u003cstrong\u003eコンパラブルコーパス(comparable corpus)\u003c/strong\u003e」は、しっかりとした対訳関係にないにしても、同じトピックに関して2言語の文書対のコーパスです。\u003c/p\u003e\n\u003cp\u003eコンパラブルコーパスは、対訳コーパスほどきっちりとした対訳が制約されないので、このような文書は大量に存在します。これらの文書を収集したものがコンパラブルコーパスです。\u003c/p\u003e\n\u003cp\u003e例としてわかりやすいのは、Wikipedeaでしょう。  Wikipediaでは言語リンクでつながった複数の言語でのページが存在します。これらの文書対ではきっちりとした対訳は保証されませんが、大量のデータを入手することができ、これも極めて重要な知識源となります。\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e以上がコーパスに関する簡単な説明でした。他にも均衡コーパス(balanced corpus)や注釈コーパス(annotated corpus)といった分類もあります。\u003c/p\u003e\n\u003cp\u003eここで抑えるべき重要なことは、コーパスとは広義で\u003cstrong\u003e文書や音声を集めたデータそのもの、あるいはデータに情報を付与して加工したもの\u003c/strong\u003eということでしょう。\u003c/p\u003e\n\u003cp\u003e今回は主にコーパスの説明とともに生コーパスについての説明をしていきました。実際に加工を加えたコーパスに関しては、また別の記事にしたいと思います!\u003c/p\u003e","Title":"自然言語処理(NLP)のコーパスって何なん？","Date":"2020-07-11","Category":"ML","Tags":["ML","NLP"],"Authors":"ゆうぼう","Slug":"corpus","Thumbnail":"/images/thumbnails/network.jpg","Description":"自然言語処理という機械学習のタスクにおいて「コーパス」という言葉が出てきます。そのコーパスについてお話をしていきます。","Published":true}],"tag":"ML","categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","CSS","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"pages":1,"page":1},"__N_SSG":true},"page":"/tag/[tag]/[page]","query":{"tag":"ML","page":"1"},"buildId":"UjM4J72D9SDl7y9VZwM4B","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>