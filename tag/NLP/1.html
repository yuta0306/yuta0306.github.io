<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>「<!-- -->NLP<!-- -->」<!-- -->1<!-- -->ページ目 | <!-- -->ゆうぼうの書跡棚</title><meta name="next-head-count" content="3"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta property="og:title" content="ゆうぼうの書跡棚"/><meta property="og:type" content="website"/><meta property="og:url" content="https://yuta0306.github.io"/><meta property="og:image" content="https://yuta0306.github.io/images/default.png"/><meta property="og:site_name" content="ゆうぼうの書跡棚"/><meta property="og:description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/75506965150cde8a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/75506965150cde8a.css" data-n-g=""/><link rel="preload" href="/_next/static/css/71fbbc4c2f48f099.css" as="style"/><link rel="stylesheet" href="/_next/static/css/71fbbc4c2f48f099.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/tag/%5Btag%5D/%5Bpage%5D-f9e21eb9aa12ee31.js" defer=""></script><script src="/_next/static/e_TiOeLyJW3ARb99YyDQ1/_buildManifest.js" defer=""></script><script src="/_next/static/e_TiOeLyJW3ARb99YyDQ1/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><h1 class="header_header__title__uoTF0">ゆうぼうの書跡棚</h1></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"><a class="header_category__item__0CmfH" href="/category/%E8%AB%96%E6%96%87/1"><li>論文</li></a><a class="header_category__item__0CmfH" href="/category/Web/1"><li>Web</li></a><a class="header_category__item__0CmfH" href="/category/JavaScript/1"><li>JavaScript</li></a><a class="header_category__item__0CmfH" href="/category/Competition/1"><li>Competition</li></a><a class="header_category__item__0CmfH" href="/category/Cloud/1"><li>Cloud</li></a><a class="header_category__item__0CmfH" href="/category/Linux/1"><li>Linux</li></a><a class="header_category__item__0CmfH" href="/category/Python/1"><li>Python</li></a><a class="header_category__item__0CmfH" href="/category/ML/1"><li>ML</li></a><a class="header_category__item__0CmfH" href="/category/Go/1"><li>Go</li></a><a class="header_category__item__0CmfH" href="/category/SQL/1"><li>SQL</li></a></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__grid__Bpzhl"><div class="card_card__container__PrCEE"><a href="/A-mental-state-Knowledge%E2%80%93aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/A-mental-state-Knowledge–aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media.png" alt="【論文まとめ】A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models.png" alt="【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/corpus"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/network.jpg" alt="自然言語処理(NLP)のコーパスって何なん？" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2020-07-11" itemProp="published">2020-07-11</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">自然言語処理(NLP)のコーパスって何なん？</h2></div></div></a></div><div></div><div class="paginager_container____vsL"><ul class="paginager_container__pagers__1zmK9"><a class="paginager_container__pager__GaEzu" href="/tag/NLP/1"><li class="paginager_container__pager__page__2YOZs">&lt;&lt;</li></a><li class="paginager_container__pager_deactive__Gjmav">&lt;</li><li class="paginager_container__pager_active__k3Sib">1</li><li class="paginager_container__pager_deactive__Gjmav">&gt;</li><a class="paginager_container__pager__GaEzu" href="/tag/NLP/1"><li class="paginager_container__pager__page__2YOZs">&gt;&gt;</li></a></ul></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET/1">COMET</a><a class="tags_container__link__1Ts3a" href="/tag/commonsense/1">commonsense</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/Contrasive%20Learning/1">Contrasive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/DST/1">DST</a><a class="tags_container__link__1Ts3a" href="/tag/empathetic%20dialogue%20system/1">empathetic dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/encyclopedic/1">encyclopedic</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Gating%20Mechanism/1">Gating Mechanism</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/Highway%20Transformer/1">Highway Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection/1">humor detection</a><a class="tags_container__link__1Ts3a" href="/tag/Internet-Augmented/1">Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/KC-Net/1">KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/knowledge-base/1">knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/Knowledge-Intensive%20NLP/1">Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/laughter/1">laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20health/1">mental health</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20state%20knowledge/1">mental state knowledge</a><a class="tags_container__link__1Ts3a" href="/tag/mentalisation/1">mentalisation</a><a class="tags_container__link__1Ts3a" href="/tag/MentalRoBERTa/1">MentalRoBERTa</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/MT/1">MT</a><a class="tags_container__link__1Ts3a" href="/tag/Multi-Hop%20Transformer/1">Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/multi-modal/1">multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLI/1">NLI</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/persona/1">persona</a><a class="tags_container__link__1Ts3a" href="/tag/PLMKE/1">PLMKE</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Prompt-Tuning/1">Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/Self-Dependency-Units%20(SDU)/1">Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/shared%20laughter/1">shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey/1">survey</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/transformer/1">transformer</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"TaggedPostData":[{"contentHtml":"\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media\u003c/p\u003e\n\u003cp\u003e研究会: Information Processing \u0026#x26; Management\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: COMET, mental health, NLP, mental state knowledge, mentalisation, Contrasive Learning, MentalRoBERTa, KC-Net\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://www.sciencedirect.com/science/article/pii/S0306457322000796\"\u003ehttps://www.sciencedirect.com/science/article/pii/S0306457322000796\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDOI: \u003ca href=\"https://doi.org/10.1016/j.ipm.2022.102961\"\u003ehttps://doi.org/10.1016/j.ipm.2022.102961\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット: Depression_Mixed, Dreaddit, SQuAD\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-mental-state-Knowledge%E2%80%93aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media/asccglgh.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e上の流れで学習して，メンタル状態を外部知識のEmbeddingを利用しながら捉える\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eData Preprocessing\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003enltk sentence tokenizerを使ってpostを文区切にする\n\u003cul\u003e\n\u003cli\u003e→文ごとのmental stateを捉えるため\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eContext-aware post (CAP) encoder\nRoBERTaをdomain-specificなデータで学習した\u003cstrong\u003eMentalRoBERTa\u003c/strong\u003eなるものがあるのでそれを使って，context-awareなエンコーダとして使用する\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eMental satte knowledge infusion\nmental stateの知識を捉えるため，ATOMICで学習されたGPTベースのCOMETを使用する\u003c/p\u003e\n\u003cp\u003e理由：\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e↑mental stateとmental health conditionの関係を捉えるために，ConceptNetではなくATOMICで学習されたものを使った\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eConceptNet：一般的な言語の概念を含む\u003c/li\u003e\n\u003cli\u003eATOMIC：human interactionを捉えたcommonsenseを含む\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eFeature extraction\n以下の5つのaspectを使用した\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eintent of S\u003c/li\u003e\n\u003cli\u003eeffect on S\u003c/li\u003e\n\u003cli\u003ereaction of S\u003c/li\u003e\n\u003cli\u003eeffect on others\u003c/li\u003e\n\u003cli\u003ereaction of others\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e面白ポイント：COMETのlm_headを削除し，Transformerの内部のみをEncoderとして扱う\u003c/strong\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e直接的にpost representationをモデルに統合できて，mental-related variablesを適応することが期待できる\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-code\"\u003e\tCAP embeddingsによるtoken-level representationは，max poolingによってsentence-level representationとされる\n\u003c/span\u003e\n\u003cspan class=\"hljs-code\"\u003e\t$\\hat{H}_j^i = max\\_pooling(H[P_{j-1}^i : P_j^i])$\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e2.\u003c/span\u003e Knowledge-aware mentalisation\n\u003cspan class=\"hljs-code\"\u003e\t5つの独立したGRUを使用して，mentalのaspect毎に学習するスタイル\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eこれでpost-level representationになる\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-arduino\"\u003e\tその後GRUによるmental aspectごとのpost-level representationとmax poolingされたsentence-level representationをAttentionすることで統合する\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eSupervised contrasive learning\nより文章のsemantic meaningに注意して学習するために，contrasive learningを使用した\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-mental-state-Knowledge%E2%80%93aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media/9nzqkqxg.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-mental-state-Knowledge%E2%80%93aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media/u6fwk2ku.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003emental state knolwedgeを使うことでスピーカー（実験ではpostした人）のmental stateを明示的にモデル化する\u003c/li\u003e\n\u003cli\u003emodel state knowledgeを理解し，使うモデルの能力を強くするため，knowledge-aware dot-product attentionに基づくmentalisation moduleを導入\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e評価方法\u003c/h2\u003e\n\u003cp\u003ebaseline\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCNN\u003c/li\u003e\n\u003cli\u003eGRU\u003c/li\u003e\n\u003cli\u003eBiLSTM_Attn\u003c/li\u003e\n\u003cli\u003eLR+Features (Logistic Regression)\u003c/li\u003e\n\u003cli\u003eEMO_INF\u003c/li\u003e\n\u003cli\u003eBERT\u003c/li\u003e\n\u003cli\u003eRoBERTa\u003c/li\u003e\n\u003cli\u003eMentalRoBERTa\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePrecision / Recall / F1を比較\u003c/p\u003e\n\u003ch2\u003e何がすごかった？\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-mental-state-Knowledge%E2%80%93aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media/82djhuwa.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-mental-state-Knowledge%E2%80%93aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media/9rsi0ppo.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003elabel情報を完全に利用するためのsupervised contrasive learningを使用することでclass-specificな特徴量を捉える必要性を議論\u003c/li\u003e\n\u003cli\u003eSOTAモデル on three stress and depression detection datasets\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e次に読みたい論文\u003c/h2\u003e\n\u003cp\u003eCEM: Commonsense-aware Empathetic Response Generation\u003c/p\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e@article{YANG2022102961,\ntitle = {A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media},\njournal = {Information Processing \u0026#x26; Management},\nvolume = {59},\nnumber = {4},\npages = {102961},\nyear = {2022},\nissn = {0306-4573},\ndoi = {\u003ca href=\"https://doi.org/10.1016/j.ipm.2022.102961\"\u003ehttps://doi.org/10.1016/j.ipm.2022.102961\u003c/a\u003e},\nurl = {\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S0306457322000796\"\u003ehttps://www.sciencedirect.com/science/article/pii/S0306457322000796\u003c/a\u003e},\nauthor = {Kailai Yang and Tianlin Zhang and Sophia Ananiadou},\nkeywords = {Mental health, Natural language processing, Mental state knowledge, Mentalisation, Contrastive learning},\nabstract = {Stress and depression detection on social media aim at the analysis of stress and identification of depression tendency from social media posts, which provide assistance for the early detection of mental health conditions. Existing methods mainly model the mental states of the post speaker implicitly. They also lack the ability to mentalise for complex mental state reasoning. Besides, they are not designed to explicitly capture class-specific features. To resolve the above issues, we propose a mental state Knowledge–aware and Contrastive Network (KC-Net). In detail, we first extract mental state knowledge from a commonsense knowledge base COMET, and infuse the knowledge using Gated Recurrent Units (GRUs) to explicitly model the mental states of the speaker. Then we propose a knowledge–aware mentalisation module based on dot-product attention to accordingly attend to the most relevant knowledge aspects. A supervised contrastive learning module is also utilised to fully leverage label information for capturing class-specific features. We test the proposed methods on a depression detection dataset Depression_Mixed with 3165 Reddit and blog posts, a stress detection dataset Dreaddit with 3553 Reddit posts, and a stress factors recognition dataset SAD with 6850 SMS-like messages. The experimental results show that our method achieves new state-of-the-art results on all datasets: 95.4% of F1 scores on Depression_Mixed, 83.5% on Dreaddit and 77.8% on SAD, with 2.07% average improvement. Factor-specific analysis and ablation study prove the effectiveness of all proposed modules, while UMAP analysis and case study visualise their mechanisms. We believe our work facilitates detection and analysis of depression and stress on social media data, and shows potential for applications on other mental health conditions.}\n}\u003c/p\u003e\n\u003c/blockquote\u003e","Title":"【論文まとめ】A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media","Date":"2023-05-21","Category":"論文","Tags":["COMET","mental health","NLP","mental state knowledge","mentalisation","Contrasive Learning","MentalRoBERTa","KC-Net"],"Authos":"ゆうぼう","Slug":"A-mental-state-Knowledge–aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media","Thumbnail":"/images/thumbnails/A-mental-state-Knowledge–aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media.png","Description":"A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social mediaのまとめ","Published":true},{"contentHtml":"\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models\u003c/p\u003e\n\u003cp\u003e研究会: arxiv\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: survey, NLP, knowledge-base, PLMKE, commonsense, encyclopedic, Knowledge-Intensive NLP\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://arxiv.org/pdf/2202.08772.pdf\"\u003ehttps://arxiv.org/pdf/2202.08772.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDOI: \u003ca href=\"https://doi.org/10.48550/arXiv.2202.08772\"\u003ehttps://doi.org/10.48550/arXiv.2202.08772\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003cp\u003eまとめること\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eKnowledge-Intensive NLPの概要\u003c/li\u003e\n\u003cli\u003eKnowledge Sources\n\u003col\u003e\n\u003cli\u003eEncyclopedic Knowledge\u003c/li\u003e\n\u003cli\u003eCommonsense Knowledge\u003c/li\u003e\n\u003cli\u003e最近のKnowledge Sourcesの特徴\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Task\n\u003col\u003e\n\u003cli\u003eKnowledge-Intensive NLP Taskの概要\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Taskの特徴\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge Fusion Methodsについて\n\u003col\u003e\n\u003cli\u003ePre-Fusion Methods\u003c/li\u003e\n\u003cli\u003ePost-Fusion Methods\u003c/li\u003e\n\u003cli\u003eHybrid-Fusion Methods\u003c/li\u003e\n\u003cli\u003e代表的なモデルの紹介\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eChallengingなことと今後の方向性\n\u003col\u003e\n\u003cli\u003eUnified PLMKEs Across Tasks and Domains\u003c/li\u003e\n\u003cli\u003eReliability of Knowledge Sources\u003c/li\u003e\n\u003cli\u003eReasoning Module Design\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e事前学習済みモデルにより，モデルのcapacityは増加傾向にあるが，encyclopedicやcommonsenseを用いた，knowledgeableなNLPモデルの需要の高まりが生じている\u003c/p\u003e\n\u003cp\u003e**PLMKEs (Pre-trained Language Model-based Knowledge-Enhanced models)**についてまとめたsurvey論文\u003c/p\u003e\n\u003cp\u003elinguistic or factual knowledgeは暗示的にモデルのパラメータに保存される\u003c/p\u003e\n\u003cp\u003e→事前学習済みのNLPモデルがより汎用的な能力を持つことを一部ではあるが説明できる\u003c/p\u003e\n\u003cp\u003e今のpre-trained LMは，明示的なencyclopedicやcommonsenseのレバレッジ能力に欠けている\u003c/p\u003e\n\u003cp\u003ePLMKEsは，関連する外部知識を取り出すモジュールと知識を混ぜるモジュールがある\u003c/p\u003e\n\u003cp\u003ePLMKEsに関連した重要な3つの要素がある\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eKnowledge Sources\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Tasks\u003c/li\u003e\n\u003cli\u003eKnowledge Fusion Methods\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eKnowledge Sources\u003c/h2\u003e\n\u003ch3\u003eEncyclopedic knowledge\u003c/h3\u003e\n\u003cp\u003eエンティティに関する属性とエンティティ間の関係性をもった知識\u003c/p\u003e\n\u003cp\u003eEntity: person → Attributes: age → Relations: educated at\u003c/p\u003e\n\u003cp\u003eWikipediaは大量のencyclopedicな知識を持っている\u003c/p\u003e\n\u003cp\u003e人物の経歴やイベントの背景などを含んでいる\u003c/p\u003e\n\u003cp\u003e一般的にはtripletsで構成されていることが多い\u003c/p\u003e\n\u003cp\u003ee.g. \u0026#x3C;Tom Hanks, occupation, actor\u003e\u003c/p\u003e\n\u003cp\u003eWikidataのような知識データがPLMKEsに広く使用されている\u003c/p\u003e\n\u003ch3\u003eCommonsense Knowledge\u003c/h3\u003e\n\u003cp\u003e日常生活のなかでの状況に関する知識\u003c/p\u003e\n\u003cp\u003eイベントとその影響を記す\u003c/p\u003e\n\u003cp\u003ee.g. mop up the floor if we split food over it / study hard to win scholarship / goat has four legs\u003c/p\u003e\n\u003cp\u003ecommonsenseの特徴\u003c/p\u003e\n\u003cp\u003e多くの人の間で共有されている知識であり，コミュニケーションの中で暗示的に想定されている知識である\u003c/p\u003e\n\u003cp\u003ecommonsenseもtripletsで表現される\u003c/p\u003e\n\u003cp\u003e最近のPLMKEsでは，ConceptNetとATOMICが外部知識として使用されることが多い\u003c/p\u003e\n\u003ch3\u003eKnowledge Sourcesの特徴\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/gcgqsmdk.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003elarge-scaleでdiverse\u003c/p\u003e\n\u003cp\u003e現在のソースはより正確で安定的に作られている\u003c/p\u003e\n\u003cp\u003eアノテーションのプロセスは部分的に自動化されていて，非エキスパートにもaccessibleになっている\u003c/p\u003e\n\u003cp\u003e知識データがカバーするドメインは多様\u003c/p\u003e\n\u003cp\u003eオープンドメインのものもあれば，specificなドメインのものも\u003c/p\u003e\n\u003cp\u003eWikipedia, DBPedia, Freebaseなどはオープンドメイン\u003c/p\u003e\n\u003cp\u003eUMLSやAMinerなどはbiomedicineやscienceの特定ドメイン\u003c/p\u003e\n\u003cp\u003edomain-specificなアプリケーションをブーストできる知識\u003c/p\u003e\n\u003cp\u003ecommonsenseに関しては\u003c/p\u003e\n\u003cp\u003eConceptNetやTransOMCSは複数のドメインのcommonsenseをカバー\u003c/p\u003e\n\u003cp\u003eATOMICやASERはある特定のタイプのcommonsenseにフォーカスした知識ソース\u003c/p\u003e\n\u003ch2\u003eKnowledge-Intensive NLP Task\u003c/h2\u003e\n\u003ch3\u003e概要\u003c/h3\u003e\n\u003cp\u003eKnowledge-intensive NLP taskは必要とする知識ソースの種類で2つに分けられ，さらに詳細に分けることができる\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/ju1lqjam.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eencyclopedic knowledge-intensive NLP task\nencyclopedicの知識ソースを利用する\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eopen-domain QA\u003c/li\u003e\n\u003cli\u003efact verification\u003c/li\u003e\n\u003cli\u003eentity linking\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/kr89pm58.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ecommonsense knowledge-intensive NLP task\ncommonsenseの知識ソースを利用する\u003c/p\u003e\n\u003cp\u003ecommonsenseの多様性のために，タスクのタイプ自体も多様化している\u003c/p\u003e\n\u003cp\u003eモデルが正確に日常のシナリオを理解し，応答するか否かのテストにフォーカスしたタスク\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGeneral Commonsense\u003c/li\u003e\n\u003cli\u003eSocial Commonsense\u003c/li\u003e\n\u003cli\u003ePhysical Commonsense\u003c/li\u003e\n\u003cli\u003eTemporal Commonsense\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eKnowledge-Intensive Taskの特徴\u003c/h3\u003e\n\u003cp\u003e実際は，モデルにとってだけではなく，人間にとってもいかなる知識の参照なしに問題に答えるのは難しい．（バラクオバマの誕生日はいつ？など\u003c/p\u003e\n\u003cp\u003eしかも，外部知識が必要なのにinputとして必要な外部知識が渡されないため，とてもチャレンジングなタスクになっている\u003c/p\u003e\n\u003cp\u003eそもそも必要な外部知識にグラウンディングするモジュールをPLMKEsの設計に加えることを考慮するようになっている\u003c/p\u003e\n\u003ch2\u003eKnowledge Fusion Methods\u003c/h2\u003e\n\u003cp\u003eモデルが知識を統合するステージは二箇所あり，\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePre-fusion; pre-training\u003c/li\u003e\n\u003cli\u003ePost-fusion; fine-tuning\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eの二通りが考えられる（もしくはその両方のステージ\u003c/p\u003e\n\u003ch3\u003ePre-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/z4lvh39q.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epre-trainingのステージで知識を統合する手法\u003c/p\u003e\n\u003cp\u003eモデルに知識を入力するため，構造化された知識データを非構造化データのテキストコーパスへと処理→モデルに入力\u003c/p\u003e\n\u003cp\u003eテキストデータとして知識を入力するため，大きくモデルのアーキテクチャを変更する必要はない\u003c/p\u003e\n\u003cp\u003eただし，知識グラフのような構造化データを非構造化データへ変えることは難しいこともある\u003c/p\u003e\n\u003cp\u003e簡単な対処法はエンティティと関係性を結合するか，流暢な文章をconditional text generation modelに生成させるか\u003c/p\u003e\n\u003cp\u003eZhang et al. 2019 | Agarwal et al. 2021 を参照（必要になれば読む\u003c/p\u003e\n\u003ch3\u003ePost-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/bshr899d.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eまず，関連知識をキャプチャする\u003c/p\u003e\n\u003cp\u003e次に取得した関連知識をGNNなどのエンコーダでembeddingを得る\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eそれを追加特徴量としてpre-trained LMに与える（図でいうA）\u003c/li\u003e\n\u003cli\u003e直接pre-trained LMに入力する（図でいうB）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHybrid-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/1yg24grj.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epre-trainingとfine-tuningの両方のステージで知識を統合する\u003c/p\u003e\n\u003cp\u003e追加の学習されるretrieverによりaugmentされたpre-trained modelは，fine-tuningのステージでより効果的にretrieverからの知識を活用できる\u003c/p\u003e\n\u003cp\u003eretrieval-augmented pre-trainingでhybrid-fusionが広く使われている\u003c/p\u003e\n\u003ch3\u003e代表的なモデル\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/xh93uokd.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/cl36oka6.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eTable4/5はSOTAモデルを示す\u003c/p\u003e\n\u003cp\u003eencyclopedic knowledge-intensive taskにおいては，BOOLQをのぞき，全てpost-fusionを採用\u003c/p\u003e\n\u003cp\u003ecommonsense knowledge-intensive taskにおいては，CommonsenseQAをのぞき，全てpre-fusionを採用\u003c/p\u003e\n\u003cp\u003epre-fusionとpost-fusionの違いは何？\u003c/p\u003e\n\u003cp\u003epre-fusionは，知識を事前学習のパラメータに暗示的に保存数る\u003c/p\u003e\n\u003cp\u003e最終的にどの知識がパラメータに保存するのかを決定するのは難しい\u003c/p\u003e\n\u003cp\u003e知識の引き出しや利用の難しさが増す\u003c/p\u003e\n\u003cp\u003epost-fusionは，明示的で具体的なテキストの知識を推論できる\u003c/p\u003e\n\u003cp\u003epost-fusionの利点は，commonsense knolwedge-intensive taskでは欠点になりうる\u003c/p\u003e\n\u003cp\u003ecommonsenseはたいていテキストの中に暗示的に置かれていて，commonsenseの知識ソースのカバー範囲はencyclopedicの知識ソースのカバー範囲に比べればとても小さい\u003c/p\u003e\n\u003cp\u003elarge-scaleなcommonsenseのソースの利用がたとえ有用だとしても，日常生活で使われる大半のcommonsenseを見落としがちなまま\u003c/p\u003e\n\u003cp\u003e→commonsenseにおいて，post-fusionがあまり効かないのはそのためなのでは？\u003c/p\u003e\n\u003ch2\u003eChallenges and Future Directions\u003c/h2\u003e\n\u003ch3\u003eUnified PLMKEs Across Tasks and Domains\u003c/h3\u003e\n\u003cp\u003etask-specificなモデリングでは進展がある\u003c/p\u003e\n\u003cp\u003epost-fusionとhybrid-fusionはencyclopedicで適用されているが，commonsenseでは採用できておらず恩恵が得られていない\u003c/p\u003e\n\u003cp\u003e異なるタスク間でのPLMKEsはユニークであるため，各タスク間で互換性がない\u003c/p\u003e\n\u003cp\u003ebiomedicalやlegalの知識に関するknowledge-intensive NLP taskまで拡張されている\u003c/p\u003e\n\u003cp\u003e最近では，異なる時間や地域に存在する知識の多様性に対しても重要度を割り当てている\u003c/p\u003e\n\u003cp\u003eタスク間やdomain間でのunified PLMKEsの必要性がましている\u003c/p\u003e\n\u003ch3\u003eReliability of Kowledge Sources\u003c/h3\u003e\n\u003cp\u003e知識ソースの信頼性に関して\u003c/p\u003e\n\u003cp\u003e多くのlarge-scaleな知識ソースは自動的な知識獲得アルゴリズムで構築されている\u003c/p\u003e\n\u003cp\u003e→スケールと正確性はトレードオフになってしまう\u003c/p\u003e\n\u003cp\u003ePLMKEsにおけるバイアスの増幅はバイアスのある知識ソースによって構築されてしまう\u003c/p\u003e\n\u003cp\u003e知識獲得アルゴリズムの見直しや使う前の知識ソースの注意深い精査が必要である\u003c/p\u003e\n\u003ch3\u003eReasoning Module Design\u003c/h3\u003e\n\u003cp\u003eReasoningはknowledge-intensive NLP taskを解く上で重要なステップである\u003c/p\u003e\n\u003cp\u003ecommonsenseを考えるときは手順を踏んで，複雑な状況を把握する\u003c/p\u003e\n\u003cp\u003ee.g. \u003c/p\u003e\n\u003cp\u003eまず，床が綺麗でないことを把握\u003c/p\u003e\n\u003cp\u003eこぼした食べ物を踏んで他の人の靴が汚くなったのだろうと考える\u003c/p\u003e\n\u003cp\u003e↑上記状況を踏まえて，モップをかける意図が生まれる\u003c/p\u003e\n\u003cp\u003e人間のような日々の状況を認識する能力を獲得するには，multi-hopなreasoning moduleが必要になる（上の例みたいな形\u003c/p\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e","Title":"【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","Date":"2023-05-21","Category":"論文","Tags":["survey","NLP","knowledge-base","PLMKE","commonsense","encyclopedic","Knowledge-Intensive NLP"],"Authos":"ゆうぼう","Slug":"A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models","Thumbnail":"/images/thumbnails/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models.png","Description":"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ","Published":true},{"contentHtml":"\u003ch2\u003eコーパスとは\u003c/h2\u003e\n\u003cp\u003e**コーパス(corpus)**とは、集めた文書のことをいいます。\u003c/p\u003e\n\u003cp\u003eもともとの原義としては、ある主題とかある作者に関する文書を集めたものがコーパスと呼ばれていたそうです。\u003c/p\u003e\n\u003cp\u003e現在はもう少し広義で捉えられ、\u003cstrong\u003e文書や音声を集めたデータそのもの、あるいはデータに情報を付与して加工したもの\u003c/strong\u003eを総称してコーパスというそうです。\u003c/p\u003e\n\u003cp\u003e最近の自然言語処理のタスクの進展は、このコーパスに活用による部分が多いです。\u003c/p\u003e\n\u003ch2\u003e生コーパス(raw corpus)\u003c/h2\u003e\n\u003cp\u003e前のセクションで話したように、コーパスには加工を加えたものと、そのまま生データのものと二通り考えられました。\u003c/p\u003e\n\u003cp\u003eそこで、生データのままの文章や音声を「\u003cstrong\u003e生コーパス(raw corpus)\u003c/strong\u003e」と呼ぶことができます。\u003c/p\u003e\n\u003ch2\u003e翻訳に関するコーパスの分類\u003c/h2\u003e\n\u003cp\u003e生コーパスの中でも、その種はいくつか存在します。\nこのトピックでは機械翻訳で扱われるようなコーパスの分類についてお話します。\u003c/p\u003e\n\u003ch2\u003e#対訳コーパス／パラレルコーパス\u003c/h2\u003e\n\u003cp\u003eまずは、「\u003cstrong\u003e対訳コーパス(bilingual corpus)\u003c/strong\u003e」または「\u003cstrong\u003eパラレルコーパス(parallel corpus)\u003c/strong\u003e」です。\u003c/p\u003e\n\u003cp\u003eこの対訳コーパスとは、翻訳関係にある2言語の文書対を収集した生コーパスになります。このコーパスは、非常に貴重ではありますが、なかなか入手しにくい希少なデータです。しかし、この対訳コーパスは機械翻訳においてとても重要な知識源となっていることは確かです。\u003c/p\u003e\n\u003ch2\u003e#コンパラブルコーパス\u003c/h2\u003e\n\u003cp\u003e対訳コーパスでは、希少なコーパスであったのに対して、  「\u003cstrong\u003eコンパラブルコーパス(comparable corpus)\u003c/strong\u003e」は、しっかりとした対訳関係にないにしても、同じトピックに関して2言語の文書対のコーパスです。\u003c/p\u003e\n\u003cp\u003eコンパラブルコーパスは、対訳コーパスほどきっちりとした対訳が制約されないので、このような文書は大量に存在します。これらの文書を収集したものがコンパラブルコーパスです。\u003c/p\u003e\n\u003cp\u003e例としてわかりやすいのは、Wikipedeaでしょう。  Wikipediaでは言語リンクでつながった複数の言語でのページが存在します。これらの文書対ではきっちりとした対訳は保証されませんが、大量のデータを入手することができ、これも極めて重要な知識源となります。\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e以上がコーパスに関する簡単な説明でした。他にも均衡コーパス(balanced corpus)や注釈コーパス(annotated corpus)といった分類もあります。\u003c/p\u003e\n\u003cp\u003eここで抑えるべき重要なことは、コーパスとは広義で\u003cstrong\u003e文書や音声を集めたデータそのもの、あるいはデータに情報を付与して加工したもの\u003c/strong\u003eということでしょう。\u003c/p\u003e\n\u003cp\u003e今回は主にコーパスの説明とともに生コーパスについての説明をしていきました。実際に加工を加えたコーパスに関しては、また別の記事にしたいと思います!\u003c/p\u003e","Title":"自然言語処理(NLP)のコーパスって何なん？","Date":"2020-07-11","Category":"ML","Tags":["ML","NLP"],"Authors":"ゆうぼう","Slug":"corpus","Thumbnail":"/images/thumbnails/network.jpg","Description":"自然言語処理という機械学習のタスクにおいて「コーパス」という言葉が出てきます。そのコーパスについてお話をしていきます。","Published":true}],"tag":"NLP","categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","CSS","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"pages":1,"page":1},"__N_SSG":true},"page":"/tag/[tag]/[page]","query":{"tag":"NLP","page":"1"},"buildId":"e_TiOeLyJW3ARb99YyDQ1","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>