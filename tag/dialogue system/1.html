<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>「<!-- -->dialogue system<!-- -->」<!-- -->1<!-- -->ページ目 | <!-- -->ゆうぼうの書跡棚</title><meta name="next-head-count" content="3"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta property="og:title" content="ゆうぼうの書跡棚"/><meta property="og:type" content="website"/><meta property="og:url" content="https://yuta0306.github.io"/><meta property="og:image" content="https://yuta0306.github.io/images/default.png"/><meta property="og:site_name" content="ゆうぼうの書跡棚"/><meta property="og:description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/a39e83d25d04c417.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a39e83d25d04c417.css" data-n-g=""/><link rel="preload" href="/_next/static/css/71fbbc4c2f48f099.css" as="style"/><link rel="stylesheet" href="/_next/static/css/71fbbc4c2f48f099.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/tag/%5Btag%5D/%5Bpage%5D-f9e21eb9aa12ee31.js" defer=""></script><script src="/_next/static/XJVBWgBTuTpSxei-rsm8E/_buildManifest.js" defer=""></script><script src="/_next/static/XJVBWgBTuTpSxei-rsm8E/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><h1 class="header_header__title__uoTF0">ゆうぼうの書跡棚</h1></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"><a class="header_category__item__0CmfH" href="/category/%E8%AB%96%E6%96%87/1"><li>論文</li></a><a class="header_category__item__0CmfH" href="/category/Web/1"><li>Web</li></a><a class="header_category__item__0CmfH" href="/category/JavaScript/1"><li>JavaScript</li></a><a class="header_category__item__0CmfH" href="/category/Competition/1"><li>Competition</li></a><a class="header_category__item__0CmfH" href="/category/Cloud/1"><li>Cloud</li></a><a class="header_category__item__0CmfH" href="/category/Linux/1"><li>Linux</li></a><a class="header_category__item__0CmfH" href="/category/Python/1"><li>Python</li></a><a class="header_category__item__0CmfH" href="/category/ML/1"><li>ML</li></a><a class="header_category__item__0CmfH" href="/category/Go/1"><li>Go</li></a><a class="header_category__item__0CmfH" href="/category/SQL/1"><li>SQL</li></a></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__grid__Bpzhl"><div class="card_card__container__PrCEE"><a href="/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey.png" alt="【論文まとめ】Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-22" itemProp="published">2023-05-22</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey.png" alt="【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-22" itemProp="published">2023-05-22</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/A-survey-on-empathetic-dialogue-systems"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/A-survey-on-empathetic-dialogue-systems.png" alt="【論文まとめ】A survey on empathetic dialogue systems" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-22" itemProp="published">2023-05-22</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】A survey on empathetic dialogue systems</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/%E9%81%A0%E9%9A%94%E6%93%8D%E4%BD%9C%E3%82%A2%E3%83%B3%E3%83%89%E3%83%AD%E3%82%A4%E3%83%89%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E8%AA%AC%E5%BE%97%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AE%E5%8F%8E%E9%9B%86%E3%81%A8%E5%88%86%E6%9E%90"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析.png" alt="【論文まとめ】遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/知識源との一対多関係を有する対話コーパスによる発話生成.png" alt="【論文まとめ】知識源との一対多関係を有する対話コーパスによる発話生成" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】知識源との一対多関係を有する対話コーパスによる発話生成</h2></div></div></a></div><ins class="adsbygoogle " style="display:block;border-bottom:1px dashed rgba(240, 240, 240, 0.6)" data-ad-client="ca-pub-4998278830587376" data-ad-slot="3060159795" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="card_card__container__PrCEE"><a href="/%E5%88%86%E9%A1%9E%E3%83%A2%E3%83%87%E3%83%ABBERT%E3%81%AB%E3%82%88%E3%82%8B%E4%B8%8D%E6%95%B4%E5%90%88%E7%94%9F%E6%88%90%E6%96%87%E3%81%AE%E6%A4%9C%E5%87%BA%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/分類モデルBERTによる不整合生成文の検出について.png" alt="【論文まとめ】分類モデルBERTによる不整合生成文の検出について" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】分類モデルBERTによる不整合生成文の検出について</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/Transformer%E3%81%AB%E3%82%88%E3%82%8Bhallucination-error%E3%81%AE%E4%BA%8B%E5%BE%8C%E4%BF%AE%E6%AD%A3"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/Transformerによるhallucination-errorの事後修正.png" alt="【論文まとめ】Transformerによるhallucination errorの事後修正" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】Transformerによるhallucination errorの事後修正</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/Prompt-Tuning-%E3%81%AB%E3%82%88%E3%82%8B%E5%80%8B%E6%80%A7%E3%82%92%E6%8C%81%E3%81%A3%E3%81%9F%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E6%A7%8B%E7%AF%89"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/Prompt-Tuning-による個性を持った対話システムの構築.png" alt="【論文まとめ】Prompt-Tuning による個性を持った対話システムの構築" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】Prompt-Tuning による個性を持った対話システムの構築</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/Internet-Augmented-Dialogue-Generation"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/Internet-Augmented-Dialogue-Generation.png" alt="【論文まとめ】Internet-Augmented Dialogue Generation" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】Internet-Augmented Dialogue Generation</h2></div></div></a></div><div></div><div class="paginager_container____vsL"><ul class="paginager_container__pagers__1zmK9"><a class="paginager_container__pager__GaEzu" href="/tag/dialogue%20system/1"><li class="paginager_container__pager__page__2YOZs">&lt;&lt;</li></a><li class="paginager_container__pager_deactive__Gjmav">&lt;</li><li class="paginager_container__pager_active__k3Sib">1</li><li class="paginager_container__pager_deactive__Gjmav">&gt;</li><a class="paginager_container__pager__GaEzu" href="/tag/dialogue%20system/1"><li class="paginager_container__pager__page__2YOZs">&gt;&gt;</li></a></ul></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET/1">COMET</a><a class="tags_container__link__1Ts3a" href="/tag/commonsense/1">commonsense</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/Contrasive%20Learning/1">Contrasive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/DST/1">DST</a><a class="tags_container__link__1Ts3a" href="/tag/empathetic%20dialogue%20system/1">empathetic dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/encyclopedic/1">encyclopedic</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Gating%20Mechanism/1">Gating Mechanism</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/Highway%20Transformer/1">Highway Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection/1">humor detection</a><a class="tags_container__link__1Ts3a" href="/tag/Internet-Augmented/1">Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/KC-Net/1">KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/knowledge-base/1">knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/Knowledge-Intensive%20NLP/1">Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/laughter/1">laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20health/1">mental health</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20state%20knowledge/1">mental state knowledge</a><a class="tags_container__link__1Ts3a" href="/tag/mentalisation/1">mentalisation</a><a class="tags_container__link__1Ts3a" href="/tag/MentalRoBERTa/1">MentalRoBERTa</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/MT/1">MT</a><a class="tags_container__link__1Ts3a" href="/tag/Multi-Hop%20Transformer/1">Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/multi-modal/1">multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLI/1">NLI</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/persona/1">persona</a><a class="tags_container__link__1Ts3a" href="/tag/PLMKE/1">PLMKE</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Prompt-Tuning/1">Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/Self-Dependency-Units%20(SDU)/1">Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/shared%20laughter/1">shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey/1">survey</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/transformer/1">transformer</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"TaggedPostData":[{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey\u003c/p\u003e\n\u003cp\u003e研究会: ACL SIGDIAL\u003c/p\u003e\n\u003cp\u003e年度: 2021\u003c/p\u003e\n\u003cp\u003eキーワード: dialogue system, survey, DST\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://aclanthology.org/2021.sigdial-1.25.pdf\"\u003ehttps://aclanthology.org/2021.sigdial-1.25.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003cp\u003eData State Tracking (以下DST) on Task-Oriented Dialogue Systemに焦点を当てたsurvey\u003c/p\u003e\n\u003ch2\u003eAbstract\u003c/h2\u003e\n\u003cp\u003e触れること\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eタスク\u003c/li\u003e\n\u003cli\u003eデータセット\u003c/li\u003e\n\u003cli\u003eevaluation metrics\u003c/li\u003e\n\u003cli\u003eアプローチ\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e本論文では，二つのDSTモデルをしっかり区別する．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003estatic ontology DST models\n\u003cul\u003e\n\u003cli\u003e固定された対話状況集合を予測する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003edynamic ontology DST models\n\u003cul\u003e\n\u003cli\u003eオントロジーが変化した時でも対話状況を予測する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDefinition of ontology\u003c/p\u003e\n\u003cp\u003ea set of concepts and categories in a subject area or domain that shows their properties and the relations between them.\u003c/p\u003e\n\u003cp\u003e単一ドメインでも複数ドメインでもトラックすることや新しいドメインにスケーリングすることのモデルの性能について議論する\u003c/p\u003e\n\u003cp\u003eTerms: knowledge transfer, zero-shot learning\u003c/p\u003e\n\u003cp\u003eカバーしている年代は2013~2020\u003c/p\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eTask-oriented dialogue system:\u003c/p\u003e\n\u003cp\u003eユーザーがタスクを成し遂げるようにするシステム\u003c/p\u003e\n\u003cp\u003eチケット予約，レストラン予約，カスタマーサポートなど\u003c/p\u003e\n\u003cp\u003eユーザの要求を正確にトラッキングする性能は，一貫していて効果的な対話を可能にする\u003c/p\u003e\n\u003cp\u003e対話状況をslot-valueで表現するDSTコンポーネントを使った情報をトラッキングする\u003c/p\u003e\n\u003cp\u003e↑この精度がとても重要で，下流のコンポーネントがこの状況を利用して，次のactionを決定する\u003c/p\u003e\n\u003cp\u003eDSTタスクは，実際Natural Language Understanding (以下NLU)のタスクを統合している\u003c/p\u003e\n\u003cp\u003eただし，単なるslot filling taskよりも複雑になっている\u003c/p\u003e\n\u003cp\u003eDST\u003c/p\u003e\n\u003cp\u003e現在のturnまで，対話レベルでslot-valueを予測\u003c/p\u003e\n\u003cp\u003eSlot Filling\u003c/p\u003e\n\u003cp\u003e特定のturnのみ考慮してslot-valueを予測すれば良い\u003c/p\u003e\n\u003cp\u003eモデルとしては以下が提案されている\u003c/p\u003e\n\u003cp\u003eRNN-based models\u003c/p\u003e\n\u003cp\u003eAttention-based models\u003c/p\u003e\n\u003cp\u003eTransformer-based models\u003c/p\u003e\n\u003cp\u003eここ最近では，単一ドメインではなく，マルチドメインやflexibleにドメインの移行をするモデリングの研究が盛んらしい\u003c/p\u003e\n\u003ch2\u003eDialogue State Tracking\u003c/h2\u003e\n\u003cp\u003eそもそもDSTとは\u003c/p\u003e\n\u003ch3\u003eDialogue State\u003c/h3\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eS\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eS_t\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eS\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e: dialogue state\u003c/p\u003e\n\u003cp\u003e→turn \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e までにおける対話履歴のsummary\u003c/p\u003e\n\u003cp\u003e次の行動を決定するための全ての十分な情報を含んでいる\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e   : turn\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003el\u003c/mi\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003el\u003c/mi\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e(slot, value)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.01968em;\"\u003el\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eo\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.01968em;\"\u003el\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e: このペアで，ユーザの目的を捉える\u003c/p\u003e\n\u003cp\u003eslotはOntology \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eO\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eO\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eO\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e の中で事前に定義されていて (ドメイン依存であるが)，\u003c/p\u003e\n\u003cp\u003evalueはユーザによって与えられた各スロット \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003es\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e で決められる\u003c/p\u003e\n\u003cp\u003eレストランの例で言えば\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e{\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eF\u003c/mi\u003e\u003cmi\u003eO\u003c/mi\u003e\u003cmi\u003eO\u003c/mi\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eI\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmi\u003eI\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eR\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003cmi\u003eR\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e}\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_t = \\{(FOOD, ITALIAN), (AREA, CENTRE)\\}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e{(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eFOO\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07847em;\"\u003eI\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07847em;\"\u003eI\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eRE\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eCENTRE\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)}\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eのようになる\u003c/p\u003e\n\u003cp\u003eslotのタイプは二つ\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003einformable\n対話から得られる→FOODやAREA\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003erequestable\nシステムが与える→ADRRESSやPHONE\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eDialogue State Tracker\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eturn-level prediction\n各ターンで与えられるslot-valueを予測\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003edialogue-level prediction\n各ターンでの完全な対話状況を予測\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eTurn-level prediction\u003c/h3\u003e\n\u003cp\u003e直近のturn \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e からslot-valueを予測する\u003c/p\u003e\n\u003cp\u003erule-basedの場合は，そのルールに従って，\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_{t-1}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eに統合して\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_t\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eを得る\u003c/p\u003e\n\u003cp\u003eturn \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e を優先したり，\u003c/p\u003e\n\u003cp\u003e確率を利用して統合したり\u003c/p\u003e\n\u003cp\u003elearning to updateの場合は，turn-levelの予測を入力として，対話状況を予測する方法を学習する\u003c/p\u003e\n\u003ch3\u003eDialogue level prediction\u003c/h3\u003e\n\u003cp\u003e各turn \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e において，完全な対話履歴を入力として，完全な対話状況 \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_t\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e を予測する\u003c/p\u003e\n\u003cp\u003e直前の対話状況 \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_{t-1}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e を考慮しないため，\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_{t-1}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eと\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_t\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eに一貫性がないこともある\u003c/p\u003e\n\u003ch2\u003eDatasets\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey/p9w4y463.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDialog State Tracking Challenge (DSTC)\u003c/li\u003e\n\u003cli\u003eDSTC2 and DSTC3\u003c/li\u003e\n\u003cli\u003eWoZ2.0\u003c/li\u003e\n\u003cli\u003eMultiWoZ\u003c/li\u003e\n\u003cli\u003eSchema-Guided Dataset (SGD)\u003c/li\u003e\n\u003cli\u003eTreeDST\u003c/li\u003e\n\u003cli\u003eMachine-to-Machine (M2M)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eEvaluation Metrics\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAverage Goal Accuracy\u003c/li\u003e\n\u003cli\u003eJoint Goal Accuracy\u003c/li\u003e\n\u003cli\u003eRequested  Slots F1\u003c/li\u003e\n\u003cli\u003eTime Complexity\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eStatic Ontology DST Models\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey/qegkxt8s.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eslot-valueは事前に定義されている\u003c/p\u003e\n\u003cp\u003e→\u003c/p\u003e\n\u003cp\u003eoutput layerは\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efeed-forward layer\n- slotとvalueが固定なので，それらはembeddingされているため可能\u003c/li\u003e\n\u003cli\u003esoftmax\n- 全てのslot-valueのペアの確率を求める\u003c/li\u003e\n\u003cli\u003esigmoid\n- それぞれのslot-valueの確率を求める\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eDelexicalization\u003c/h3\u003e\n\u003cp\u003eimbalanced training data for slot-valuesに対処する効果的なアプローチ\u003c/p\u003e\n\u003cp\u003e入力のslot valuesをラベルの名前に置き換える\u003c/p\u003e\n\u003cp\u003eI want Chinese food.\u003c/p\u003e\n\u003cp\u003e→ I want F.VALUE F.SLOT.\u003c/p\u003e\n\u003ch3\u003eData-driven DST\u003c/h3\u003e\n\u003cp\u003edelexicalizationは確かに効果的だが，手作業でのfeature engineeringが必要になる\u003c/p\u003e\n\u003cp\u003e→ data-drivenな手法が提案された\u003c/p\u003e\n\u003ch3\u003eParameter sharing\u003c/h3\u003e\n\u003cp\u003e昔のモデルはslotごとにエンコーダが分かれていた\u003c/p\u003e\n\u003cp\u003e→そのため全てのslotに対してパラメータを共有する手法が提案された\u003c/p\u003e\n\u003cp\u003eStateNet？\u003c/p\u003e\n\u003ch3\u003eRNN and latency in DST\u003c/h3\u003e\n\u003cp\u003e予測時間が問題だったため，それに対する対策の提案\u003c/p\u003e\n\u003ch3\u003eEncoder based on pre-trained LM\u003c/h3\u003e\n\u003cp\u003eBERTなどを使うことで，捕捉できるslot valueが増えた\u003c/p\u003e\n\u003ch2\u003eDynamic Ontology DST Models\u003c/h2\u003e\n\u003cp\u003eオントロジーが事前定義されていなくてもslot-valueをトラッキングする必要がある\u003c/p\u003e\n\u003cp\u003eアプローチは2種\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eユーザの入力からslot-valueをコピー\u003c/li\u003e\n\u003cli\u003eoutputにslot-valueを生成\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下図は2種のアプローチを合わせたアーキテクチャ\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey/l30un8m9.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003estatic ontology vs dynamic ontology\u003c/p\u003e\n\u003cp\u003estaticだとvalueが有限だが，\u003c/p\u003e\n\u003cp\u003edynamicだとoutputの語彙数がとても大きくなる\u003c/p\u003e\n\u003ch3\u003eCopy and pointer networks\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey/7vvgrpy7.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003ecopy mechanismとpointer networkがメインのアプローチ\u003c/p\u003e\n\u003cp\u003eどちらもattention-based\u003c/p\u003e\n\u003cp\u003eXu氏とHu氏が提案したpointer networkベースのアーキテクチャだと，すべてのslotには適用できず，postprocessingが必要だった\u003c/p\u003e\n\u003cp\u003e→ Wu氏がTRADEというモデルを提案\u003c/p\u003e\n\u003cp\u003e全てのslotとdomainに関する全てのパラメータを共有していて，domain transferができるらしい\u003c/p\u003e\n\u003cp\u003ezero-shotアプローチと言える\u003c/p\u003e\n\u003ch3\u003eCategorical and non-categorical slot-values\u003c/h3\u003e\n\u003cp\u003enon-categoricalなslotは，オープンなvalue集合を受け入れることができる\u003c/p\u003e\n\u003cp\u003eZhang氏が提案した手法によれば\u003c/p\u003e\n\u003cp\u003eもしcategoricalのラベルがついていれば，outputは事前定義されたvalueに対する確率のスコアを出力\u003c/p\u003e\n\u003cp\u003enon-categoricalであれば，outputにはinput tokenからデコードされたものを出力\u003c/p\u003e\n\u003cp\u003eHeck氏は，TripPy (triple copy strategy)を提案\u003c/p\u003e\n\u003cp\u003eシナリオに応じてslot-valueを予測する\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eユーザに明示的に示された\u003c/li\u003e\n\u003cli\u003eシステムに示され，ユーザによって言及された\u003c/li\u003e\n\u003cli\u003e別のドメインのslotのために前の対話ターンにおいて示された\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eFunction-baed update\u003c/h3\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo stretchy=\"false\"\u003e{\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eR\u003c/mi\u003e\u003cmi\u003eR\u003c/mi\u003e\u003cmi\u003eY\u003c/mi\u003e\u003cmi\u003eO\u003c/mi\u003e\u003cmi\u003eV\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmi\u003eR\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003eO\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eR\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eU\u003c/mi\u003e\u003cmi\u003eP\u003c/mi\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e}\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\{CARRYOVER, DELETE, DONTCARE, UPDATE\\}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e{\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eC\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.00773em;\"\u003eRR\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eY\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eO\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.22222em;\"\u003eV\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.00773em;\"\u003eER\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eE\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eETE\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07153em;\"\u003eONTC\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eRE\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eU\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.13889em;\"\u003eP\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eTE\u003c/span\u003e\u003cspan class=\"mclose\"\u003e}\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eを使う\u003c/p\u003e\n\u003cp\u003eCARRYOVER: 前の対話状況を引き継ぐ\u003c/p\u003e\n\u003cp\u003eDELETE        : slot-valueを戻す\u003c/p\u003e\n\u003cp\u003eUPDATE       : slot-valueの予測を必要とし，対話状況を更新する\u003c/p\u003e\n\u003ch2\u003eTake-away Points\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e各スロットに多様なモデルを使うのは，汎化性能や効果的な表現を学習するのに限りがある\u003c/li\u003e\n\u003cli\u003eスロット間のパラメータシェアリングは効果的で，全てのスロットに対するパフォーマンスを改善する\u003c/li\u003e\n\u003cli\u003e大規模データセットを使うと，RNNはSOTAの性能が出る\u003c/li\u003e\n\u003cli\u003eRNNは，encoderとdecoderを両方使うと時間がかかる問題がある\u003c/li\u003e\n\u003cli\u003eattention-basedのcopying mechanismは効果的なアプローチであり，多くのSOTAモデルで採用されているアプローチ\u003c/li\u003e\n\u003cli\u003e小資源のドメインに対しては，事前学習済みの言語モデルを使用することで性能がよくなる\u003c/li\u003e\n\u003cli\u003e統計的な更新関数はルールベースの更新関数を超える性能を出す\u003c/li\u003e\n\u003cli\u003eドメインのスケーラビリティとモデルの柔軟性が問題の時，scheme-basedアプローチを使うとscheme内での変更を入れることが可能になる\n\u003col\u003e\n\u003cli\u003ezero-shotを含むtransfer learningが可能に\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eDSTモデルの大半は，事前学習済み言語モデルが使われている\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eDST Challenges and Future Directions\u003c/h2\u003e\n\u003cp\u003e現実世界の会話アプリにおいて新たなslotやdomainの追加は避けられない\u003c/p\u003e\n\u003ch3\u003eFew-shot and Zero-shot Models\u003c/h3\u003e\n\u003ch3\u003eData Augmentation and Data-efficient Models\u003c/h3\u003e\n\u003ch3\u003eDiverse Datasets\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey/3pbaksol.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e@inproceedings{balaraman-etal-2021-recent,\ntitle = \"Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey\",\nauthor = \"Balaraman, Vevake and\nSheikhalishahi, Seyedmostafa and\nMagnini, Bernardo\",\nbooktitle = \"Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue\",\nmonth = jul,\nyear = \"2021\",\naddress = \"Singapore and Online\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"\u003ca href=\"https://aclanthology.org/2021.sigdial-1.25\"\u003ehttps://aclanthology.org/2021.sigdial-1.25\u003c/a\u003e\",\npages = \"239--251\",\nabstract = \"This paper aims at providing a comprehensive overview of recent developments in dialogue state tracking (DST) for task-oriented conversational systems. We introduce the task, the main datasets that have been exploited as well as their evaluation metrics, and we analyze several proposed approaches. We distinguish between static ontology DST models, which predict a fixed set of dialogue states, and dynamic ontology models, which can predict dialogue states even when the ontology changes. We also discuss the model{'}s ability to track either single or multiple domains and to scale to new domains, both in terms of knowledge transfer and zero-shot learning. We cover a period from 2013 to 2020, showing a significant increase of multiple domain methods, most of them utilizing pre-trained language models.\",\n}\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey","Date":"2023-05-22","Category":"論文","Tags":["dialogue system","survey","DST"],"Authos":"ゆうぼう","Slug":"Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey","Thumbnail":"/images/thumbnails/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey.png","Description":"Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Surveyのまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey\u003c/p\u003e\n\u003cp\u003e研究会: arxiv\u003c/p\u003e\n\u003cp\u003e年度: 2021\u003c/p\u003e\n\u003cp\u003eキーワード: survey, dialogue system\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://arxiv.org/pdf/2105.04387.pdf\"\u003ehttps://arxiv.org/pdf/2105.04387.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ry2fz8tn.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e対話システムに関するサーベイ論文\u003c/p\u003e\n\u003cp\u003e対話システムはNLPタスクの一種\u003c/p\u003e\n\u003cp\u003e研究の価値が高いNLPタスクを多く含むため，対話システムは複雑と言える．\u003c/p\u003e\n\u003cp\u003eここ最近で良い成果をあげているもののほとんどがDL\u003c/p\u003e\n\u003cp\u003eメインは，モデルタイプとシステムタイプについて述べられる．\u003c/p\u003e\n\u003cp\u003eシステムタイプ\u003c/p\u003e\n\u003cp\u003eタスク指向型\u003c/p\u003e\n\u003cp\u003eオープンドメイン型\u003c/p\u003e\n\u003ch3\u003eKeywords\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/8575dpgt.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch3\u003eサーベイの主張の流れ\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/hpk33ao6.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003ch3\u003eIntroduction\u003c/h3\u003e\n\u003cp\u003e対話システムはNLPにおいてホットな話題であり，産業においても需要が非常に高い．\u003c/p\u003e\n\u003cp\u003eタスク指向型とオープンドメイン型の対話システムが存在する．\u003c/p\u003e\n\u003cp\u003e昔ながらのタスク指向型は，Natural Language Understanding, Dialogue State Tracking, Policy Learning, Natural Language Generationの4つからなっていた\u003c/p\u003e\n\u003cp\u003e⇒\u003c/p\u003e\n\u003cp\u003e最近のSoTAモデルでは，E2Eのタスク指向型の対話システムが多い．\u003c/p\u003e\n\u003cp\u003eオープンドメイン型\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003egenerative systems\n\u003cul\u003e\n\u003cli\u003eseq2seqなモデル\u003c/li\u003e\n\u003cli\u003eユーザのメッセージや対話履歴を返答系列にマッピングする(Trainingデータに存在しないであろうものも含む)\u003c/li\u003e\n\u003cli\u003e柔軟でコンテクストを読んだ返答をするが，時々主張が一貫しない返答や鈍感で面白くない返答を返す．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eretrieval-based systems (検索)\n\u003cul\u003e\n\u003cli\u003e返答の集合の中から，すでに存在する適した返答を探す．\u003c/li\u003e\n\u003cli\u003e表面上では良い返答をする．ただし，返答集合は有限集合なので，対話上のコンテクストに対しては関係性があまりみられないこともある．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eensemble systems\n\u003cul\u003e\n\u003cli\u003e上記二つを含む\u003c/li\u003e\n\u003cli\u003eGeneratie systemsは検索システムをよくするために使われる．\u003c/li\u003e\n\u003cli\u003e検索システムはより適した返答を選ぶために使われる．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e古典的な対話システムとして，finite state-basedとstatistical learningとmachine learning-basedが挙げられる．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFinite State-based\n\u003cul\u003e\n\u003cli\u003e対話の流れはあらかじめ決められている\u003c/li\u003e\n\u003cli\u003e決まったシナリオの中でしか対応ができない．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eStatistical Learning-based\n\u003cul\u003e\n\u003cli\u003eFinite State-basedよりは柔軟である．あらかじめ対応が決められていないから．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003emachine learning-based\n\u003cul\u003e\n\u003cli\u003eDeep learningが主流？\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNLPの中には対話システムに近い領域がある．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQ \u0026#x26; A\u003c/li\u003e\n\u003cli\u003ereading comprehension\u003c/li\u003e\n\u003cli\u003edialogue disentanglement\u003c/li\u003e\n\u003cli\u003evisual dialogue\u003c/li\u003e\n\u003cli\u003evisual Q \u0026#x26; A\u003c/li\u003e\n\u003cli\u003edialogue reasoning\u003c/li\u003e\n\u003cli\u003econversational semantic parsing\u003c/li\u003e\n\u003cli\u003edialogue relation extraction\u003c/li\u003e\n\u003cli\u003edialogue sentiment analysis\u003c/li\u003e\n\u003cli\u003ehate speech detection\u003c/li\u003e\n\u003cli\u003eMISC detection (???)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eNeural Models in Dialogue Sustems\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCNN\n\u003cul\u003e\n\u003cli\u003eここ数年NLPの分野での応用も多いらしい\u003c/li\u003e\n\u003cli\u003eフレーズや文章，パラグラフには意味づけをするのに有用でCNNがヒラルキーなモデルになる\u003c/li\u003e\n\u003cli\u003eCNNは一条に乏しいため，最近のSoTAにおいては，テキストをencoderにかけたのちにCNNを用いてヒエラルキーな特徴抽出を行っている．\u003c/li\u003e\n\u003cli\u003e欠点として入力系列の長さは固定長のため以下の使用例\n\u003cul\u003e\n\u003cli\u003eencoderの出力をCNNでベクトル化\u003c/li\u003e\n\u003cli\u003econtextと返答の候補を行列にして，CNNで近さを図ることによって，妥当な候補を選び出す\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e基本的にCNNとencoderはセットか？\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/37cmjuij.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRNN and Vanilla seq2seq\n\u003cul\u003e\n\u003cli\u003e系列として扱えるのが利点と考えるべき\u003c/li\u003e\n\u003cli\u003eHMMや古典的な系列モデルだと，推論時のアルゴリズムの複雑さや考えるべき状態空間の増大に合わせて行列サイズが大きくなりすぎて，大きな状態空間を必要とするデータには対応しがたい．\u003c/li\u003e\n\u003cli\u003eマルコフモデルは限られた条件下においては強力なモデルになりうる．\u003c/li\u003e\n\u003cli\u003eRNNは最近では提案されないが，NLPタスクにおいては未だ現役として活躍することもある\u003c/li\u003e\n\u003cli\u003eJordan-Type \u0026#x26; Elman-Type RNN\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ts6afg6g.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-graphql\"\u003e\t- Jordan-\u003cspan class=\"hljs-keyword\"\u003eType\u003c/span\u003e RNN\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/mz0mr5oj.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 最新の隠れ層の状態は，Input\u003cspan class=\"hljs-emphasis\"\u003e_tとOutput_\u003c/span\u003et-1による\n\u003cspan class=\"hljs-code\"\u003e\t\t\t\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Elman-Type RNN\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/10bbby3m.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 最新の隠れ層の状態は，Input\u003cspan class=\"hljs-emphasis\"\u003e_tとHidden_\u003c/span\u003et-1による\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e いずれにしてもシンプルなRNNは勾配消失か勾配爆発が大抵おこる\n\u003cspan class=\"hljs-code\"\u003e\t\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e LSTM\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/k21pyf3t.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Gates\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 入力ゲート\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 忘却ゲート\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 出力ゲート\n\n\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e GRU; Gated Recurrent Unit\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/fs4fug4f.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Gates\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 更新ゲート\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e リセットゲート\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e パラメータが少ないため，\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 早い\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 汎化性がみられる\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e ただし，\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 大きなデータセットには対応しきれないこともある\n\u003cspan class=\"hljs-code\"\u003e\t\t\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Bi-directional RNN\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/vrdvputk.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 双方向を考慮したRNN\n\u003cspan class=\"hljs-code\"\u003e\t\t\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e seq2seq; Encoder-Decoder model\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 初めは機械翻訳のために提案された手法\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Encoderにより入力系列をベクトル化，その隠れ状態をDecodeして生成することを目指す\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/56q5hqna.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Encode時\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e t時刻のinputとt-1時刻のhiddenによって，t時刻のhiddenが決まる\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Decode時\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e t時刻のhiddenとt-1時刻のoutputによって，t時刻のoutputをデコードする\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 入力系列と出力系列の長さが固定長である必要はない．\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e その代わり，適応させる系列長と出力される系列長は同じになることは保証されない\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eHierarchical Recurrent Encoder-Decoder; HRED\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/4s0olxfm.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-diff\"\u003e\u003cspan class=\"hljs-deletion\"\u003e- コンテクストを理解するためのseq2seqモデル\u003c/span\u003e\n\u003cspan class=\"hljs-deletion\"\u003e- クエリの履歴を理解する？\u003c/span\u003e\n\u003cspan class=\"hljs-deletion\"\u003e- トークンレベルとターンレベルで学習する\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eMemory Networks\u003c/li\u003e\n\u003cli\u003eAttention and Transformer\n\u003cul\u003e\n\u003cli\u003eAttention\u003c/li\u003e\n\u003cli\u003eTransformer\n\u003cul\u003e\n\u003cli\u003eMuti-head Attention\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePointer Net and CopyNet\n\u003cul\u003e\n\u003cli\u003ePointer Net\u003c/li\u003e\n\u003cli\u003eCopyNet\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDeep RL and GANs\n\u003cul\u003e\n\u003cli\u003eDeep Q-Networks\u003c/li\u003e\n\u003cli\u003eREINFORCE\u003c/li\u003e\n\u003cli\u003eGANs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge Graph Augmented Neural Networks\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e2章は途中から読むのやめた．使用されるネットワークよりも課題感の方が知りたい．\u003c/p\u003e\n\u003ch3\u003eタスク指向型対話システム\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/y29vzu3h.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eドメインの決まったタスクにおいて特定の問題を解決する．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNatural Language Understanding\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/1mx5wsm3.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e 3つのタスクを持つ\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e ドメイン分類\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 意図の理解\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e スロット埋め\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e IOB; Inside Outside Beginning\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e NER; Named Entity Recognition\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e intent detectionにおいては，Task-Oriented Dialogue BERTがSoTA?\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Domain classification \u0026#x26; intent detectionは同カテゴリタスク\n\n\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e slot filling task = semantic tagging\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e NLUタスクを解く際に，音声データをそのままInputとして与える研究事例も出ているらしい\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e エラーが少なくロバストなモデルになったらしい？\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Natural Language UnderstandingとNatural Language Generationは逆のプロセスをふむ\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 同時にタスクを学習結果が得られるというアプローチも\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eDialogue State Tracking\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/aao7x0r4.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e ユーザの目的と対話履歴を追跡する\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e NLUとDSTのタスクは近い関係にある．\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e NLUは単語にtagを割り振っていくイメージ\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e DSTはtagのplaceholderを会話の内容から埋めていくイメージ\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Dialogue Stateには3つの要素からなる\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Goal constraint corresponding with informable slots\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 特別なvalueの制約で，ユーザによって言及されるか特別な値をとる\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e DontcareやNoneが特別な値にあたる\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Requested slots\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Search method of current turn\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e 古典的な手法でいくと，\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e ルールベースはエラーが多く，ドメイン適応が大変\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 統計的手法はノイジーな状態や曖昧性に弱い\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e ニューラルネットな手法\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e slot-valueのペアを事前定義して学習\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e valueが大きくなると複雑性が増す\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e slot-valueのペアを読むだけでよく，2値分類タスクとして解ける\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e モデルの複雑性は避けられるが，反応速度が遅くなる可能性がある．\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e slot-valueのペアを定義せずに，対話の中から直接選ぶ\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePolicy Learning\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDSTモジュールの出力結果からどう行動をとるか\u003c/li\u003e\n\u003cli\u003e教師あり学習or 強化学習\u003c/li\u003e\n\u003cli\u003e教師ありだとアノテショーンデータセットを作るのがとても大変\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNatural Language Generation; NLG\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eタスク指向型対話システムにおける最終層のモジュール\u003c/li\u003e\n\u003cli\u003e最終的な自然言語表現を生成するシステム\u003c/li\u003e\n\u003cli\u003e4つのコンポーネントからなる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/9ybi8yfr.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Content Determination\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Sentence Planning\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Surface Realization\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Lexicalization, Referring expression, aggregation\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e RNNに基づいた統計言語モデルにおいて，意味的制約や文法構造による返答生成を行うなど\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e コンテクストを理解した返答を生成することは重要である\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e タスク指向型においては，返答の多様性というよりも信頼性のほうが重要視されがち\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e 意味解析をビームサーチを使うことで，意味の正しさを改善する手法も提案された\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eE2E Methods\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eend-to-endのパイプラインを組むことで高いパフォーマンスを発揮することがあるが，\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e多くのモジュールを組み込むため，バックプロパゲーションで誤差が伝播しないこともある．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eすべてのモジュールが，返答の精度を向上するために，対等に重要であるとは限らない．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e違うドメインに差し替えるとき，オントロジーを事前学習させる必要があるため，困難が生じることもある\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eやり方は大きく分けて2つ\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eすべてのモジュールを展開して誤差逆伝播させる？\u003c/li\u003e\n\u003cli\u003e知識ベースの検索システムと返答生成の双方を用いてパイプラインを組む\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eタスク指向型においては，外部の知識源が必要なことが多い\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eオープンドメイン型対話システム\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e雑談対話システム，或いはタスク思考型ではない対話システムのこと\u003c/li\u003e\n\u003cli\u003eSoTAを示しているオープンドメインは大抵ニューラルネットで解決している\u003c/li\u003e\n\u003cli\u003e完全なるデータドリブンなものが多い\u003c/li\u003e\n\u003cli\u003eオープンドメイン型対話システムは，大まか3つに分けられる\n\u003cul\u003e\n\u003cli\u003e生成システム\u003c/li\u003e\n\u003cli\u003e検索ベースシステム\u003c/li\u003e\n\u003cli\u003eアンサンブルシステム\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e３つの話が以下\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e生成システム\n\u003cul\u003e\n\u003cli\u003e訓練コーパスに出てこないような返答に対して，ユーザのメッセージや対話履歴をマッピングするために，seq2seqなモデルを適用する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e検索システム\n\u003cul\u003e\n\u003cli\u003e決まった返答集合の中からすでに存在する返答を探そうとする\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eアンサンブルシステム\n\u003cul\u003e\n\u003cli\u003e生成手法と検索手法を合わせる．\u003c/li\u003e\n\u003cli\u003e生成された返答と検索された返答とを比べる．\u003c/li\u003e\n\u003cli\u003e生成も，検索された返答を洗練するために用いられる．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e特徴として，\u003c/p\u003e\n\u003cp\u003e生成モデルは\u003c/p\u003e\n\u003cp\u003e柔軟でコンテクストを読んだ返答をできるが，ときには理解に欠けていたり，怠けた返答を見せることがある\u003c/p\u003e\n\u003cp\u003e検索ベースのモデルは\u003c/p\u003e\n\u003cp\u003e人の返答の集合から実際の返答を選ぶため，返答の集合は有限集合であり，コンテクストと相関がないことがある．\u003c/p\u003e\n\u003cp\u003eただし，表面上のレベルでは，首尾一貫した返答することも多い\u003c/p\u003e\n\u003cp\u003e以下は，オープンドメイン型対話システムにおける，難しさとホットなトピックをまとめる\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eContext Awareness\n\u003cul\u003e\n\u003cli\u003e対話コンテクストは会話のトピックを決定したり，ユーザの目標を決定したりと重要\u003c/li\u003e\n\u003cli\u003eコンテクストを解釈した対話エージェントは，現メッセージだけではなく，対話履歴からももとにして返答する\u003c/li\u003e\n\u003cli\u003e生成モデルも検索ベースも，どちらも対話コンテクストモデリングに依存する\u003c/li\u003e\n\u003cli\u003eいくつかのモデルではAttentionが使用されているらしい\u003c/li\u003e\n\u003cli\u003e構造化されたAttentionを用いることでコンテクストを読み取れる？\u003c/li\u003e\n\u003cli\u003e対話をリライトする問題があるらしい\n\u003cul\u003e\n\u003cli\u003e複数のメッセージから単一のメッセージに変換する目標\u003c/li\u003e\n\u003cli\u003eここではコンテクストを理解させることが重要\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eResponse Coherence\n\u003cul\u003e\n\u003cli\u003e首尾一貫した返答は，良い生成器としての一つのクオリティ\u003c/li\u003e\n\u003cli\u003e対話の中で，論理的で首尾一貫しているか？という指標\u003c/li\u003e\n\u003cli\u003e生成モデルにおいてホットなトピックとなっている（検索ベースはすでに人の返答をりようするのでもともと一貫性はあるという主張）\u003c/li\u003e\n\u003cli\u003e一貫性のない文の順序を見つけるタスクを解くことで，返答の一貫性を改善した事例もあり\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eResponse Diversity\n\u003cul\u003e\n\u003cli\u003e人が多用するような表現は訓練コーパスにも多く含まれ，それらばかりを返答してしまうことが問題となりうる\u003c/li\u003e\n\u003cli\u003eかつては条件付き確率において，尤度関数を解くことで尤もらしい返答をもとめていた．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/00fwhths.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e この手法では，返答の精度の安全性と適切さはトレードオフになっていた？\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e ビームサーチを提案されたことも\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eSpeaker Consistency and Personality-based Response\n\u003cul\u003e\n\u003cli\u003eシステムは，訓練コーパスからサンプリングされた分布に対して学習\n\u003cul\u003e\n\u003cli\u003e対話者の趣味といった一貫性のないものに対する返答は．．．\u003c/li\u003e\n\u003cli\u003e対話者の役割を理解し，その個人に合わせた返答が必要になる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e1ステージではなく，3ステージで個人的な嗜好に対応した事例がある\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEmpathetic Response\n\u003cul\u003e\n\u003cli\u003e同情する対話システムは，ユーザの感情の変化や感情に伴った適切な返答をする\u003c/li\u003e\n\u003cli\u003e雑談チャットについて，このトピックは重要\u003c/li\u003e\n\u003cli\u003eCortanaやAlexaなどの製品にもモジュールが含まれている\u003c/li\u003e\n\u003cli\u003eCoBERTのモデルなど\u003c/li\u003e\n\u003cli\u003e感情対話システムのデータセットはとぼしいが，新たなデータセットとベンチマークが提供されたらしい\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eConversation Topics\n\u003cul\u003e\n\u003cli\u003eトピックや目的は，会話に参加した人と会話を続けるための重要な役割を果たす\u003c/li\u003e\n\u003cli\u003eトピックを理解させることが重要\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge-Grounded System\n\u003cul\u003e\n\u003cli\u003e人は，会話のコンテクストと経験や記憶といったものとを関連付けて，返答をする（機会には難しい）\u003c/li\u003e\n\u003cli\u003e生成モデルは，単なる機械翻訳よりも複雑\n\u003cul\u003e\n\u003cli\u003eより自由度が高く，制約が曖昧なため\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e故に，雑談チャットは，外部から得られる常識と結びつけて，seq2seqなモデルによって生成する\u003c/li\u003e\n\u003cli\u003eメモリーネットワークなどで，知識をグラウンディングする手法\u003c/li\u003e\n\u003cli\u003e知識グラフは外部の情報をソースにするものもある．\u003c/li\u003e\n\u003cli\u003egraph attentionを用いて，常識をグラフベースで学習する手法も\u003c/li\u003e\n\u003cli\u003e主な考え方は，外部の知識グラフを使って，会話の論理の流れをモデリングする指標の一部として扱う\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eInteractive Training\n\u003cul\u003e\n\u003cli\u003e別名；human-in-loop training\u003c/li\u003e\n\u003cli\u003eアノテーションされたデータセットは限られている\n\u003cul\u003e\n\u003cli\u003eすべての状況をカバーすることは不可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eユーザとの対話の中で，システムを改善する\u003c/li\u003e\n\u003cli\u003e強化学習における逐次学習を提案\u003c/li\u003e\n\u003cli\u003e対話相手と話して，その相手からフィードバックを得る\u003c/li\u003e\n\u003cli\u003e教師あり学習をした後，Interactive Trainingによってファインチューニングする\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eVisual Dialogue\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/v3baquyk.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Visual Q \u0026#x26; Aなど\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e 画像あり対話システムのほか，映像あり対話システムも面白いトピックだが難題でもある\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 特徴量抽出の複雑さも増す\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e visual dialogueのアノテーションは重労働であり，データセットに乏しいので，現在はデータの不十分さに悩まされている\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e評価のアプローチ\u003c/h3\u003e\n\u003cp\u003e評価の仕方も重要なパートとなっている\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eタスク指向型対話システムにおける評価\n\u003cul\u003e\n\u003cli\u003eBLEUスコアを用いて，システムの返答と人の返答を比べるなど\u003c/li\u003e\n\u003cli\u003eTask Completion Rate\n\u003cul\u003e\n\u003cli\u003eすべてのタスクの試行に対して，いくつのイベントが成功したかの割合\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eTask Completion Cost\n\u003cul\u003e\n\u003cli\u003eタスクをこなすのに使われたリソース\u003c/li\u003e\n\u003cli\u003e解決までの時間が重視されるタスクにおいて用いられる\u003c/li\u003e\n\u003cli\u003eなるべく短いターン数で完遂するのが良しとされる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eHuman-based Evaluation\n\u003cul\u003e\n\u003cli\u003eユーザの対話とユーザの満足度のスコアを提供\u003c/li\u003e\n\u003cli\u003e方法はふたつ\n\u003cul\u003e\n\u003cli\u003eクラウドソーシングで労働を雇う\u003c/li\u003e\n\u003cli\u003e実際にローンチしてからユーザのフィードバックで評価する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eオープンドメイン型対話システムにおける評価\n\u003cul\u003e\n\u003cli\u003e明確なメトリックはない\u003c/li\u003e\n\u003cli\u003e長らくHuman Evaluationを使ってきた\u003c/li\u003e\n\u003cli\u003eWord-overlap Metrics\n\u003cul\u003e\n\u003cli\u003e生成された系列と実際の系列の近さを計算する\u003c/li\u003e\n\u003cli\u003e機械翻訳や要約タスクにおいて用いられる\u003c/li\u003e\n\u003cli\u003en-gramのものとして\n\u003cul\u003e\n\u003cli\u003eBLEU\u003c/li\u003e\n\u003cli\u003eROUGE\u003c/li\u003e\n\u003cli\u003eMETEOR(BLUEの改良版)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eNeural Metrics\n\u003cul\u003e\n\u003cli\u003eニューラルモデルによって計算させる\u003c/li\u003e\n\u003cli\u003eRNNやCNN,GANの識別器を使うなどして，ターンレベルの特徴量抽出を行うなど\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e今もホットなトピックになっている\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eデータセット\u003c/h3\u003e\n\u003cp\u003eタスク指向型対話システム\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/4xcx432d.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/bvaa6edt.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/5nqvspiq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eオープンドメイン型対話システム\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ja1g5vzq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ki5ab45o.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ikzadi1i.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/nuxspw6o.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/1u3frgui.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch3\u003e結論とトレンド\u003c/h3\u003e\n\u003cp\u003eココ最近のトレンド\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMutlimodal dialogue systems\n\u003cul\u003e\n\u003cli\u003e異なるモダリティを組み合わせる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMultitask dialogue systems\n\u003cul\u003e\n\u003cli\u003eタスク指向型と知識グラウンディングさせたオープンドメイン型を組み合わせて，一つのフレームワークまたはシングルモデルとして完結させる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCorpus exploration on Internet\n\u003cul\u003e\n\u003cli\u003ereal-timeなコーパスをインターネットから取り出せるようになれば，期待がもてる\u003c/li\u003e\n\u003cli\u003e研究に値するのでは？\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eUser modeling\n\u003cul\u003e\n\u003cli\u003e生成と評価の双方でホットなトピック\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDialogue generation with a long-term goal\n\u003cul\u003e\n\u003cli\u003e日常的な雑談は特に目的はない\u003c/li\u003e\n\u003cli\u003eしかし，会話が意図的にある特定の目的に向かうときは，ほんの少しでも状況があるはず\u003c/li\u003e\n\u003cli\u003e現在のオープンドメイン型は，長期的な目的を除いてモデリングされがち\n\u003cul\u003e\n\u003cli\u003e十分な知性を備えていない\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey","Date":"2023-05-22","Category":"論文","Tags":["survey","dialogue system"],"Authos":"ゆうぼう","Slug":"Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey","Thumbnail":"/images/thumbnails/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey.png","Description":"Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Surveyのまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: A survey on empathetic dialogue systems\u003c/p\u003e\n\u003cp\u003e研究会: Information Fusion 64\u003c/p\u003e\n\u003cp\u003e年度: 2020\u003c/p\u003e\n\u003cp\u003eキーワード: survey, dialogue system, empathetic dialogue system\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://sentic.net/empathetic-dialogue-systems.pdf\"\u003ehttps://sentic.net/empathetic-dialogue-systems.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDOI: \u003ca href=\"https://doi.org/10.1016/j.inffus.2020.06.011\"\u003ehttps://doi.org/10.1016/j.inffus.2020.06.011\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKeywords\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eArtificial Intelligence,\u003c/p\u003e\n\u003cp\u003eAffective computing,\u003c/p\u003e\n\u003cp\u003eDialogue system\u003c/p\u003e\n\u003cp\u003e共感的対話システム構築の最終目的\u003c/p\u003e\n\u003cp\u003e→ユーザの疑問や悩みに応えること\u003c/p\u003e\n\u003cp\u003eどのような機能が対話システムの共感的な振る舞いを可能にしたのかという，機能の観点から対話システムのユニークな側面に注目する．\u003c/p\u003e\n\u003cp\u003ePersonalization：　システムの一貫性と整合性を高める働き．\u003c/p\u003e\n\u003cp\u003e→ユーザ固有の情報\u003c/p\u003e\n\u003cp\u003eemotion，personalization，knowledge の3要素が重要\u003c/p\u003e\n\u003cp\u003eEmpathetic Dialogue System\u003c/p\u003e\n\u003cp\u003e感情の状態の感受や表現，個人的な嗜好，知識を強化する\u003c/p\u003e\n\u003cp\u003e3つの重要な特徴について\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eemotional-awareness\u003c/li\u003e\n\u003cli\u003ePersonality-awareness\u003c/li\u003e\n\u003cli\u003eKnowledge-accessibility\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/jj8cey5y.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e3つのサブトピックを扱う\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePerceiving and expressing emotion\u003c/li\u003e\n\u003cli\u003eCaring each individual\u003c/li\u003e\n\u003cli\u003eCasting into knowledge\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e過去10年ぶんほどをカバー\u003c/p\u003e\n\u003ch2\u003ePropaedeutic background\u003c/h2\u003e\n\u003cp\u003ebackboneとして使われているアーキテクチャの紹介\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eNeural language model\n1. RNN (LSTM, GRUなど)\n\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/ab1tzbka.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-css\"\u003e  \t\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e. Sequence-\u003cspan class=\"hljs-selector-tag\"\u003eto\u003c/span\u003e-sequence model\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/vxnsfxcb.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/j79vo4ch.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eRNN\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003elong short-term memory, LSTM\n入力・忘却・出力の3つのゲート\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003egated recurrent unit, GRU\ngated関数は通常シグモイド関数．勾配のスケールを制限し，複数回の時間ステップの後に爆発するようにする．\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSeq2Seq\nmodualizedなシステムは，通常以下の4パートからなる：\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNatural Language Understanding, NLU\n入力から構造情報を抽出する\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ea Dialogue State Tracker, DST\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ea Dialogue Polich, DP\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ea response generator\n先行モジュールすべての出力に基づいた応答を生成する．\u003c/p\u003e\n\u003cp\u003e別名，エンコーダ・デコーダモデル．\u003c/p\u003e\n\u003cp\u003e条件付き対話生成のモデル化にはおそらく最も広く使われているニューラルアーキテクチャ．\u003c/p\u003e\n\u003cp\u003eエンコーダ，デコーダはそれぞれ，通常RNNをベースとしている．\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eAttention mechanism\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/ccvc5cuj.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs\"\u003eエンコーダが符号化できる最大ワード数の制限．入力単語数が大きくなると適切に符号化できない．\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e→デコーダが文脈の最も関連性の高い位置にアクセスすることが，この問題に効果的\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs\"\u003eRNNやseq2seqなどの，入力単語数の限界に対して対処できると，RNNやseq2seqでの問題の解消に一役買ったと紹介．\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eMemory networks; MMN\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/4dbq5m5d.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-wasm\"\u003eRNNの隠れ空間ではメモリは時間と共に更新されるものであるが，このメモリは小さかったり離れすぎていたりする．対話のような，文脈を理解するために長期的な記憶が必要な分野では上手くいかないことも．\n\n内部に必要な情報を保持できないため，外部メモリの機能を実装したのがこのMMN\n\n外部の\u003cspan class=\"hljs-keyword\"\u003ememory\u003c/span\u003e slotsに対して，attentionをかけてslotを更新するなどをする\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eVAE, Variational AutoEncoder\n条件付き確率分布に基づき，データ分布に近いように生成をする.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e通常のオートエンコーダ：\u003c/p\u003e\n\u003cp\u003e　入力→エンコーダが潜在変数を生成→デコーダ→出力（入力に似たものを生成）\u003c/p\u003e\n\u003cp\u003eVAE：\u003c/p\u003e\n\u003cp\u003e　潜在変数がN(0,1)の確率分布に従うと仮定する．\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-scss\"\u003e条件付き\u003cspan class=\"hljs-built_in\"\u003eVAE\u003c/span\u003e(CVAE)：条件付き確率分布 \u003cspan class=\"hljs-selector-tag\"\u003eP\u003c/span\u003e(出力応答 | 入力)をモデル化する．\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eGAN, Generative Adversarial Network\nGenerator G, Discriminator D　からなる．\u003c/p\u003e\n\u003cp\u003e画像生成から伝達学習までさまざまなタスクで大きな成果をあげている．\u003c/p\u003e\n\u003cp\u003eGenerator vs Discriminator：\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e生成器（G）は分類誤差を最大にして識別器（D）を欺くように訓練され，Dは分類誤差を最小にするように訓練される．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eRL, Reinforcement Learning（強化学習）\n以下のような一般的に用いられる目的関数は，対話システムの現実的な目標と明確な関連性を持っていない．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e尤度\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eELBO\nELBOを解く．\u003c/p\u003e\n\u003cp\u003e対話における各タイミングでの学習のフィードバックは，単語ごとではなく，まとまった文章が生成されたのちに与えられる．このため遅延報酬関数を使用できる．\u003c/p\u003e\n\u003cp\u003e論文の中でも，RLの重要性が何度も紹介されていた\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eAffective dialogue system\u003c/h2\u003e\n\u003cp\u003e感情は，反応と社会的行動で文化的な作用であり，これは人と環境の関係によって連続的に発展していくもの\u003c/p\u003e\n\u003cp\u003e感情のカテゴライズは，心理学者と哲学者の間でせわしく，長らく議論されてきた\u003c/p\u003e\n\u003cp\u003e感情は社会的な機能も持つ．そして情動は意思決定に関連する尺度である可能性が示唆されている．人間の会話行動のエミュレートだけでなく，システムとユーザとの感情的なつながりを強化することができる．\u003c/p\u003e\n\u003cp\u003e本書における affective dialogue system\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eperceiving emotion\u003c/li\u003e\n\u003cli\u003eunderstanding emotion\u003c/li\u003e\n\u003cli\u003eexpressing and regulating emotion\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e↓\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eemotion-awareness\n文脈の中の感情の表現に関係する，対話中のユーザの感情状態を検出できなければならない．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eemotion-expressiveness\n生成された応答に感情情報を取り入れることに関係する．\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e感情に関する理論は，感情の挿入がユーザとの感情の結びつきを強くするという利点をサポートしてくれる\u003c/p\u003e\n\u003ch3\u003eEmotion analysis\u003c/h3\u003e\n\u003cp\u003e一般的には，多くのcomputational modelは3つのカテゴリーに分けられる\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003edimensional approach（次元的）\u003c/li\u003e\n\u003cli\u003ediscrete approach（離散的）\u003c/li\u003e\n\u003cli\u003eappraisal approach（評価的）\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eDimensional approach\u003c/p\u003e\n\u003cp\u003e感情をベクトル（[覚醒]と[静寂]を表すもの）として表現する．\u003c/p\u003e\n\u003cp\u003e次元空間を持つことで，異なる感情の間でも類似度を計算できるのが利点\u003c/p\u003e\n\u003cp\u003eDiscrete approace\u003c/p\u003e\n\u003cp\u003e感情をいくつかのカテゴリーに分類する．\u003c/p\u003e\n\u003cp\u003eカテゴリ数は設定によって異なってくる．（2，32，64，など．emojiで表したり）\u003c/p\u003e\n\u003cp\u003eAppraisal approach\u003c/p\u003e\n\u003cp\u003e感情と引き起こされたリアクションの関係について学習する\u003c/p\u003e\n\u003cp\u003e分布型\u003c/p\u003e\n\u003cp\u003e感情の別の表現方法．embeddingを使う．\u003c/p\u003e\n\u003cp\u003eメリット：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e感情の種類が連続的になり，補完が可能になる\u003c/li\u003e\n\u003cli\u003eDLの入力として直接利用できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこの利点は，感情のタイプを連続値として扱えること\u003c/p\u003e\n\u003cp\u003eDeep learningのinputとして扱えること\u003c/p\u003e\n\u003cp\u003eもう一つのタイプは感情を，実際の効果として重視する\u003c/p\u003e\n\u003cp\u003esatisfactionやpolitenessとして分類する\u003c/p\u003e\n\u003cp\u003e文や文脈から感情・感情を予測するタスク\u003c/p\u003e\n\u003cp\u003e会話が与えられた時，感情ラベルを事前に予測する＝条件付き確率分布の学習と同義\u003c/p\u003e\n\u003cp\u003easpect-base分析\u003c/p\u003e\n\u003cp\u003e目的：アスペクトと文の両方から感情ラベルを予測することを学習する．\u003c/p\u003e\n\u003cp\u003e文に複数のアスペクトが付与されているとして，その種類に応じて予測を行う？\u003c/p\u003e\n\u003cp\u003e対話システムによる感情ラベル予測では，現在の時間ステップまでの対話履歴しか見えないことがることに注意\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eChallenges\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e感情は曖昧な方法で表現される\n\u003cul\u003e\n\u003cli\u003eコンテクストから理由づけを必要とする\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e対話で現れた感情は，過去から継続していて，文脈的な感情の状態にとても依存している\n\u003cul\u003e\n\u003cli\u003e発話者自身もだが，そのパーティにも影響を受ける\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eさまざまなモダリティを合わせて感情を表している\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eEmotion-aware encoders\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/zrlg6ntb.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eEmotion-aware encoderは，感情に関連した情報をエンコードする\u003c/p\u003e\n\u003cp\u003e得られる文脈ベクトルにも感情に関連した情報が含まれる．\u003c/p\u003e\n\u003cp\u003eモジュール化されたフレームワークは，POMDPとしてモデル化したものとして扱える\u003c/p\u003e\n\u003cp\u003e追加の特徴量として感情のラベルを与えることで機能する\u003c/p\u003e\n\u003cp\u003eただし，テスト時は感情ラベルがない\u003c/p\u003e\n\u003cp\u003e→emotion detector（＝追加の感情検出器）を加えて，暗示的に感情のラベルを推測することで機能させる\u003c/p\u003e\n\u003ch3\u003eEmotion-expressive decoder\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/w0fopt7s.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e感情的なレスポンスを促進する目的で使われる\u003c/p\u003e\n\u003cp\u003econtrollable variableとして直接感情を与える\u003c/p\u003e\n\u003cp\u003eモデルはCVAEやGAN，RLなどを使うことが多いらしい\u003c/p\u003e\n\u003cp\u003econtrollable variableの想定\u003c/p\u003e\n\u003cp\u003e一つまたは複数の潜在的な変数が応答の生成に対して強制力を持っていること\u003c/p\u003e\n\u003cp\u003eそしてそのような変数が存在していること\u003c/p\u003e\n\u003cp\u003e潜在的な対話状態をモデリングするのに自然なアーキテクチャはCVAE\u003c/p\u003e\n\u003cp\u003e学習の際，微分できないことが多いので，誤差をフィードバックするにはRLを使うのが重要\u003c/p\u003e\n\u003ch3\u003eDiscussion\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eChallenges\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e感情のラベルの不足\n\u003cul\u003e\n\u003cli\u003e対話のアノテーション処理に時間がかかるため，人手が不足．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eweak supervisions を用いることで緩和可能：事前に学習された感情ラベルを使うとか，複数のデータソースを組み合わせて規模を拡大するとか\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e感情の評価\n\u003cul\u003e\n\u003cli\u003e単語レベルでは感情の手がかりが微妙なこともある．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eユーザの本質的な感情と実際の認識にギャップがある可能性　→ユーザの誘導とギャップをノイズとして扱うこと．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e他の目的における感情のcompliance\u003c/li\u003e\n\u003cli\u003eターンレベルでのcontrollable variableと生成される単語の依存性\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003ePersonalized dialogue system; PDS\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/kip5j4e8.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epersonalized informationは，話者の意図や継続的な状態を知覚したり，結果的に適したレスポンスを生成するのを成功させる鍵になる\u003c/p\u003e\n\u003ch3\u003eUser modeling\u003c/h3\u003e\n\u003cp\u003eパーソナリティを表現する方法は，多くのパーソナリティ理論で重要になっている関心ごとである\u003c/p\u003e\n\u003cp\u003eこのサーベイでは，user modelingの方法として，二つに分類される\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eidentity-based\u003c/li\u003e\n\u003cli\u003eknowledge-based\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIdentity-based user modeling\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eもっともシンプルな方法で，identityを静的な属性として与える\u003c/p\u003e\n\u003cp\u003eidentity-basedの特徴量は，信頼性があり，情報抽出するための追加のステップを必要とせずに直接的に扱うことができる\u003c/p\u003e\n\u003cp\u003eidentity-basedの特徴量のソースは主に，registrationで収集したメタデータである\u003c/p\u003e\n\u003cp\u003epersona factsとidentity featuresはパーソナライズされた応答の生成に効果があるため，unstructured dataとstructured dataの双方を使う\u003c/p\u003e\n\u003cp\u003eidentity-basedをニューラルネットに入れるときは，embedding layerを用いて，連続値のdense vectorにする\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge-based user modeling\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003estructured dataとpredefined rulesを用いる\u003c/p\u003e\n\u003cp\u003eidentity-basedと比べると，これはユーザのメタデータの制限がない\u003c/p\u003e\n\u003cp\u003estructuredとunstructured information data sourceを両方使用できる\u003c/p\u003e\n\u003cp\u003ePersonalized reasoningというタスク\u003c/p\u003e\n\u003cp\u003eknowledge baseから事実を取り出すことを目的にしている\u003c/p\u003e\n\u003ch3\u003ePersonalized response generation\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003egenerative methods\u003c/li\u003e\n\u003cli\u003eretrieval-based methods (ranking methods)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePDSのメインの目標は，適した応答だけでなく，ユーザのじゅう雨よう（重要？）な知識に基づいた応答を生成すること\u003c/p\u003e\n\u003cp\u003eここでは二つのサブトピックの紹介があった\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epersonality-aware model\u003c/li\u003e\n\u003cli\u003epersonality-infused model\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003ePersonality-aware model\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eユーザのパーソナリティ，もしくは会話のパーティに適応した応答を生成する\u003c/p\u003e\n\u003cp\u003eその応答には，ユーザの嗜好が含まれるということである\u003c/p\u003e\n\u003cp\u003eユーザのプロファイルや会話履歴は，話者の記憶の中で異なる役割をはたす→メモリ(MMNの話など)\u003c/p\u003e\n\u003cp\u003eシステムの中で多くのユーザの参加する大規模な環境においては，それぞれのユーザのタイプに十分なデータを持つのが難しくなりうる\u003c/p\u003e\n\u003cp\u003e→ユーザの知識を収集したり，転移することは可能\u003c/p\u003e\n\u003cp\u003e以降はtransfer learningの話がなされていた．RLも同様に使えるとのこと\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePersonality-infused agent dialogue systems\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e会話をスムーズで，柔軟で自然に行うために，システムにpersonalityを与える\u003c/p\u003e\n\u003cp\u003e3つのコンポーネントからなる\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProfiler Detector\u003c/li\u003e\n\u003cli\u003eBidirectional Decoder\u003c/li\u003e\n\u003cli\u003ePosition Detector\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eProfile Detector\nどのprofileのvalueが生成された応答の中で言及されるべきかを選ぶ\u003c/p\u003e\n\u003cp\u003eMLPを使う\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBidirectional Decoder\nprofile valueが言及される中で応答を生成する目的のデコーダ\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePosition Detector\ndecoding positionのスタート位置を予測する\u003c/p\u003e\n\u003cp\u003eここで使うコンポーネントはbidirectional decoderで監視するように設計される\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003ePosition Detectorは，training dataをかえる性能があるらしい\u003c/p\u003e\n\u003cp\u003epre-specificなエージェントのprofileに沿った応答生成ができるモデルを提供してくれる\u003c/p\u003e\n\u003cp\u003epersona representationの後，以下の提案があった\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ePersona Aware Attention\nそれぞれのdecoding positionに対するAttention weightsを生成する\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePersona Aware Bias\nデコーダのoutput layerの分散表現を差し込むことで生成分布を評価する\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAttentive Memory Network; AMNの提案\u003c/p\u003e\n\u003cp\u003eおそらく個人だけでなく，所属するグループの影響を加味するためのモデルだと思う\u003c/p\u003e\n\u003cp\u003eコンポーネント二つ\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAttentive Encoders\u003c/li\u003e\n\u003cli\u003eKnowledge-Store Memory Module\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eKnowledge-based dialogue system\u003c/h3\u003e\n\u003cp\u003ecurrent dialogue, personal background, external knowledge sourceからきた知識から探したり，コミュニケーションをとるプロセスを経る\u003c/p\u003e\n\u003cp\u003e→ knowledge graphなど\u003c/p\u003e\n\u003cp\u003eexternal knowledgeは重要な役割をはたすことができる\u003c/p\u003e\n\u003cp\u003eこのシステムはたいてい二つの追加のコンポーネントを持つ\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eknowledge encoder\u003c/li\u003e\n\u003cli\u003eknowledge-aware decoder\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eこれらによりcontextとexternal knowledgeの両方で応答に条件付けできる\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge encoding\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eStructured knowledge\nlanguage understandingで重要な役割\u003c/p\u003e\n\u003cp\u003e扱うモデルの変遷\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBoW→Sequence→Data cell→Recursive graph\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs\"\u003e人の前処理やルールベースなどでフィルターをかけるステップが必要\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e\n\u003cp\u003eUnstructured knowledge\n制約が少ないため，扱えるデータの量が多い\u003c/p\u003e\n\u003cp\u003e分散表現に変換できるので，end-to-endのモデル\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge-aware decoding\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ehistorical knowledgeとしてknowledge source→contextなどとinputを一緒に入力にかける\u003c/p\u003e\n\u003cp\u003einputはembeddingされたもの\u003c/p\u003e\n\u003cp\u003e応答生成における2種類の知識ソース：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e対話の履歴から得られるもの\u003c/li\u003e\n\u003cli\u003e事前予知的知識\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eKnowledge attention\nknowledge encoderの出力であるknowledge embeddingを使って，応答の生成に条件付けをする\u003c/p\u003e\n\u003cp\u003e文脈とknowledge embeddingのセットが与えられたら，関連する知識を読み取るか再認識する必要があり，それが応答性性の条件付けに使われる．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCopy\nattention mechanismをベースにしている\u003c/p\u003e\n\u003cp\u003eattentionを入力から単語を選び，コピーするためのポインターに使う\u003c/p\u003e\n\u003cp\u003eseq2seqをコピー機構で拡張することで，検索ベースの手法より優れた性能を発揮する事が示された．\u003c/p\u003e\n\u003cp\u003e単語は決められた単語の分布から取るか，knowledge baseからの単語をコピーすることで生成される\u003c/p\u003e\n\u003cp\u003e高階層のmemory architectureの学習の提案をしている人もいる\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eFuture direction\u003c/h2\u003e\n\u003cp\u003eempathetic dialogue systemに残る研究課題：\u003c/p\u003e\n\u003cp\u003epersonalization, knowledge, and emotion の要素の組み合わせによる包括的な共感システムの構築なんかはあまり行われていなかった．\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eMulti-goal Management\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eコミュニケーションには多くのobjective（目的）が乗っている\n→複数の目的によって過負荷になる事がある．感情や性格，知識を取り入れることでさらに顕著に．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003edialogue agentは全ての異なる側面に取り入れるべき\nすべての異なる側面を考慮する必要があるから↓\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003euser's inherent states, communicating information, minimizing the communicative effortsなど\nこれらを同時に達成するための最適解をいかに効率的に探索するかが問題となる\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExplicit Affective Policy\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e感情は明示的な行動と考えられる\u003c/li\u003e\n\u003cli\u003eagentが他の人の感情をミラーリングしたり，共感を示したりする\n並列共感（相手の感情のミラーリング）と反応的共感に対して異なる戦略を取る事ができる．\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLong-term Empathy Modeling\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e対話中での共感はlong-termである\u003c/li\u003e\n\u003cli\u003eemotion, personality, knowledgeを静的，動的の双方で評価して，long-termで対応する\n静的で動的：安定的なベースを持ちながら，変化もしやすい．長期的なデータ収集において変化に適応する会話モデルの構築が課題．\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDialogue Generation with Target-dependent Emotion\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e感情は，話者と会話の参加者にアタッチされた特定の次元であるとして，target-dependent emotionをuser modelingに合わせる\n感情とターゲットの依存関係が省略されてきた．ターゲットに依存する感情をユーザモデリングと組み合わせることが望まれる（感情と人格の2次元の相関　←共同でモデル化する必要性）．\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDialogue Generation with Emotion Knowledge\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003esentimental, emotionalな知識を使って，感情の状態を認識する\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIncorporate Cues from Multimodal Input\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e複数のモダリティを使って共感を示す\u003c/li\u003e\n\u003cli\u003ei.e. audio signals, body gestures\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePersonalized Diversifying Dialogue Generation\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eユーザに合わせて，生成する応答や検索する応答をカスタマイズする\u003c/li\u003e\n\u003cli\u003eグループごとに多様性はあるが，同グループ内での多様性はかけるのが問題\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDeeper Conversation and User modeling\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e与えられたユーザからのクエリに対して，統計的にもっともらしい回答を取り出すのがシンプルなメインの目標なのが現在\u003c/li\u003e\n\u003cli\u003e将来的には，会話ごとにモデルを作ったり，どのようにユーザの感情が変わるかを理解したり，重要な会話や嗜好を覚えたり，ユーザのニーズや意図を汲み取る以上のことをするようになる(?)\u003c/li\u003e\n\u003cli\u003e↑そのためのサブタスク\n\u003col\u003e\n\u003cli\u003esarcasm detection（皮肉検出）\u003c/li\u003e\n\u003cli\u003etime expression（時間表現）\u003c/li\u003e\n\u003cli\u003enamed entity recognition（固有表現）\u003c/li\u003e\n\u003cli\u003eanaphora resolution\u003c/li\u003e\n\u003cli\u003emicrotext normalization\u003c/li\u003e\n\u003cli\u003eetc\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e@article{MA202050,\ntitle = {A survey on empathetic dialogue systems},\njournal = {Information Fusion},\nvolume = {64},\npages = {50-70},\nyear = {2020},\nissn = {1566-2535},\ndoi = {\u003ca href=\"https://doi.org/10.1016/j.inffus.2020.06.011%7D\"\u003ehttps://doi.org/10.1016/j.inffus.2020.06.011}\u003c/a\u003e,\nurl = {\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S1566253520303092%7D\"\u003ehttps://www.sciencedirect.com/science/article/pii/S1566253520303092}\u003c/a\u003e,\nauthor = {Yukun Ma and Khanh Linh Nguyen and Frank Z. Xing and Erik Cambria},\nkeywords = {Artificial intelligence, Affective computing, Dialogue systems},\nabstract = {Dialogue systems have achieved growing success in many areas thanks to the rapid advances of machine learning techniques. In the quest for generating more human-like conversations, one of the major challenges is to learn to generate responses in a more empathetic manner. In this review article, we focus on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge. Accordingly, we identify three key features that underpin such systems: emotion-awareness, personality-awareness, and knowledge-accessibility. The main goal of this review is to serve as a comprehensive guide to research and development on empathetic dialogue systems and to suggest future directions in this domain.}\n}\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】A survey on empathetic dialogue systems","Date":"2023-05-22","Category":"論文","Tags":["survey","dialogue system","empathetic dialogue system"],"Authos":"ゆうぼう","Slug":"A-survey-on-empathetic-dialogue-systems","Thumbnail":"/images/thumbnails/A-survey-on-empathetic-dialogue-systems.png","Description":"A survey on empathetic dialogue systemsのまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: 遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析\u003c/p\u003e\n\u003cp\u003e研究会: NLP\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: dialogue system\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-2.pdf\"\u003ehttps://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-2.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e対話を通じてユーザに行動変容を促す説得対話システムの研究を行うため，マルチモーダル情報を含む説得対話コーパスの収録\u003c/p\u003e\n\u003cp\u003e音声と顔画像から得られる特徴量を含む説得対話コーパス\u003c/p\u003e\n\u003cp\u003e収集したコーパスと合わせて前後にアンケート\u003c/p\u003e\n\u003cp\u003e被験者に対して追跡調査を行い，実際に説得により行動が変容したかも調査\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e5〜8分の対話を収録\u003c/p\u003e\n\u003cp\u003e3つのドメインについて収集：「運動の促し」「インターネット依存の改善」「慈善事業団体への募金の促し」\u003c/p\u003e\n\u003cp\u003eWoz対話であることを伏せて，ERICAで開発された新しいシステムと対話をしてもらうという目的と被験者に伝えた\u003c/p\u003e\n\u003cp\u003e効果的な説得対話の戦略（論文参照）に基づいてERICAが発話\u003c/p\u003e\n\u003cp\u003eまた以下の流れで対話\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eお互いに挨拶\u003c/li\u003e\n\u003cli\u003e会話テーマの提示（ドメイン）\u003c/li\u003e\n\u003cli\u003e会話テーマに対する被験者の意識を尋ねる\u003c/li\u003e\n\u003cli\u003e相手の反応に応じて説得\u003c/li\u003e\n\u003cli\u003e5分経過後，流れに応じて対話終了\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cp\u003e説得対話における非言語情報の活用を指向し，遠隔操作Androidを用いたWoz対話によるcleanマルチモーダル説得対話コーパスの収集\u003c/p\u003e\n\u003cp\u003e先行研究では主に対話中の説得にフォーカスしているが，本論文では追跡調査による実際の行動変容を調査\u003c/p\u003e\n\u003ch2\u003e実験\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e収録環境\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e説得マイクでステレオ録音／Webカメラで正面から顔を撮影→OpenFaceでAction Unitを抽出／音声は書き起こし→訓練されたアノテーたによって拡張ISO-24617-2対話行為タグに基づく対話行為タグ付与を\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e事前アンケート\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e性格，意思決定の傾向，説得対象ドメインへの意識，現在の状況など\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e事後アンケート\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e年齢，性別，学歴，パートナーの有無，政治的見解など\u003c/p\u003e\n\u003cp\u003eERICAへの印象，対話を通じての意識の変化なども用意\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e追跡調査\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e説得に対して合意した被験者に対して，1週間後にその合意を履行したか追跡調査\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E9%81%A0%E9%9A%94%E6%93%8D%E4%BD%9C%E3%82%A2%E3%83%B3%E3%83%89%E3%83%AD%E3%82%A4%E3%83%89%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E8%AA%AC%E5%BE%97%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AE%E5%8F%8E%E9%9B%86%E3%81%A8%E5%88%86%E6%9E%90/h2xv1id7.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E9%81%A0%E9%9A%94%E6%93%8D%E4%BD%9C%E3%82%A2%E3%83%B3%E3%83%89%E3%83%AD%E3%82%A4%E3%83%89%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E8%AA%AC%E5%BE%97%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AE%E5%8F%8E%E9%9B%86%E3%81%A8%E5%88%86%E6%9E%90/6nfsjg5n.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e実際の行動の変容や意識の変容に関わらず，多くの人が対話中に説得へ合意\u003c/p\u003e\n\u003cp\u003e→実際に説得が効果的であったかを対話上の振る舞いから判定することは困難\u003c/p\u003e\n\u003cp\u003e意識変容から行動変容に映るにはハードルがある\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eロジスティック回帰による説得に有効な要素の分析\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E9%81%A0%E9%9A%94%E6%93%8D%E4%BD%9C%E3%82%A2%E3%83%B3%E3%83%89%E3%83%AD%E3%82%A4%E3%83%89%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E8%AA%AC%E5%BE%97%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AE%E5%8F%8E%E9%9B%86%E3%81%A8%E5%88%86%E6%9E%90/hp4pnema.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E9%81%A0%E9%9A%94%E6%93%8D%E4%BD%9C%E3%82%A2%E3%83%B3%E3%83%89%E3%83%AD%E3%82%A4%E3%83%89%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E8%AA%AC%E5%BE%97%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AE%E5%8F%8E%E9%9B%86%E3%81%A8%E5%88%86%E6%9E%90/kzssp4zq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E9%81%A0%E9%9A%94%E6%93%8D%E4%BD%9C%E3%82%A2%E3%83%B3%E3%83%89%E3%83%AD%E3%82%A4%E3%83%89%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E8%AA%AC%E5%BE%97%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AE%E5%8F%8E%E9%9B%86%E3%81%A8%E5%88%86%E6%9E%90/bopuu7bx.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2\u003eその他（なぜ通ったか？等）\u003c/h2\u003e\n\u003cp\u003e倫理審査が必要らしい\u003c/p\u003e\n\u003cp\u003e顔とか映すデータを撮る場合は倫理審査のため，被験者に合意を得る必要がありそう\u003c/p\u003e\n\u003ch2\u003e次読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析","Date":"2023-05-21","Category":"論文","Tags":["dialogue system"],"Authos":"ゆうぼう","Slug":"遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析","Thumbnail":"/images/thumbnails/遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析.png","Description":"遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析のまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: 知識源との一対多関係を有する対話コーパスによる発話生成\u003c/p\u003e\n\u003cp\u003e研究会: NLP\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: dialogue system, knowledge-base\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-3.pdf\"\u003ehttps://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-3.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003eある文脈において利用可能な知識は一意とは限らず，実際に利用された知識意外にも利用可能な知識は存在する可能性がある\u003c/p\u003e\n\u003cp\u003e→　旅行代理店における対話を題材として，基準対話データセットを作成（知識が一意）\u003c/p\u003e\n\u003cp\u003e→　基準対話データセットを元にマルチラベル対話データセットを作成（知識が複数対応）\u003c/p\u003e\n\u003cp\u003eマルチラベル対話データセットを発話生成モデルの生成に用いると，多様で適切な応答が可能になることが示唆\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/4tpxgaoh.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/6h5aq4kv.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e基準対話データセットの構築\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eクラウドソーシングを利用して，東京と大阪の観光地441件を対象に，観光地に関する対話おw収集\u003c/p\u003e\n\u003cp\u003e知識情報として，基礎情報はじゃらんからスクレイピング，レビュー情報にはGoogle Map APIを用いて取得\u003c/p\u003e\n\u003cp\u003e店発話は，知識情報をなるべく用いて発話し，使用できる知識情報源は最大で2つとした\u003c/p\u003e\n\u003cp\u003e相槌など知識情報を使用しない発話にはnoneのラベルを付与\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eマルチラベルデータセットの構築\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e利用していない知識は，「利用できない知識」ではなく「利用していない知識」\u003c/p\u003e\n\u003cp\u003e→　基準対話データセットから400件を抽出し，対象の発話において利用可能な知識をアノテーション\u003c/p\u003e\n\u003cp\u003e基準対話データセットの分布とマルチラベル対話データセットの分布を比較すると，多くの知識源が利用可能であるとわかる\u003c/p\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cp\u003e一つの発話に対して複数の知識を対応させたマルチラベル対話データセットを作成\u003c/p\u003e\n\u003ch2\u003e実験\u003c/h2\u003e\n\u003cp\u003eLaboro製BERTを用いて利用可能な知識情報を選択\u003c/p\u003e\n\u003cp\u003e→　TransformerベースのNTT製大規模対話モデルhobbyistを用いて，知識情報を用いた応答生成\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/yy6uxb1q.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eBERTを用いた知識選択\u003c/p\u003e\n\u003cp\u003eシングルtestが0.46，マルチtestが0.90\u003c/p\u003e\n\u003cp\u003e適切な知識が選択できていれば正解なので，マルチが高くなるのはそれはそう\u003c/p\u003e\n\u003cp\u003eマルチラベル対話データセットを使用した応答生成は，全て文脈として正しく，知識を反映した多様かつ適切な生成ができていた\u003c/p\u003e\n\u003ch2\u003eその他（なぜ通ったか？等）\u003c/h2\u003e\n\u003ch2\u003e次読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】知識源との一対多関係を有する対話コーパスによる発話生成","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","knowledge-base"],"Authos":"ゆうぼう","Slug":"知識源との一対多関係を有する対話コーパスによる発話生成","Thumbnail":"/images/thumbnails/知識源との一対多関係を有する対話コーパスによる発話生成.png","Description":"知識源との一対多関係を有する対話コーパスによる発話生成のまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: 分類モデルBERTによる不整合生成文の検出について\u003c/p\u003e\n\u003cp\u003e研究会: NLP\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: dialogue system, NLI\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-4.pdf\"\u003ehttps://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-4.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット: 日本語SNLI\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003eニューラル文章生成において，文章としては自然だが，内容が事実とは異なる**事実不整合（factual inconsistency）**が問題\u003c/p\u003e\n\u003cp\u003e→　BERTを用いて分類タスクをすることで生成文の事実不整合の検出を試みる\u003c/p\u003e\n\u003cp\u003e疑似データセットを作成し学習することで，不整合検出におけるドメイン適応の重要性を明らかにした\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%88%86%E9%A1%9E%E3%83%A2%E3%83%87%E3%83%ABBERT%E3%81%AB%E3%82%88%E3%82%8B%E4%B8%8D%E6%95%B4%E5%90%88%E7%94%9F%E6%88%90%E6%96%87%E3%81%AE%E6%A4%9C%E5%87%BA%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/l81q3d7a.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%88%86%E9%A1%9E%E3%83%A2%E3%83%87%E3%83%ABBERT%E3%81%AB%E3%82%88%E3%82%8B%E4%B8%8D%E6%95%B4%E5%90%88%E7%94%9F%E6%88%90%E6%96%87%E3%81%AE%E6%A4%9C%E5%87%BA%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6/gnt0fefy.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e特に数値データに対してロバストなモデルになるよう学習するため，知識に数値が含まれる「料金情報」「アクセス情報」「営業時間情報」の3カテゴリに絞って学習に用いる\u003c/p\u003e\n\u003cp\u003e疑似例の作成は数値や日付，駅名等を書き換えることで対応\u003c/p\u003e\n\u003cp\u003e料金，アクセス，営業時間情報で書き以下絵対象がお’異なるため，それぞれ小cleanなる改変方法でデータを書き換え\u003c/p\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cp\u003e旅行ドメインに対して疑似データセットを作成し，それを用いて学習することで，SNLIデータセットを用いた学習に比べて，事実不整合の生成文の検出精度を向上\u003c/p\u003e\n\u003ch2\u003e実験\u003c/h2\u003e\n\u003cp\u003eデータセット\u003c/p\u003e\n\u003cp\u003e事実整合性判定学習データセット\u003c/p\u003e\n\u003cp\u003e料金，アクセス，営業時間情報について作成した疑似生後売れ，不整合例を集めたデータセット\u003c/p\u003e\n\u003cp\u003eニューラル生成文データセット\u003c/p\u003e\n\u003cp\u003eNTT製TransformerのHobbyistを用いて生成した文章を含むデータセット\u003c/p\u003e\n\u003cp\u003eLaboro社製BERTをファインチューニング\u003c/p\u003e\n\u003cp\u003eベースラインデータセットとして，日本語SNLIデータセット\u003c/p\u003e\n\u003cp\u003erecallが最良のエポックの重みを最良モデルとして評価\u003c/p\u003e\n\u003cp\u003erecallが低いモデルは大量の不整合を見逃していることになるため，目的を果たしていないと考えたから\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e提案手法（疑似例を用いたデータセット）は事実不整合検出に有効である\u003c/p\u003e\n\u003cp\u003e正解できなかった不整合例の内訳\u003c/p\u003e\n\u003cp\u003e料金7件／アクセス1件／営業時間16件\u003c/p\u003e\n\u003cp\u003e→　テンプレートの拡充が必要か？\u003c/p\u003e\n\u003ch2\u003eその他（なぜ通ったか？等）\u003c/h2\u003e\n\u003ch2\u003e次読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】分類モデルBERTによる不整合生成文の検出について","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","NLI"],"Authos":"ゆうぼう","Slug":"分類モデルBERTによる不整合生成文の検出について","Thumbnail":"/images/thumbnails/分類モデルBERTによる不整合生成文の検出について.png","Description":"分類モデルBERTによる不整合生成文の検出についてのまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: Transformerによるhallucination errorの事後修正\u003c/p\u003e\n\u003cp\u003e研究会: NLP\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: dialogue system\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-5.pdf\"\u003ehttps://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-5.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e文生成時に与えた外部知識と異なる内容の発話文を生成してしまうhallucination errorが課題\u003c/p\u003e\n\u003cp\u003e→　hallucination errorを含むデータを疑似的に作成し，BARTやTransformerを用いて事後修正を試みる\u003c/p\u003e\n\u003cp\u003e1.6BのTransformerでは52件中29件の事後修正をした\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Transformer%E3%81%AB%E3%82%88%E3%82%8Bhallucination-error%E3%81%AE%E4%BA%8B%E5%BE%8C%E4%BF%AE%E6%AD%A3/seiwj31o.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e一つの発話文と知識源のペアをテンプレートとして複数のデータを疑似的に作成することで，各知識とカテゴリごとに40000件の発話ぶんと知識源のペアを作成\u003c/p\u003e\n\u003cp\u003e→　「営業時間」「アクセス」「料金」に関するエンティティを書き換えることで疑似的なhallcination errorを含んだ文を作成\u003c/p\u003e\n\u003cp\u003eニューラル生成モデルは事実と無関係な文章を生成する場合がある\u003c/p\u003e\n\u003cp\u003e→　エンティティの書き換えだけではなく，無関係な発話を含んだデータも作成\u003c/p\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cp\u003ehallucination errorを含むデータを疑似的に作成することで，ニューラルモデルによる事後修正の試み\u003c/p\u003e\n\u003ch2\u003e実験\u003c/h2\u003e\n\u003cp\u003eNTT製japanese-dialog-transormers（1.6B）\u003c/p\u003e\n\u003cp\u003e黒橋研製日本語BART（0.12B）\u003c/p\u003e\n\u003cp\u003ehallucination error修正学習データセットには，無関係な発話を含む（add_unrelated）とそれを含まない（baseline）データセットを二種類用意\u003c/p\u003e\n\u003cp\u003e※知識源とHEを[SEP]でつなげるが，普通はBARTは対応していないのでfairseq上ではFusion-in-DecoderをBARTに実装する必要があるらしい\u003c/p\u003e\n\u003cp\u003e評価指標\u003c/p\u003e\n\u003cp\u003eFaithfulness／BLEU-4 score\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Transformer%E3%81%AB%E3%82%88%E3%82%8Bhallucination-error%E3%81%AE%E4%BA%8B%E5%BE%8C%E4%BF%AE%E6%AD%A3/kl305xy2.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Transformer%E3%81%AB%E3%82%88%E3%82%8Bhallucination-error%E3%81%AE%E4%BA%8B%E5%BE%8C%E4%BF%AE%E6%AD%A3/76t0zx7b.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eBLEU-4は「数値が異なる」みたいな単純なhallucination errorは正しく評価できていないのでは？\u003c/p\u003e\n\u003cp\u003eBARTとTransformerの大きな精度差はおそらくパラメータ数と事前学習時のデータセットの差なのでは？\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Transformer%E3%81%AB%E3%82%88%E3%82%8Bhallucination-error%E3%81%AE%E4%BA%8B%E5%BE%8C%E4%BF%AE%E6%AD%A3/p9noavar.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e知識源に出現するエンティティの順序とモデルの主直に出現するエンティティの順序が同じ\u003c/p\u003e\n\u003cp\u003e→　エンティティが出現する順序に注目して書き換えを行っている可能性\u003c/p\u003e\n\u003cp\u003e正しくエンティティの関係を理解できていない？\u003c/p\u003e\n\u003cp\u003eadd_relatedでは発話ぶんにある一文を削除する傾向が見られた\u003c/p\u003e\n\u003ch2\u003eその他（なぜ通ったか？等）\u003c/h2\u003e\n\u003cp\u003e今後の展望\u003c/p\u003e\n\u003cp\u003eHE修正学習データセットの基となるデータの収集\u003c/p\u003e\n\u003cp\u003e書き換えルールなど作成方法の拡張の必要性\u003c/p\u003e\n\u003ch2\u003e次読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】Transformerによるhallucination errorの事後修正","Date":"2023-05-21","Category":"論文","Tags":["dialogue system"],"Authos":"ゆうぼう","Slug":"Transformerによるhallucination-errorの事後修正","Thumbnail":"/images/thumbnails/Transformerによるhallucination-errorの事後修正.png","Description":"Transformerによるhallucination errorの事後修正のまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: Prompt-Tuning による個性を持った対話システムの構築\u003c/p\u003e\n\u003cp\u003e研究会: NLP\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: dialogue system, persona, Prompt-Tuning\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-1.pdf\"\u003ehttps://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-1.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット: PERSONA-CHAT, DailyDialog\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e与えられたキャラクター設定（ペルソナ）を考慮した応答生成をする雑談対話システムの構築\u003c/p\u003e\n\u003cp\u003e一貫した発話をしない対話システムは魅力的ではない\u003c/p\u003e\n\u003cp\u003e→　一貫性を持たせるためペルソナに着目\u003c/p\u003e\n\u003cp\u003ePrompt-Tuningを行うことで，Fine-Tuningに比べて学習時間と計算資源を削減しつつ，より自然で個性を持ったシステムの構築\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prompt-Tuning-%E3%81%AB%E3%82%88%E3%82%8B%E5%80%8B%E6%80%A7%E3%82%92%E6%8C%81%E3%81%A3%E3%81%9F%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E6%A7%8B%E7%AF%89/gur4p6lh.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eペルソナ情報を埋め込むトークン（Persona Info Token）用のEmbedding層を追加したTransformerモデルを提案\u003c/p\u003e\n\u003cp\u003eこの新たに追加したEmbedding層のパラメータを更新する\u003c/p\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cp\u003e事前学習済みモデルのパラメータを更新しないPrompt-Tuningによって学習\u003c/p\u003e\n\u003cp\u003e→　学習に要する時間と計算資源の削減が可能\u003c/p\u003e\n\u003cp\u003e数百個の対話ペアからなる小規模なデータセットであっても，個性を持ったシステムの構築が可能\u003c/p\u003e\n\u003ch2\u003e実験\u003c/h2\u003e\n\u003cp\u003eデータセット：Persona-Chat／DailyDialog\u003c/p\u003e\n\u003cp\u003e1往復の2初話ずつに分割→これを対話ペア\u003c/p\u003e\n\u003cp\u003e使用するペルソナ：Persona-chatにおける対話ペア数の多い上位3種類のペルソナのみ\u003c/p\u003e\n\u003cp\u003eペルソナとは無関係な対話ペアとしてDailyDialogを使用\u003c/p\u003e\n\u003cp\u003e→　TopicがRelationshipの対話ペアを使用\u003c/p\u003e\n\u003cp\u003e中でも発話と応答の両方の長さが50文字以下の対話ペアを一定の比率で学習用データセットに混ぜる\u003c/p\u003e\n\u003cp\u003e→　なぜ？：短い発話やペルソナと無関係な一般的な発話おデータセットに取り込む\u003c/p\u003e\n\u003cp\u003eペルソナ文を与える際，長さ\u0026#x3C;200の時は，200になるまでペルソナぶんを繰り返し並べる\u003c/p\u003e\n\u003cp\u003e生成の戦略にはGreedy searchを採用\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prompt-Tuning-%E3%81%AB%E3%82%88%E3%82%8B%E5%80%8B%E6%80%A7%E3%82%92%E6%8C%81%E3%81%A3%E3%81%9F%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E6%A7%8B%E7%AF%89/4nnv2ixn.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prompt-Tuning-%E3%81%AB%E3%82%88%E3%82%8B%E5%80%8B%E6%80%A7%E3%82%92%E6%8C%81%E3%81%A3%E3%81%9F%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E6%A7%8B%E7%AF%89/eoo61yjd.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prompt-Tuning-%E3%81%AB%E3%82%88%E3%82%8B%E5%80%8B%E6%80%A7%E3%82%92%E6%8C%81%E3%81%A3%E3%81%9F%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E6%A7%8B%E7%AF%89/tebl4dqq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Prompt-Tuning-%E3%81%AB%E3%82%88%E3%82%8B%E5%80%8B%E6%80%A7%E3%82%92%E6%8C%81%E3%81%A3%E3%81%9F%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E6%A7%8B%E7%AF%89/wqq0hd5g.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e自動評価時：distinct-{1, 2}\u003c/p\u003e\n\u003cp\u003eGPT-J-6BをPrompt-Tuningしたモデルが最も多様性のある生成\u003c/p\u003e\n\u003cp\u003eFine-Tuningの時は入力にペルソナを孵化しない方が良い性能\u003c/p\u003e\n\u003cp\u003e人手評価時\u003c/p\u003e\n\u003cp\u003e全ての項目においてGPT-J-6BをPrompt-Tuningしたモデルの評価が高い\u003c/p\u003e\n\u003ch2\u003eその他（なぜ通ったか？等）\u003c/h2\u003e\n\u003cp\u003eLINEとの共同研究\u003c/p\u003e\n\u003cp\u003eAI-Bridging cloudを用いてA100（40GB）を使用した実験\u003c/p\u003e\n\u003ch2\u003e次読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】Prompt-Tuning による個性を持った対話システムの構築","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","persona","Prompt-Tuning"],"Authos":"ゆうぼう","Slug":"Prompt-Tuning-による個性を持った対話システムの構築","Thumbnail":"/images/thumbnails/Prompt-Tuning-による個性を持った対話システムの構築.png","Description":"Prompt-Tuning による個性を持った対話システムの構築のまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: Internet-Augmented Dialogue Generation\u003c/p\u003e\n\u003cp\u003e研究会: ACL\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: dialogue system, Internet-Augmented\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://aclanthology.org/2022.acl-long.579.pdf\"\u003ehttps://aclanthology.org/2022.acl-long.579.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDOI: \u003ca href=\"http://dx.doi.org/10.18653/v1/2022.acl-long.579\"\u003ehttp://dx.doi.org/10.18653/v1/2022.acl-long.579\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット: Topical-Chat, Wizard of Wikipedia\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e検索クエリを生成し，Bing検索の結果をもとに応答生成を行うことで，大規模言語モデルの抱えるhallucinationの問題を軽減しつつ，up-to-the-minute relavent informationを導入した生成を可能にする．\u003c/p\u003e\n\u003cp\u003eインターネットによるaugmentationを行わないモデルやFAISSベースのモデルよりも，search-queryのモデルは優れた会話能力を達成した．\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e提案手法 (Search Engine-Augmented Generation) の流れ\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eコンテクストから検索クエリを生成\u003c/li\u003e\n\u003cli\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e個のドキュメントを取得\u003c/li\u003e\n\u003cli\u003eFiD (Fusion in Decoder)モデルによって，個々のドキュメントをエンコードし，対話コンテクストと結合して，応答を生成\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eインターネットへのアクセスの手法\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eFAISS: distributed approximate nearest-neighbor databaseにストアすることでページをキャッシュ\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003eこれがベースライン的な手法\u003c/li\u003e\n\u003cli\u003eCommon CrawlのデータをFAISSストアして検索をかける\u003c/li\u003e\n\u003cli\u003eベースライン手法\n\u003col\u003e\n\u003cli\u003eRAG (Retrieval Augmented Generation)\u003c/li\u003e\n\u003cli\u003eFiD (Fusion in Decoder)\u003c/li\u003e\n\u003cli\u003eFiD-RAG\u003c/li\u003e\n\u003cli\u003eFAISS + Search Query-based Retrieval\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eインターネットに直接アクセスしてページを取得\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003eFAISS-basedの手法の課題を解決するため\n\u003col\u003e\n\u003cli\u003eリアルタイムなウェブ情報に更新するのが難しい\u003c/li\u003e\n\u003cli\u003eローカルのFAISSにストアできるウェブページの数には限界がある\u003c/li\u003e\n\u003cli\u003eインターネット検索エンジンがチューニングしているハイクオリティなページのランキングの利点を活かせない\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eインターネットにアクセスすることで，常に数え切れないほどの最新の情報にアクセスし，それを取り入れた応答生成を可能にする\u003c/li\u003e\n\u003cli\u003eknowledge regulationなどを行うことで，dynamic state of the worldに対応する\n\u003cul\u003e\n\u003cli\u003e大規模言語モデルは，知識をweightsの中で記憶してしまうため，hallucinationが起きやすい→これを正則化によってよりうまく情報をcopyするように学習させる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e長い目で見れば機械学習の手法は実世界とのインタラクションが求められるが，まず自然な第一ステップとしてインターネットへのアクセスをモデル化してみた．\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e実験\u003c/h2\u003e\n\u003cp\u003eWizard of the Internet (WizInt)という新たなタスクで評価\u003c/p\u003e\n\u003cp\u003eT5, BART-large, BlenderBotをファインチューニング\u003c/p\u003e\n\u003cp\u003eRetrieval-augmented methodは5つのドキュメント (\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e5\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eN = 5\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e5\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e) を使用\u003c/p\u003e\n\u003cp\u003eデコーダ\u003c/p\u003e\n\u003cp\u003eビームサーチ with ビームサイズ = 3\u003c/p\u003e\n\u003cp\u003e最小sequence length = 20\u003c/p\u003e\n\u003cp\u003ebeam blocking ngram = 3\u003c/p\u003e\n\u003cp\u003e評価指標\u003c/p\u003e\n\u003cp\u003ePPL\u003c/p\u003e\n\u003cp\u003eF1\u003c/p\u003e\n\u003cp\u003egold responseとのオーバーラップを評価\u003c/p\u003e\n\u003cp\u003eKnowledge F1 (KF1)\u003c/p\u003e\n\u003cp\u003eモデルの応答と人間がデータ収集時に使った知識のオーバーラップを評価\u003c/p\u003e\n\u003cp\u003e→ F1とKF1はトレードオフ\u003c/p\u003e\n\u003cp\u003eKF1が高く，F1が低いと知識には富んでいるが，会話能力は低\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/l7s7sphq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eTable 3からBART-largeを全てのモデルのPLMベースとして採用\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/ixgpnink.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/128zhnye.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e対話生成のプロセスにインターネットの情報を与えると，人との対話においてより事実との不整合の少ない情報を生成することができる\u003c/p\u003e\n\u003ch2\u003eその他（なぜ通ったか？等）\u003c/h2\u003e\n\u003ch3\u003eDatasetの概要\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/c1e96cpy.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/upaxz8vo.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/w6dyemsg.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eWizard vs apprentice (Figure 3がペルソナ設定のインターフェース)\u003c/p\u003e\n\u003cp\u003eWizardは対話しながらネット検索ができる\u003c/p\u003e\n\u003cp\u003e→検索された結果をアノテーションし，適切な検索結果が得られなければもう一度検索でき，検索結果を無視することも可能\u003c/p\u003e\n\u003cp\u003eApprenticeはペルソナを選び，そのもとでチャット\u003c/p\u003e\n\u003cp\u003eペルソナはPersona-ChatとTopical-Chatデータセットに含まれるペルソナから選択\u003c/p\u003e\n\u003ch3\u003eデータ収集インターフェース\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/z4f9ivph.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch3\u003e対話例\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/xaxs9n1p.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/7wk8s9an.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/gktrd3cq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/5onmd3g5.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Internet-Augmented-Dialogue-Generation/el45rvtq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2\u003e次読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e@inproceedings{komeili-etal-2022-internet,\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003etitle = \"{I}nternet-Augmented Dialogue Generation\",\nauthor = \"Komeili, Mojtaba and\nShuster, Kurt and\nWeston, Jason\",\nbooktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\nmonth = may,\nyear = \"2022\",\naddress = \"Dublin, Ireland\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"\u003ca href=\"https://aclanthology.org/2022.acl-long.579\"\u003ehttps://aclanthology.org/2022.acl-long.579\u003c/a\u003e\",\ndoi = \"10.18653/v1/2022.acl-long.579\",\npages = \"8460--8478\",\nabstract = \"The largest store of continually updating knowledge on our planet can be accessed via internet search. In this work we study giving access to this information to conversational agents. Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue (Shuster et al., 2021); moreover, those facts are frozen in time at the point of model training. In contrast, we propose an approach that learns to generate an internet search query based on the context, and then conditions on the search results to finally generate a response, a method that can employ up-to-the-minute relevant information. We train and evaluate such models on a newly collected dataset of human-human conversations whereby one of the speakers is given access to internet search during knowledgedriven discussions in order to ground their responses. We find that search-query based access of the internet in conversation provides superior performance compared to existing approaches that either use no augmentation or FAISS-based retrieval (Lewis et al., 2020b).\",\n}\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】Internet-Augmented Dialogue Generation","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","Internet-Augmented"],"Authos":"ゆうぼう","Slug":"Internet-Augmented-Dialogue-Generation","Thumbnail":"/images/thumbnails/Internet-Augmented-Dialogue-Generation.png","Description":"Internet-Augmented Dialogue Generationのまとめ","Published":true}],"tag":"dialogue system","categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","CSS","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"pages":1,"page":1},"__N_SSG":true},"page":"/tag/[tag]/[page]","query":{"tag":"dialogue system","page":"1"},"buildId":"XJVBWgBTuTpSxei-rsm8E","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>