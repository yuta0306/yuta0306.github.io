<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>「<!-- -->survey<!-- -->」<!-- -->1<!-- -->ページ目 | <!-- -->ゆうぼうの書跡棚</title><meta name="next-head-count" content="3"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta property="og:title" content="ゆうぼうの書跡棚"/><meta property="og:type" content="website"/><meta property="og:url" content="https://yuta0306.github.io"/><meta property="og:image" content="https://yuta0306.github.io/images/default.png"/><meta property="og:site_name" content="ゆうぼうの書跡棚"/><meta property="og:description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/b31a7883dd1db9d4.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b31a7883dd1db9d4.css" data-n-g=""/><link rel="preload" href="/_next/static/css/71fbbc4c2f48f099.css" as="style"/><link rel="stylesheet" href="/_next/static/css/71fbbc4c2f48f099.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/tag/%5Btag%5D/%5Bpage%5D-f9e21eb9aa12ee31.js" defer=""></script><script src="/_next/static/OvzKZc4hOSTui8FWWOMaS/_buildManifest.js" defer=""></script><script src="/_next/static/OvzKZc4hOSTui8FWWOMaS/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><h1 class="header_header__title__uoTF0">ゆうぼうの書跡棚</h1></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"><a class="header_category__item__0CmfH" href="/category/%E8%AB%96%E6%96%87/1"><li>論文</li></a><a class="header_category__item__0CmfH" href="/category/Web/1"><li>Web</li></a><a class="header_category__item__0CmfH" href="/category/JavaScript/1"><li>JavaScript</li></a><a class="header_category__item__0CmfH" href="/category/Competition/1"><li>Competition</li></a><a class="header_category__item__0CmfH" href="/category/Cloud/1"><li>Cloud</li></a><a class="header_category__item__0CmfH" href="/category/Linux/1"><li>Linux</li></a><a class="header_category__item__0CmfH" href="/category/Python/1"><li>Python</li></a><a class="header_category__item__0CmfH" href="/category/ML/1"><li>ML</li></a><a class="header_category__item__0CmfH" href="/category/Go/1"><li>Go</li></a><a class="header_category__item__0CmfH" href="/category/SQL/1"><li>SQL</li></a></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__grid__Bpzhl"><div class="card_card__container__PrCEE"><a href="/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey.png" alt="【論文まとめ】Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey.png" alt="【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models.png" alt="【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models</h2></div></div></a></div><div></div><div class="paginager_container____vsL"><ul class="paginager_container__pagers__1zmK9"><a class="paginager_container__pager__GaEzu" href="/tag/survey/1"><li class="paginager_container__pager__page__2YOZs">&lt;&lt;</li></a><li class="paginager_container__pager_deactive__Gjmav">&lt;</li><li class="paginager_container__pager_active__k3Sib">1</li><li class="paginager_container__pager_deactive__Gjmav">&gt;</li><a class="paginager_container__pager__GaEzu" href="/tag/survey/1"><li class="paginager_container__pager__page__2YOZs">&gt;&gt;</li></a></ul></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET/1">COMET</a><a class="tags_container__link__1Ts3a" href="/tag/commonsense/1">commonsense</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/Contrasive%20Learning/1">Contrasive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/DST/1">DST</a><a class="tags_container__link__1Ts3a" href="/tag/encyclopedic/1">encyclopedic</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Gating%20Mechanism/1">Gating Mechanism</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/Highway%20Transformer/1">Highway Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection/1">humor detection</a><a class="tags_container__link__1Ts3a" href="/tag/Internet-Augmented/1">Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/KC-Net/1">KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/knowledge-base/1">knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/Knowledge-Intensive%20NLP/1">Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/laughter/1">laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20health/1">mental health</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20state%20knowledge/1">mental state knowledge</a><a class="tags_container__link__1Ts3a" href="/tag/mentalisation/1">mentalisation</a><a class="tags_container__link__1Ts3a" href="/tag/MentalRoBERTa/1">MentalRoBERTa</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/MT/1">MT</a><a class="tags_container__link__1Ts3a" href="/tag/Multi-Hop%20Transformer/1">Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/multi-modal/1">multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLI/1">NLI</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/persona/1">persona</a><a class="tags_container__link__1Ts3a" href="/tag/PLMKE/1">PLMKE</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Prompt-Tuning/1">Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/Self-Dependency-Units%20(SDU)/1">Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/shared%20laughter/1">shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey/1">survey</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/transformer/1">transformer</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"TaggedPostData":[{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003eData State Tracking (以下DST) on Task-Oriented Dialogue Systemに焦点を当てたsurvey\u003c/p\u003e\n\u003ch2\u003eAbstract\u003c/h2\u003e\n\u003cp\u003e触れること\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eタスク\u003c/li\u003e\n\u003cli\u003eデータセット\u003c/li\u003e\n\u003cli\u003eevaluation metrics\u003c/li\u003e\n\u003cli\u003eアプローチ\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e本論文では，二つのDSTモデルをしっかり区別する．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003estatic ontology DST models\n\u003cul\u003e\n\u003cli\u003e固定された対話状況集合を予測する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003edynamic ontology DST models\n\u003cul\u003e\n\u003cli\u003eオントロジーが変化した時でも対話状況を予測する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDefinition of ontology\u003c/p\u003e\n\u003cp\u003ea set of concepts and categories in a subject area or domain that shows their properties and the relations between them.\u003c/p\u003e\n\u003cp\u003e単一ドメインでも複数ドメインでもトラックすることや新しいドメインにスケーリングすることのモデルの性能について議論する\u003c/p\u003e\n\u003cp\u003eTerms: knowledge transfer, zero-shot learning\u003c/p\u003e\n\u003cp\u003eカバーしている年代は2013~2020\u003c/p\u003e\n\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eTask-oriented dialogue system:\u003c/p\u003e\n\u003cp\u003eユーザーがタスクを成し遂げるようにするシステム\u003c/p\u003e\n\u003cp\u003eチケット予約，レストラン予約，カスタマーサポートなど\u003c/p\u003e\n\u003cp\u003eユーザの要求を正確にトラッキングする性能は，一貫していて効果的な対話を可能にする\u003c/p\u003e\n\u003cp\u003e対話状況をslot-valueで表現するDSTコンポーネントを使った情報をトラッキングする\u003c/p\u003e\n\u003cp\u003e↑この精度がとても重要で，下流のコンポーネントがこの状況を利用して，次のactionを決定する\u003c/p\u003e\n\u003cp\u003eDSTタスクは，実際Natural Language Understanding (以下NLU)のタスクを統合している\u003c/p\u003e\n\u003cp\u003eただし，単なるslot filling taskよりも複雑になっている\u003c/p\u003e\n\u003cp\u003eDST\u003c/p\u003e\n\u003cp\u003e現在のturnまで，対話レベルでslot-valueを予測\u003c/p\u003e\n\u003cp\u003eSlot Filling\u003c/p\u003e\n\u003cp\u003e特定のturnのみ考慮してslot-valueを予測すれば良い\u003c/p\u003e\n\u003cp\u003eモデルとしては以下が提案されている\u003c/p\u003e\n\u003cp\u003eRNN-based models\u003c/p\u003e\n\u003cp\u003eAttention-based models\u003c/p\u003e\n\u003cp\u003eTransformer-based models\u003c/p\u003e\n\u003cp\u003eここ最近では，単一ドメインではなく，マルチドメインやflexibleにドメインの移行をするモデリングの研究が盛んらしい\u003c/p\u003e\n\u003ch2\u003eDialogue State Tracking\u003c/h2\u003e\n\u003cp\u003eそもそもDSTとは\u003c/p\u003e\n\u003ch3\u003eDialogue State\u003c/h3\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eS\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eS_t\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eS\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e: dialogue state\u003c/p\u003e\n\u003cp\u003e→turn \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e までにおける対話履歴のsummary\u003c/p\u003e\n\u003cp\u003e次の行動を決定するための全ての十分な情報を含んでいる\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e   : turn\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003el\u003c/mi\u003e\u003cmi\u003eo\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003ev\u003c/mi\u003e\u003cmi\u003ea\u003c/mi\u003e\u003cmi\u003el\u003c/mi\u003e\u003cmi\u003eu\u003c/mi\u003e\u003cmi\u003ee\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e(slot, value)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.01968em;\"\u003el\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eo\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003ev\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ea\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.01968em;\"\u003el\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eu\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ee\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e: このペアで，ユーザの目的を捉える\u003c/p\u003e\n\u003cp\u003eslotはOntology \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eO\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eO\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6833em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eO\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e の中で事前に定義されていて (ドメイン依存であるが)，\u003c/p\u003e\n\u003cp\u003evalueはユーザによって与えられた各スロット \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003es\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.4306em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e で決められる\u003c/p\u003e\n\u003cp\u003eレストランの例で言えば\u003c/p\u003e\n\u003cp\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e{\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eF\u003c/mi\u003e\u003cmi\u003eO\u003c/mi\u003e\u003cmi\u003eO\u003c/mi\u003e\u003cmi\u003eD\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eI\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmi\u003eI\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmi\u003eR\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmi\u003eA\u003c/mi\u003e\u003cmo separator=\"true\"\u003e,\u003c/mo\u003e\u003cmi\u003eC\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi\u003eT\u003c/mi\u003e\u003cmi\u003eR\u003c/mi\u003e\u003cmi\u003eE\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmo stretchy=\"false\"\u003e}\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_t = \\{(FOOD, ITALIAN), (AREA, CENTRE)\\}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e{(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eFOO\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eD\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07847em;\"\u003eI\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.13889em;\"\u003eT\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.07847em;\"\u003eI\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eN\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eRE\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eA\u003c/span\u003e\u003cspan class=\"mpunct\"\u003e,\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.1667em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003eCENTRE\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)}\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eのようになる\u003c/p\u003e\n\u003cp\u003eslotのタイプは二つ\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003einformable\n対話から得られる→FOODやAREA\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003erequestable\nシステムが与える→ADRRESSやPHONE\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eDialogue State Tracker\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eturn-level prediction\n各ターンで与えられるslot-valueを予測\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003edialogue-level prediction\n各ターンでの完全な対話状況を予測\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eTurn-level prediction\u003c/h3\u003e\n\u003cp\u003e直近のturn \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e からslot-valueを予測する\u003c/p\u003e\n\u003cp\u003erule-basedの場合は，そのルールに従って，\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_{t-1}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eに統合して\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_t\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eを得る\u003c/p\u003e\n\u003cp\u003eturn \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e を優先したり，\u003c/p\u003e\n\u003cp\u003e確率を利用して統合したり\u003c/p\u003e\n\u003cp\u003elearning to updateの場合は，turn-levelの予測を入力として，対話状況を予測する方法を学習する\u003c/p\u003e\n\u003ch3\u003eDialogue level prediction\u003c/h3\u003e\n\u003cp\u003e各turn \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003et\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6151em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e において，完全な対話履歴を入力として，完全な対話状況 \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_t\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e を予測する\u003c/p\u003e\n\u003cp\u003e直前の対話状況 \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_{t-1}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e を考慮しないため，\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmrow\u003e\u003cmi\u003et\u003c/mi\u003e\u003cmo\u003e−\u003c/mo\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/mrow\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_{t-1}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003cspan class=\"mbin mtight\"\u003e−\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2083em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eと\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003es\u003c/mi\u003e\u003cmi\u003et\u003c/mi\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003es_t\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003es\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.2806em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mathnormal mtight\"\u003et\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eに一貫性がないこともある\u003c/p\u003e\n\u003ch2\u003eDatasets\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey/4stb497n.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDialog State Tracking Challenge (DSTC)\u003c/li\u003e\n\u003cli\u003eDSTC2 and DSTC3\u003c/li\u003e\n\u003cli\u003eWoZ2.0\u003c/li\u003e\n\u003cli\u003eMultiWoZ\u003c/li\u003e\n\u003cli\u003eSchema-Guided Dataset (SGD)\u003c/li\u003e\n\u003cli\u003eTreeDST\u003c/li\u003e\n\u003cli\u003eMachine-to-Machine (M2M)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eEvaluation Metrics\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAverage Goal Accuracy\u003c/li\u003e\n\u003cli\u003eJoint Goal Accuracy\u003c/li\u003e\n\u003cli\u003eRequested  Slots F1\u003c/li\u003e\n\u003cli\u003eTime Complexity\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eStatic Ontology DST Models\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey/672om8je.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eslot-valueは事前に定義されている\u003c/p\u003e\n\u003cp\u003e→\u003c/p\u003e\n\u003cp\u003eoutput layerは\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efeed-forward layer\n- slotとvalueが固定なので，それらはembeddingされているため可能\u003c/li\u003e\n\u003cli\u003esoftmax\n- 全てのslot-valueのペアの確率を求める\u003c/li\u003e\n\u003cli\u003esigmoid\n- それぞれのslot-valueの確率を求める\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eDelexicalization\u003c/h3\u003e\n\u003cp\u003eimbalanced training data for slot-valuesに対処する効果的なアプローチ\u003c/p\u003e\n\u003cp\u003e入力のslot valuesをラベルの名前に置き換える\u003c/p\u003e\n\u003cp\u003eI want Chinese food.\u003c/p\u003e\n\u003cp\u003e→ I want F.VALUE F.SLOT.\u003c/p\u003e\n\u003ch3\u003eData-driven DST\u003c/h3\u003e\n\u003cp\u003edelexicalizationは確かに効果的だが，手作業でのfeature engineeringが必要になる\u003c/p\u003e\n\u003cp\u003e→ data-drivenな手法が提案された\u003c/p\u003e\n\u003ch3\u003eParameter sharing\u003c/h3\u003e\n\u003cp\u003e昔のモデルはslotごとにエンコーダが分かれていた\u003c/p\u003e\n\u003cp\u003e→そのため全てのslotに対してパラメータを共有する手法が提案された\u003c/p\u003e\n\u003cp\u003eStateNet？\u003c/p\u003e\n\u003ch3\u003eRNN and latency in DST\u003c/h3\u003e\n\u003cp\u003e予測時間が問題だったため，それに対する対策の提案\u003c/p\u003e\n\u003ch3\u003eEncoder based on pre-trained LM\u003c/h3\u003e\n\u003cp\u003eBERTなどを使うことで，捕捉できるslot valueが増えた\u003c/p\u003e\n\u003ch2\u003eDynamic Ontology DST Models\u003c/h2\u003e\n\u003cp\u003eオントロジーが事前定義されていなくてもslot-valueをトラッキングする必要がある\u003c/p\u003e\n\u003cp\u003eアプローチは2種\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eユーザの入力からslot-valueをコピー\u003c/li\u003e\n\u003cli\u003eoutputにslot-valueを生成\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e下図は2種のアプローチを合わせたアーキテクチャ\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey/rdiiezxm.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003estatic ontology vs dynamic ontology\u003c/p\u003e\n\u003cp\u003estaticだとvalueが有限だが，\u003c/p\u003e\n\u003cp\u003edynamicだとoutputの語彙数がとても大きくなる\u003c/p\u003e\n\u003ch3\u003eCopy and pointer networks\u003c/h3\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","survey","DST"],"Authos":"ゆうぼう","Slug":"Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey","Thumbnail":"/images/thumbnails/Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey.png","Description":"Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Surveyのまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/jjd6raay.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e対話システムに関するサーベイ論文\u003c/p\u003e\n\u003cp\u003e対話システムはNLPタスクの一種\u003c/p\u003e\n\u003cp\u003e研究の価値が高いNLPタスクを多く含むため，対話システムは複雑と言える．\u003c/p\u003e\n\u003cp\u003eここ最近で良い成果をあげているもののほとんどがDL\u003c/p\u003e\n\u003cp\u003eメインは，モデルタイプとシステムタイプについて述べられる．\u003c/p\u003e\n\u003cp\u003eシステムタイプ\u003c/p\u003e\n\u003cp\u003eタスク指向型\u003c/p\u003e\n\u003cp\u003eオープンドメイン型\u003c/p\u003e\n\u003ch3\u003eKeywords\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/vcs36qfg.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch3\u003eサーベイの主張の流れ\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/80r4nod6.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003ch3\u003eIntroduction\u003c/h3\u003e\n\u003cp\u003e対話システムはNLPにおいてホットな話題であり，産業においても需要が非常に高い．\u003c/p\u003e\n\u003cp\u003eタスク指向型とオープンドメイン型の対話システムが存在する．\u003c/p\u003e\n\u003cp\u003e昔ながらのタスク指向型は，Natural Language Understanding, Dialogue State Tracking, Policy Learning, Natural Language Generationの4つからなっていた\u003c/p\u003e\n\u003cp\u003e⇒\u003c/p\u003e\n\u003cp\u003e最近のSoTAモデルでは，E2Eのタスク指向型の対話システムが多い．\u003c/p\u003e\n\u003cp\u003eオープンドメイン型\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003egenerative systems\n\u003cul\u003e\n\u003cli\u003eseq2seqなモデル\u003c/li\u003e\n\u003cli\u003eユーザのメッセージや対話履歴を返答系列にマッピングする(Trainingデータに存在しないであろうものも含む)\u003c/li\u003e\n\u003cli\u003e柔軟でコンテクストを読んだ返答をするが，時々主張が一貫しない返答や鈍感で面白くない返答を返す．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eretrieval-based systems (検索)\n\u003cul\u003e\n\u003cli\u003e返答の集合の中から，すでに存在する適した返答を探す．\u003c/li\u003e\n\u003cli\u003e表面上では良い返答をする．ただし，返答集合は有限集合なので，対話上のコンテクストに対しては関係性があまりみられないこともある．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eensemble systems\n\u003cul\u003e\n\u003cli\u003e上記二つを含む\u003c/li\u003e\n\u003cli\u003eGeneratie systemsは検索システムをよくするために使われる．\u003c/li\u003e\n\u003cli\u003e検索システムはより適した返答を選ぶために使われる．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e古典的な対話システムとして，finite state-basedとstatistical learningとmachine learning-basedが挙げられる．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFinite State-based\n\u003cul\u003e\n\u003cli\u003e対話の流れはあらかじめ決められている\u003c/li\u003e\n\u003cli\u003e決まったシナリオの中でしか対応ができない．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eStatistical Learning-based\n\u003cul\u003e\n\u003cli\u003eFinite State-basedよりは柔軟である．あらかじめ対応が決められていないから．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003emachine learning-based\n\u003cul\u003e\n\u003cli\u003eDeep learningが主流？\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNLPの中には対話システムに近い領域がある．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eQ \u0026#x26; A\u003c/li\u003e\n\u003cli\u003ereading comprehension\u003c/li\u003e\n\u003cli\u003edialogue disentanglement\u003c/li\u003e\n\u003cli\u003evisual dialogue\u003c/li\u003e\n\u003cli\u003evisual Q \u0026#x26; A\u003c/li\u003e\n\u003cli\u003edialogue reasoning\u003c/li\u003e\n\u003cli\u003econversational semantic parsing\u003c/li\u003e\n\u003cli\u003edialogue relation extraction\u003c/li\u003e\n\u003cli\u003edialogue sentiment analysis\u003c/li\u003e\n\u003cli\u003ehate speech detection\u003c/li\u003e\n\u003cli\u003eMISC detection (???)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eNeural Models in Dialogue Sustems\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCNN\n\u003cul\u003e\n\u003cli\u003eここ数年NLPの分野での応用も多いらしい\u003c/li\u003e\n\u003cli\u003eフレーズや文章，パラグラフには意味づけをするのに有用でCNNがヒラルキーなモデルになる\u003c/li\u003e\n\u003cli\u003eCNNは一条に乏しいため，最近のSoTAにおいては，テキストをencoderにかけたのちにCNNを用いてヒエラルキーな特徴抽出を行っている．\u003c/li\u003e\n\u003cli\u003e欠点として入力系列の長さは固定長のため以下の使用例\n\u003cul\u003e\n\u003cli\u003eencoderの出力をCNNでベクトル化\u003c/li\u003e\n\u003cli\u003econtextと返答の候補を行列にして，CNNで近さを図ることによって，妥当な候補を選び出す\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e基本的にCNNとencoderはセットか？\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/hdigizvu.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRNN and Vanilla seq2seq\n\u003cul\u003e\n\u003cli\u003e系列として扱えるのが利点と考えるべき\u003c/li\u003e\n\u003cli\u003eHMMや古典的な系列モデルだと，推論時のアルゴリズムの複雑さや考えるべき状態空間の増大に合わせて行列サイズが大きくなりすぎて，大きな状態空間を必要とするデータには対応しがたい．\u003c/li\u003e\n\u003cli\u003eマルコフモデルは限られた条件下においては強力なモデルになりうる．\u003c/li\u003e\n\u003cli\u003eRNNは最近では提案されないが，NLPタスクにおいては未だ現役として活躍することもある\u003c/li\u003e\n\u003cli\u003eJordan-Type \u0026#x26; Elman-Type RNN\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ovxdz4bq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-graphql\"\u003e\t- Jordan-\u003cspan class=\"hljs-keyword\"\u003eType\u003c/span\u003e RNN\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/o372ifqn.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 最新の隠れ層の状態は，Input\u003cspan class=\"hljs-emphasis\"\u003e_tとOutput_\u003c/span\u003et-1による\n\u003cspan class=\"hljs-code\"\u003e\t\t\t\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Elman-Type RNN\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/oewhruxt.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 最新の隠れ層の状態は，Input\u003cspan class=\"hljs-emphasis\"\u003e_tとHidden_\u003c/span\u003et-1による\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e いずれにしてもシンプルなRNNは勾配消失か勾配爆発が大抵おこる\n\u003cspan class=\"hljs-code\"\u003e\t\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e LSTM\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/k612y88q.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Gates\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 入力ゲート\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 忘却ゲート\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 出力ゲート\n\n\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e GRU; Gated Recurrent Unit\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/42latyhe.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Gates\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 更新ゲート\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e リセットゲート\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e パラメータが少ないため，\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 早い\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 汎化性がみられる\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e ただし，\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 大きなデータセットには対応しきれないこともある\n\u003cspan class=\"hljs-code\"\u003e\t\t\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Bi-directional RNN\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/t4zdtd2s.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 双方向を考慮したRNN\n\u003cspan class=\"hljs-code\"\u003e\t\t\n\u003c/span\u003e\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e seq2seq; Encoder-Decoder model\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 初めは機械翻訳のために提案された手法\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Encoderにより入力系列をベクトル化，その隠れ状態をDecodeして生成することを目指す\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/yubh8sbs.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Encode時\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e t時刻のinputとt-1時刻のhiddenによって，t時刻のhiddenが決まる\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Decode時\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e t時刻のhiddenとt-1時刻のoutputによって，t時刻のoutputをデコードする\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 入力系列と出力系列の長さが固定長である必要はない．\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e その代わり，適応させる系列長と出力される系列長は同じになることは保証されない\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eHierarchical Recurrent Encoder-Decoder; HRED\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/l6wqmq77.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-diff\"\u003e\u003cspan class=\"hljs-deletion\"\u003e- コンテクストを理解するためのseq2seqモデル\u003c/span\u003e\n\u003cspan class=\"hljs-deletion\"\u003e- クエリの履歴を理解する？\u003c/span\u003e\n\u003cspan class=\"hljs-deletion\"\u003e- トークンレベルとターンレベルで学習する\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eMemory Networks\u003c/li\u003e\n\u003cli\u003eAttention and Transformer\n\u003cul\u003e\n\u003cli\u003eAttention\u003c/li\u003e\n\u003cli\u003eTransformer\n\u003cul\u003e\n\u003cli\u003eMuti-head Attention\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePointer Net and CopyNet\n\u003cul\u003e\n\u003cli\u003ePointer Net\u003c/li\u003e\n\u003cli\u003eCopyNet\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eDeep RL and GANs\n\u003cul\u003e\n\u003cli\u003eDeep Q-Networks\u003c/li\u003e\n\u003cli\u003eREINFORCE\u003c/li\u003e\n\u003cli\u003eGANs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge Graph Augmented Neural Networks\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e2章は途中から読むのやめた．使用されるネットワークよりも課題感の方が知りたい．\u003c/p\u003e\n\u003ch3\u003eタスク指向型対話システム\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/xkjm1m9f.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eドメインの決まったタスクにおいて特定の問題を解決する．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNatural Language Understanding\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/anac43sh.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e 3つのタスクを持つ\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e ドメイン分類\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 意図の理解\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e スロット埋め\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e IOB; Inside Outside Beginning\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e NER; Named Entity Recognition\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e intent detectionにおいては，Task-Oriented Dialogue BERTがSoTA?\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Domain classification \u0026#x26; intent detectionは同カテゴリタスク\n\n\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e slot filling task = semantic tagging\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e NLUタスクを解く際に，音声データをそのままInputとして与える研究事例も出ているらしい\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e エラーが少なくロバストなモデルになったらしい？\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Natural Language UnderstandingとNatural Language Generationは逆のプロセスをふむ\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 同時にタスクを学習結果が得られるというアプローチも\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eDialogue State Tracking\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/vu1cl18j.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e ユーザの目的と対話履歴を追跡する\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e NLUとDSTのタスクは近い関係にある．\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e NLUは単語にtagを割り振っていくイメージ\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e DSTはtagのplaceholderを会話の内容から埋めていくイメージ\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Dialogue Stateには3つの要素からなる\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Goal constraint corresponding with informable slots\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e 特別なvalueの制約で，ユーザによって言及されるか特別な値をとる\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e DontcareやNoneが特別な値にあたる\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Requested slots\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Search method of current turn\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e 古典的な手法でいくと，\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e ルールベースはエラーが多く，ドメイン適応が大変\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 統計的手法はノイジーな状態や曖昧性に弱い\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e ニューラルネットな手法\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e slot-valueのペアを事前定義して学習\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e valueが大きくなると複雑性が増す\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e slot-valueのペアを読むだけでよく，2値分類タスクとして解ける\n\u003cspan class=\"hljs-bullet\"\u003e\t\t-\u003c/span\u003e モデルの複雑性は避けられるが，反応速度が遅くなる可能性がある．\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e slot-valueのペアを定義せずに，対話の中から直接選ぶ\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePolicy Learning\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDSTモジュールの出力結果からどう行動をとるか\u003c/li\u003e\n\u003cli\u003e教師あり学習or 強化学習\u003c/li\u003e\n\u003cli\u003e教師ありだとアノテショーンデータセットを作るのがとても大変\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNatural Language Generation; NLG\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eタスク指向型対話システムにおける最終層のモジュール\u003c/li\u003e\n\u003cli\u003e最終的な自然言語表現を生成するシステム\u003c/li\u003e\n\u003cli\u003e4つのコンポーネントからなる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/pki8nvzq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Content Determination\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Sentence Planning\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Surface Realization\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e Lexicalization, Referring expression, aggregation\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e RNNに基づいた統計言語モデルにおいて，意味的制約や文法構造による返答生成を行うなど\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e コンテクストを理解した返答を生成することは重要である\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e タスク指向型においては，返答の多様性というよりも信頼性のほうが重要視されがち\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e 意味解析をビームサーチを使うことで，意味の正しさを改善する手法も提案された\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eE2E Methods\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eend-to-endのパイプラインを組むことで高いパフォーマンスを発揮することがあるが，\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e多くのモジュールを組み込むため，バックプロパゲーションで誤差が伝播しないこともある．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eすべてのモジュールが，返答の精度を向上するために，対等に重要であるとは限らない．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e違うドメインに差し替えるとき，オントロジーを事前学習させる必要があるため，困難が生じることもある\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eやり方は大きく分けて2つ\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eすべてのモジュールを展開して誤差逆伝播させる？\u003c/li\u003e\n\u003cli\u003e知識ベースの検索システムと返答生成の双方を用いてパイプラインを組む\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eタスク指向型においては，外部の知識源が必要なことが多い\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eオープンドメイン型対話システム\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e雑談対話システム，或いはタスク思考型ではない対話システムのこと\u003c/li\u003e\n\u003cli\u003eSoTAを示しているオープンドメインは大抵ニューラルネットで解決している\u003c/li\u003e\n\u003cli\u003e完全なるデータドリブンなものが多い\u003c/li\u003e\n\u003cli\u003eオープンドメイン型対話システムは，大まか3つに分けられる\n\u003cul\u003e\n\u003cli\u003e生成システム\u003c/li\u003e\n\u003cli\u003e検索ベースシステム\u003c/li\u003e\n\u003cli\u003eアンサンブルシステム\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e３つの話が以下\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e生成システム\n\u003cul\u003e\n\u003cli\u003e訓練コーパスに出てこないような返答に対して，ユーザのメッセージや対話履歴をマッピングするために，seq2seqなモデルを適用する\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e検索システム\n\u003cul\u003e\n\u003cli\u003e決まった返答集合の中からすでに存在する返答を探そうとする\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eアンサンブルシステム\n\u003cul\u003e\n\u003cli\u003e生成手法と検索手法を合わせる．\u003c/li\u003e\n\u003cli\u003e生成された返答と検索された返答とを比べる．\u003c/li\u003e\n\u003cli\u003e生成も，検索された返答を洗練するために用いられる．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e特徴として，\u003c/p\u003e\n\u003cp\u003e生成モデルは\u003c/p\u003e\n\u003cp\u003e柔軟でコンテクストを読んだ返答をできるが，ときには理解に欠けていたり，怠けた返答を見せることがある\u003c/p\u003e\n\u003cp\u003e検索ベースのモデルは\u003c/p\u003e\n\u003cp\u003e人の返答の集合から実際の返答を選ぶため，返答の集合は有限集合であり，コンテクストと相関がないことがある．\u003c/p\u003e\n\u003cp\u003eただし，表面上のレベルでは，首尾一貫した返答することも多い\u003c/p\u003e\n\u003cp\u003e以下は，オープンドメイン型対話システムにおける，難しさとホットなトピックをまとめる\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eContext Awareness\n\u003cul\u003e\n\u003cli\u003e対話コンテクストは会話のトピックを決定したり，ユーザの目標を決定したりと重要\u003c/li\u003e\n\u003cli\u003eコンテクストを解釈した対話エージェントは，現メッセージだけではなく，対話履歴からももとにして返答する\u003c/li\u003e\n\u003cli\u003e生成モデルも検索ベースも，どちらも対話コンテクストモデリングに依存する\u003c/li\u003e\n\u003cli\u003eいくつかのモデルではAttentionが使用されているらしい\u003c/li\u003e\n\u003cli\u003e構造化されたAttentionを用いることでコンテクストを読み取れる？\u003c/li\u003e\n\u003cli\u003e対話をリライトする問題があるらしい\n\u003cul\u003e\n\u003cli\u003e複数のメッセージから単一のメッセージに変換する目標\u003c/li\u003e\n\u003cli\u003eここではコンテクストを理解させることが重要\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eResponse Coherence\n\u003cul\u003e\n\u003cli\u003e首尾一貫した返答は，良い生成器としての一つのクオリティ\u003c/li\u003e\n\u003cli\u003e対話の中で，論理的で首尾一貫しているか？という指標\u003c/li\u003e\n\u003cli\u003e生成モデルにおいてホットなトピックとなっている（検索ベースはすでに人の返答をりようするのでもともと一貫性はあるという主張）\u003c/li\u003e\n\u003cli\u003e一貫性のない文の順序を見つけるタスクを解くことで，返答の一貫性を改善した事例もあり\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eResponse Diversity\n\u003cul\u003e\n\u003cli\u003e人が多用するような表現は訓練コーパスにも多く含まれ，それらばかりを返答してしまうことが問題となりうる\u003c/li\u003e\n\u003cli\u003eかつては条件付き確率において，尤度関数を解くことで尤もらしい返答をもとめていた．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/7leakwao.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e この手法では，返答の精度の安全性と適切さはトレードオフになっていた？\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e ビームサーチを提案されたことも\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eSpeaker Consistency and Personality-based Response\n\u003cul\u003e\n\u003cli\u003eシステムは，訓練コーパスからサンプリングされた分布に対して学習\n\u003cul\u003e\n\u003cli\u003e対話者の趣味といった一貫性のないものに対する返答は．．．\u003c/li\u003e\n\u003cli\u003e対話者の役割を理解し，その個人に合わせた返答が必要になる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e1ステージではなく，3ステージで個人的な嗜好に対応した事例がある\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEmpathetic Response\n\u003cul\u003e\n\u003cli\u003e同情する対話システムは，ユーザの感情の変化や感情に伴った適切な返答をする\u003c/li\u003e\n\u003cli\u003e雑談チャットについて，このトピックは重要\u003c/li\u003e\n\u003cli\u003eCortanaやAlexaなどの製品にもモジュールが含まれている\u003c/li\u003e\n\u003cli\u003eCoBERTのモデルなど\u003c/li\u003e\n\u003cli\u003e感情対話システムのデータセットはとぼしいが，新たなデータセットとベンチマークが提供されたらしい\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eConversation Topics\n\u003cul\u003e\n\u003cli\u003eトピックや目的は，会話に参加した人と会話を続けるための重要な役割を果たす\u003c/li\u003e\n\u003cli\u003eトピックを理解させることが重要\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge-Grounded System\n\u003cul\u003e\n\u003cli\u003e人は，会話のコンテクストと経験や記憶といったものとを関連付けて，返答をする（機会には難しい）\u003c/li\u003e\n\u003cli\u003e生成モデルは，単なる機械翻訳よりも複雑\n\u003cul\u003e\n\u003cli\u003eより自由度が高く，制約が曖昧なため\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e故に，雑談チャットは，外部から得られる常識と結びつけて，seq2seqなモデルによって生成する\u003c/li\u003e\n\u003cli\u003eメモリーネットワークなどで，知識をグラウンディングする手法\u003c/li\u003e\n\u003cli\u003e知識グラフは外部の情報をソースにするものもある．\u003c/li\u003e\n\u003cli\u003egraph attentionを用いて，常識をグラフベースで学習する手法も\u003c/li\u003e\n\u003cli\u003e主な考え方は，外部の知識グラフを使って，会話の論理の流れをモデリングする指標の一部として扱う\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eInteractive Training\n\u003cul\u003e\n\u003cli\u003e別名；human-in-loop training\u003c/li\u003e\n\u003cli\u003eアノテーションされたデータセットは限られている\n\u003cul\u003e\n\u003cli\u003eすべての状況をカバーすることは不可能\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eユーザとの対話の中で，システムを改善する\u003c/li\u003e\n\u003cli\u003e強化学習における逐次学習を提案\u003c/li\u003e\n\u003cli\u003e対話相手と話して，その相手からフィードバックを得る\u003c/li\u003e\n\u003cli\u003e教師あり学習をした後，Interactive Trainingによってファインチューニングする\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eVisual Dialogue\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/6bhqn4eh.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-markdown\"\u003e\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e Visual Q \u0026#x26; Aなど\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e 画像あり対話システムのほか，映像あり対話システムも面白いトピックだが難題でもある\n\u003cspan class=\"hljs-bullet\"\u003e\t-\u003c/span\u003e 特徴量抽出の複雑さも増す\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e visual dialogueのアノテーションは重労働であり，データセットに乏しいので，現在はデータの不十分さに悩まされている\n\u003cspan class=\"hljs-bullet\"\u003e-\u003c/span\u003e \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003e評価のアプローチ\u003c/h3\u003e\n\u003cp\u003e評価の仕方も重要なパートとなっている\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey","Date":"2023-05-21","Category":"論文","Tags":["survey","dialogue system"],"Authos":"ゆうぼう","Slug":"Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey","Thumbnail":"/images/thumbnails/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey.png","Description":"Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Surveyのまとめ","Published":true},{"contentHtml":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e\n\u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003eまとめること\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eKnowledge-Intensive NLPの概要\u003c/li\u003e\n\u003cli\u003eKnowledge Sources\n\u003col\u003e\n\u003cli\u003eEncyclopedic Knowledge\u003c/li\u003e\n\u003cli\u003eCommonsense Knowledge\u003c/li\u003e\n\u003cli\u003e最近のKnowledge Sourcesの特徴\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Task\n\u003col\u003e\n\u003cli\u003eKnowledge-Intensive NLP Taskの概要\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Taskの特徴\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge Fusion Methodsについて\n\u003col\u003e\n\u003cli\u003ePre-Fusion Methods\u003c/li\u003e\n\u003cli\u003ePost-Fusion Methods\u003c/li\u003e\n\u003cli\u003eHybrid-Fusion Methods\u003c/li\u003e\n\u003cli\u003e代表的なモデルの紹介\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eChallengingなことと今後の方向性\n\u003col\u003e\n\u003cli\u003eUnified PLMKEs Across Tasks and Domains\u003c/li\u003e\n\u003cli\u003eReliability of Knowledge Sources\u003c/li\u003e\n\u003cli\u003eReasoning Module Design\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e事前学習済みモデルにより，モデルのcapacityは増加傾向にあるが，encyclopedicやcommonsenseを用いた，knowledgeableなNLPモデルの需要の高まりが生じている\u003c/p\u003e\n\u003cp\u003e**PLMKEs (Pre-trained Language Model-based Knowledge-Enhanced models)**についてまとめたsurvey論文\u003c/p\u003e\n\u003cp\u003elinguistic or factual knowledgeは暗示的にモデルのパラメータに保存される\u003c/p\u003e\n\u003cp\u003e→事前学習済みのNLPモデルがより汎用的な能力を持つことを一部ではあるが説明できる\u003c/p\u003e\n\u003cp\u003e今のpre-trained LMは，明示的なencyclopedicやcommonsenseのレバレッジ能力に欠けている\u003c/p\u003e\n\u003cp\u003ePLMKEsは，関連する外部知識を取り出すモジュールと知識を混ぜるモジュールがある\u003c/p\u003e\n\u003cp\u003ePLMKEsに関連した重要な3つの要素がある\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eKnowledge Sources\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Tasks\u003c/li\u003e\n\u003cli\u003eKnowledge Fusion Methods\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eKnowledge Sources\u003c/h2\u003e\n\u003ch3\u003eEncyclopedic knowledge\u003c/h3\u003e\n\u003cp\u003eエンティティに関する属性とエンティティ間の関係性をもった知識\u003c/p\u003e\n\u003cp\u003eEntity: person → Attributes: age → Relations: educated at\u003c/p\u003e\n\u003cp\u003eWikipediaは大量のencyclopedicな知識を持っている\u003c/p\u003e\n\u003cp\u003e人物の経歴やイベントの背景などを含んでいる\u003c/p\u003e\n\u003cp\u003e一般的にはtripletsで構成されていることが多い\u003c/p\u003e\n\u003cp\u003ee.g. \u0026#x3C;Tom Hanks, occupation, actor\u003e\u003c/p\u003e\n\u003cp\u003eWikidataのような知識データがPLMKEsに広く使用されている\u003c/p\u003e\n\u003ch3\u003eCommonsense Knowledge\u003c/h3\u003e\n\u003cp\u003e日常生活のなかでの状況に関する知識\u003c/p\u003e\n\u003cp\u003eイベントとその影響を記す\u003c/p\u003e\n\u003cp\u003ee.g. mop up the floor if we split food over it / study hard to win scholarship / goat has four legs\u003c/p\u003e\n\u003cp\u003ecommonsenseの特徴\u003c/p\u003e\n\u003cp\u003e多くの人の間で共有されている知識であり，コミュニケーションの中で暗示的に想定されている知識である\u003c/p\u003e\n\u003cp\u003ecommonsenseもtripletsで表現される\u003c/p\u003e\n\u003cp\u003e最近のPLMKEsでは，ConceptNetとATOMICが外部知識として使用されることが多い\u003c/p\u003e\n\u003ch3\u003eKnowledge Sourcesの特徴\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/uthim0s7.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003elarge-scaleでdiverse\u003c/p\u003e\n\u003cp\u003e現在のソースはより正確で安定的に作られている\u003c/p\u003e\n\u003cp\u003eアノテーションのプロセスは部分的に自動化されていて，非エキスパートにもaccessibleになっている\u003c/p\u003e\n\u003cp\u003e知識データがカバーするドメインは多様\u003c/p\u003e\n\u003cp\u003eオープンドメインのものもあれば，specificなドメインのものも\u003c/p\u003e\n\u003cp\u003eWikipedia, DBPedia, Freebaseなどはオープンドメイン\u003c/p\u003e\n\u003cp\u003eUMLSやAMinerなどはbiomedicineやscienceの特定ドメイン\u003c/p\u003e\n\u003cp\u003edomain-specificなアプリケーションをブーストできる知識\u003c/p\u003e\n\u003cp\u003ecommonsenseに関しては\u003c/p\u003e\n\u003cp\u003eConceptNetやTransOMCSは複数のドメインのcommonsenseをカバー\u003c/p\u003e\n\u003cp\u003eATOMICやASERはある特定のタイプのcommonsenseにフォーカスした知識ソース\u003c/p\u003e\n\u003ch2\u003eKnowledge-Intensive NLP Task\u003c/h2\u003e\n\u003ch3\u003e概要\u003c/h3\u003e\n\u003cp\u003eKnowledge-intensive NLP taskは必要とする知識ソースの種類で2つに分けられ，さらに詳細に分けることができる\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/gqzadptj.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eencyclopedic knowledge-intensive NLP task\nencyclopedicの知識ソースを利用する\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eopen-domain QA\u003c/li\u003e\n\u003cli\u003efact verification\u003c/li\u003e\n\u003cli\u003eentity linking\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/62ojprnq.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ecommonsense knowledge-intensive NLP task\ncommonsenseの知識ソースを利用する\u003c/p\u003e\n\u003cp\u003ecommonsenseの多様性のために，タスクのタイプ自体も多様化している\u003c/p\u003e\n\u003cp\u003eモデルが正確に日常のシナリオを理解し，応答するか否かのテストにフォーカスしたタスク\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGeneral Commonsense\u003c/li\u003e\n\u003cli\u003eSocial Commonsense\u003c/li\u003e\n\u003cli\u003ePhysical Commonsense\u003c/li\u003e\n\u003cli\u003eTemporal Commonsense\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eKnowledge-Intensive Taskの特徴\u003c/h3\u003e\n\u003cp\u003e実際は，モデルにとってだけではなく，人間にとってもいかなる知識の参照なしに問題に答えるのは難しい．（バラクオバマの誕生日はいつ？など\u003c/p\u003e\n\u003cp\u003eしかも，外部知識が必要なのにinputとして必要な外部知識が渡されないため，とてもチャレンジングなタスクになっている\u003c/p\u003e\n\u003cp\u003eそもそも必要な外部知識にグラウンディングするモジュールをPLMKEsの設計に加えることを考慮するようになっている\u003c/p\u003e\n\u003ch2\u003eKnowledge Fusion Methods\u003c/h2\u003e\n\u003cp\u003eモデルが知識を統合するステージは二箇所あり，\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePre-fusion; pre-training\u003c/li\u003e\n\u003cli\u003ePost-fusion; fine-tuning\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eの二通りが考えられる（もしくはその両方のステージ\u003c/p\u003e\n\u003ch3\u003ePre-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/kb8yzih8.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epre-trainingのステージで知識を統合する手法\u003c/p\u003e\n\u003cp\u003eモデルに知識を入力するため，構造化された知識データを非構造化データのテキストコーパスへと処理→モデルに入力\u003c/p\u003e\n\u003cp\u003eテキストデータとして知識を入力するため，大きくモデルのアーキテクチャを変更する必要はない\u003c/p\u003e\n\u003cp\u003eただし，知識グラフのような構造化データを非構造化データへ変えることは難しいこともある\u003c/p\u003e\n\u003cp\u003e簡単な対処法はエンティティと関係性を結合するか，流暢な文章をconditional text generation modelに生成させるか\u003c/p\u003e\n\u003cp\u003eZhang et al. 2019 | Agarwal et al. 2021 を参照（必要になれば読む\u003c/p\u003e\n\u003ch3\u003ePost-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/m33733t8.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eまず，関連知識をキャプチャする\u003c/p\u003e\n\u003cp\u003e次に取得した関連知識をGNNなどのエンコーダでembeddingを得る\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eそれを追加特徴量としてpre-trained LMに与える（図でいうA）\u003c/li\u003e\n\u003cli\u003e直接pre-trained LMに入力する（図でいうB）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHybrid-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/6xhcy94c.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epre-trainingとfine-tuningの両方のステージで知識を統合する\u003c/p\u003e\n\u003cp\u003e追加の学習されるretrieverによりaugmentされたpre-trained modelは，fine-tuningのステージでより効果的にretrieverからの知識を活用できる\u003c/p\u003e\n\u003cp\u003eretrieval-augmented pre-trainingでhybrid-fusionが広く使われている\u003c/p\u003e\n\u003ch3\u003e代表的なモデル\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/codzwuzx.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/myiyapki.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eTable4/5はSOTAモデルを示す\u003c/p\u003e\n\u003cp\u003eencyclopedic knowledge-intensive taskにおいては，BOOLQをのぞき，全てpost-fusionを採用\u003c/p\u003e\n\u003cp\u003ecommonsense knowledge-intensive taskにおいては，CommonsenseQAをのぞき，全てpre-fusionを採用\u003c/p\u003e\n\u003cp\u003epre-fusionとpost-fusionの違いは何？\u003c/p\u003e\n\u003cp\u003epre-fusionは，知識を事前学習のパラメータに暗示的に保存数る\u003c/p\u003e\n\u003cp\u003e最終的にどの知識がパラメータに保存するのかを決定するのは難しい\u003c/p\u003e\n\u003cp\u003e知識の引き出しや利用の難しさが増す\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n","Title":"【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","Date":"2023-05-21","Category":"論文","Tags":["survey","NLP","knowledge-base","PLMKE","commonsense","encyclopedic","Knowledge-Intensive NLP"],"Authos":"ゆうぼう","Slug":"A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models","Thumbnail":"/images/thumbnails/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models.png","Description":"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ","Published":true}],"tag":"survey","categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","CSS","dialogue system","DST","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"pages":1,"page":1},"__N_SSG":true},"page":"/tag/[tag]/[page]","query":{"tag":"survey","page":"1"},"buildId":"OvzKZc4hOSTui8FWWOMaS","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>