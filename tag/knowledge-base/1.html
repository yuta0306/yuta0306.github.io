<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>「<!-- -->knowledge-base<!-- -->」<!-- -->1<!-- -->ページ目 | <!-- -->ゆうぼうの書跡棚</title><meta name="next-head-count" content="3"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><link rel="alternate" type="application/rss+xml" href="https:/yuta0306.github.io/feed.xml" title="RSS2.0"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/75506965150cde8a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/75506965150cde8a.css" data-n-g=""/><link rel="preload" href="/_next/static/css/71fbbc4c2f48f099.css" as="style"/><link rel="stylesheet" href="/_next/static/css/71fbbc4c2f48f099.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/tag/%5Btag%5D/%5Bpage%5D-f9e21eb9aa12ee31.js" defer=""></script><script src="/_next/static/Crb-9VUq2liKCIMbDFwj0/_buildManifest.js" defer=""></script><script src="/_next/static/Crb-9VUq2liKCIMbDFwj0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><h1 class="header_header__title__uoTF0">ゆうぼうの書跡棚</h1></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"><a class="header_category__item__0CmfH" href="/category/%E8%AB%96%E6%96%87/1"><li>論文</li></a><a class="header_category__item__0CmfH" href="/category/Web/1"><li>Web</li></a><a class="header_category__item__0CmfH" href="/category/JavaScript/1"><li>JavaScript</li></a><a class="header_category__item__0CmfH" href="/category/Competition/1"><li>Competition</li></a><a class="header_category__item__0CmfH" href="/category/Cloud/1"><li>Cloud</li></a><a class="header_category__item__0CmfH" href="/category/Python/1"><li>Python</li></a><a class="header_category__item__0CmfH" href="/category/Linux/1"><li>Linux</li></a><a class="header_category__item__0CmfH" href="/category/ML/1"><li>ML</li></a><a class="header_category__item__0CmfH" href="/category/Go/1"><li>Go</li></a><a class="header_category__item__0CmfH" href="/category/SQL/1"><li>SQL</li></a></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__grid__Bpzhl"><div class="card_card__container__PrCEE"><a href="/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/知識源との一対多関係を有する対話コーパスによる発話生成.png" alt="【論文まとめ】知識源との一対多関係を有する対話コーパスによる発話生成" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】知識源との一対多関係を有する対話コーパスによる発話生成</h2></div></div></a></div><div class="card_card__container__PrCEE"><a href="/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models.png" alt="【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-21" itemProp="published">2023-05-21</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models</h2></div></div></a></div><div class="paginager_container____vsL"><ul class="paginager_container__pagers__1zmK9"><a class="paginager_container__pager__GaEzu" href="/tag/knowledge-base/1"><li class="paginager_container__pager__page__2YOZs">&lt;&lt;</li></a><li class="paginager_container__pager_deactive__Gjmav">&lt;</li><li class="paginager_container__pager_active__k3Sib">1</li><li class="paginager_container__pager_deactive__Gjmav">&gt;</li><a class="paginager_container__pager__GaEzu" href="/tag/knowledge-base/1"><li class="paginager_container__pager__page__2YOZs">&gt;&gt;</li></a></ul></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/ASR/1">ASR</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/brew/1">brew</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET/1">COMET</a><a class="tags_container__link__1Ts3a" href="/tag/commonsense/1">commonsense</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/Contrasive%20Learning/1">Contrasive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/Contrastive%20Learning/1">Contrastive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/Demo/1">Demo</a><a class="tags_container__link__1Ts3a" href="/tag/Dialogue%20Structure%20Learning/1">Dialogue Structure Learning</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/DST/1">DST</a><a class="tags_container__link__1Ts3a" href="/tag/Emotion%20Recognition/1">Emotion Recognition</a><a class="tags_container__link__1Ts3a" href="/tag/empathetic%20dialogue%20system/1">empathetic dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/encyclopedic/1">encyclopedic</a><a class="tags_container__link__1Ts3a" href="/tag/Error%20Correction/1">Error Correction</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Gating%20Mechanism/1">Gating Mechanism</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/Highway%20Transformer/1">Highway Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection/1">humor detection</a><a class="tags_container__link__1Ts3a" href="/tag/Intent%20Classification/1">Intent Classification</a><a class="tags_container__link__1Ts3a" href="/tag/Internet-Augmented/1">Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/KC-Net/1">KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/knowledge-base/1">knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/Knowledge-Intensive%20NLP/1">Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/laughter/1">laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/LLM/1">LLM</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20health/1">mental health</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20state%20knowledge/1">mental state knowledge</a><a class="tags_container__link__1Ts3a" href="/tag/mentalisation/1">mentalisation</a><a class="tags_container__link__1Ts3a" href="/tag/MentalRoBERTa/1">MentalRoBERTa</a><a class="tags_container__link__1Ts3a" href="/tag/Merging%20Models/1">Merging Models</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/Model%20Editing/1">Model Editing</a><a class="tags_container__link__1Ts3a" href="/tag/Model%20Patching/1">Model Patching</a><a class="tags_container__link__1Ts3a" href="/tag/MT/1">MT</a><a class="tags_container__link__1Ts3a" href="/tag/Multi-Hop%20Transformer/1">Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/multi-modal/1">multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLG/1">NLG</a><a class="tags_container__link__1Ts3a" href="/tag/NLI/1">NLI</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/persona/1">persona</a><a class="tags_container__link__1Ts3a" href="/tag/PLMKE/1">PLMKE</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Prompt-Tuning/1">Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/Self-Dependency-Units%20(SDU)/1">Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/shared%20laughter/1">shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/SLU/1">SLU</a><a class="tags_container__link__1Ts3a" href="/tag/Speech%20Disfluency/1">Speech Disfluency</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey/1">survey</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/Transfer%20Learning/1">Transfer Learning</a><a class="tags_container__link__1Ts3a" href="/tag/transformer/1">transformer</a><a class="tags_container__link__1Ts3a" href="/tag/Weight%20Interpolation/1">Weight Interpolation</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%81%9E%E3%81%8D%E6%89%8B%E5%8F%8D%E5%BF%9C/1">聞き手反応</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"TaggedPostData":[{"contentHtml":"\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: 知識源との一対多関係を有する対話コーパスによる発話生成\u003c/p\u003e\n\u003cp\u003e研究会: NLP\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: dialogue system, knowledge-base\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-3.pdf\"\u003ehttps://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-3.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003eある文脈において利用可能な知識は一意とは限らず，実際に利用された知識意外にも利用可能な知識は存在する可能性がある\u003c/p\u003e\n\u003cp\u003e→　旅行代理店における対話を題材として，基準対話データセットを作成（知識が一意）\u003c/p\u003e\n\u003cp\u003e→　基準対話データセットを元にマルチラベル対話データセットを作成（知識が複数対応）\u003c/p\u003e\n\u003cp\u003eマルチラベル対話データセットを発話生成モデルの生成に用いると，多様で適切な応答が可能になることが示唆\u003c/p\u003e\n\u003ch2\u003e提案手法\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/4tpxgaoh.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/6h5aq4kv.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e基準対話データセットの構築\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eクラウドソーシングを利用して，東京と大阪の観光地441件を対象に，観光地に関する対話おw収集\u003c/p\u003e\n\u003cp\u003e知識情報として，基礎情報はじゃらんからスクレイピング，レビュー情報にはGoogle Map APIを用いて取得\u003c/p\u003e\n\u003cp\u003e店発話は，知識情報をなるべく用いて発話し，使用できる知識情報源は最大で2つとした\u003c/p\u003e\n\u003cp\u003e相槌など知識情報を使用しない発話にはnoneのラベルを付与\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eマルチラベルデータセットの構築\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e利用していない知識は，「利用できない知識」ではなく「利用していない知識」\u003c/p\u003e\n\u003cp\u003e→　基準対話データセットから400件を抽出し，対象の発話において利用可能な知識をアノテーション\u003c/p\u003e\n\u003cp\u003e基準対話データセットの分布とマルチラベル対話データセットの分布を比較すると，多くの知識源が利用可能であるとわかる\u003c/p\u003e\n\u003ch2\u003e新規性\u003c/h2\u003e\n\u003cp\u003e一つの発話に対して複数の知識を対応させたマルチラベル対話データセットを作成\u003c/p\u003e\n\u003ch2\u003e実験\u003c/h2\u003e\n\u003cp\u003eLaboro製BERTを用いて利用可能な知識情報を選択\u003c/p\u003e\n\u003cp\u003e→　TransformerベースのNTT製大規模対話モデルhobbyistを用いて，知識情報を用いた応答生成\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/yy6uxb1q.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eBERTを用いた知識選択\u003c/p\u003e\n\u003cp\u003eシングルtestが0.46，マルチtestが0.90\u003c/p\u003e\n\u003cp\u003e適切な知識が選択できていれば正解なので，マルチが高くなるのはそれはそう\u003c/p\u003e\n\u003cp\u003eマルチラベル対話データセットを使用した応答生成は，全て文脈として正しく，知識を反映した多様かつ適切な生成ができていた\u003c/p\u003e\n\u003ch2\u003eその他（なぜ通ったか？等）\u003c/h2\u003e\n\u003ch2\u003e次読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e","Title":"【論文まとめ】知識源との一対多関係を有する対話コーパスによる発話生成","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","knowledge-base"],"Authos":"ゆうぼう","Slug":"知識源との一対多関係を有する対話コーパスによる発話生成","Thumbnail":"/images/thumbnails/知識源との一対多関係を有する対話コーパスによる発話生成.png","Description":"知識源との一対多関係を有する対話コーパスによる発話生成のまとめ","Published":true},{"contentHtml":"\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models\u003c/p\u003e\n\u003cp\u003e研究会: arxiv\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: survey, NLP, knowledge-base, PLMKE, commonsense, encyclopedic, Knowledge-Intensive NLP\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://arxiv.org/pdf/2202.08772.pdf\"\u003ehttps://arxiv.org/pdf/2202.08772.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDOI: \u003ca href=\"https://doi.org/10.48550/arXiv.2202.08772\"\u003ehttps://doi.org/10.48550/arXiv.2202.08772\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003cp\u003eまとめること\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eKnowledge-Intensive NLPの概要\u003c/li\u003e\n\u003cli\u003eKnowledge Sources\n\u003col\u003e\n\u003cli\u003eEncyclopedic Knowledge\u003c/li\u003e\n\u003cli\u003eCommonsense Knowledge\u003c/li\u003e\n\u003cli\u003e最近のKnowledge Sourcesの特徴\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Task\n\u003col\u003e\n\u003cli\u003eKnowledge-Intensive NLP Taskの概要\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Taskの特徴\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eKnowledge Fusion Methodsについて\n\u003col\u003e\n\u003cli\u003ePre-Fusion Methods\u003c/li\u003e\n\u003cli\u003ePost-Fusion Methods\u003c/li\u003e\n\u003cli\u003eHybrid-Fusion Methods\u003c/li\u003e\n\u003cli\u003e代表的なモデルの紹介\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003eChallengingなことと今後の方向性\n\u003col\u003e\n\u003cli\u003eUnified PLMKEs Across Tasks and Domains\u003c/li\u003e\n\u003cli\u003eReliability of Knowledge Sources\u003c/li\u003e\n\u003cli\u003eReasoning Module Design\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e事前学習済みモデルにより，モデルのcapacityは増加傾向にあるが，encyclopedicやcommonsenseを用いた，knowledgeableなNLPモデルの需要の高まりが生じている\u003c/p\u003e\n\u003cp\u003e**PLMKEs (Pre-trained Language Model-based Knowledge-Enhanced models)**についてまとめたsurvey論文\u003c/p\u003e\n\u003cp\u003elinguistic or factual knowledgeは暗示的にモデルのパラメータに保存される\u003c/p\u003e\n\u003cp\u003e→事前学習済みのNLPモデルがより汎用的な能力を持つことを一部ではあるが説明できる\u003c/p\u003e\n\u003cp\u003e今のpre-trained LMは，明示的なencyclopedicやcommonsenseのレバレッジ能力に欠けている\u003c/p\u003e\n\u003cp\u003ePLMKEsは，関連する外部知識を取り出すモジュールと知識を混ぜるモジュールがある\u003c/p\u003e\n\u003cp\u003ePLMKEsに関連した重要な3つの要素がある\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eKnowledge Sources\u003c/li\u003e\n\u003cli\u003eKnowledge-Intensive NLP Tasks\u003c/li\u003e\n\u003cli\u003eKnowledge Fusion Methods\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eKnowledge Sources\u003c/h2\u003e\n\u003ch3\u003eEncyclopedic knowledge\u003c/h3\u003e\n\u003cp\u003eエンティティに関する属性とエンティティ間の関係性をもった知識\u003c/p\u003e\n\u003cp\u003eEntity: person → Attributes: age → Relations: educated at\u003c/p\u003e\n\u003cp\u003eWikipediaは大量のencyclopedicな知識を持っている\u003c/p\u003e\n\u003cp\u003e人物の経歴やイベントの背景などを含んでいる\u003c/p\u003e\n\u003cp\u003e一般的にはtripletsで構成されていることが多い\u003c/p\u003e\n\u003cp\u003ee.g. \u0026#x3C;Tom Hanks, occupation, actor\u003e\u003c/p\u003e\n\u003cp\u003eWikidataのような知識データがPLMKEsに広く使用されている\u003c/p\u003e\n\u003ch3\u003eCommonsense Knowledge\u003c/h3\u003e\n\u003cp\u003e日常生活のなかでの状況に関する知識\u003c/p\u003e\n\u003cp\u003eイベントとその影響を記す\u003c/p\u003e\n\u003cp\u003ee.g. mop up the floor if we split food over it / study hard to win scholarship / goat has four legs\u003c/p\u003e\n\u003cp\u003ecommonsenseの特徴\u003c/p\u003e\n\u003cp\u003e多くの人の間で共有されている知識であり，コミュニケーションの中で暗示的に想定されている知識である\u003c/p\u003e\n\u003cp\u003ecommonsenseもtripletsで表現される\u003c/p\u003e\n\u003cp\u003e最近のPLMKEsでは，ConceptNetとATOMICが外部知識として使用されることが多い\u003c/p\u003e\n\u003ch3\u003eKnowledge Sourcesの特徴\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/gcgqsmdk.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003elarge-scaleでdiverse\u003c/p\u003e\n\u003cp\u003e現在のソースはより正確で安定的に作られている\u003c/p\u003e\n\u003cp\u003eアノテーションのプロセスは部分的に自動化されていて，非エキスパートにもaccessibleになっている\u003c/p\u003e\n\u003cp\u003e知識データがカバーするドメインは多様\u003c/p\u003e\n\u003cp\u003eオープンドメインのものもあれば，specificなドメインのものも\u003c/p\u003e\n\u003cp\u003eWikipedia, DBPedia, Freebaseなどはオープンドメイン\u003c/p\u003e\n\u003cp\u003eUMLSやAMinerなどはbiomedicineやscienceの特定ドメイン\u003c/p\u003e\n\u003cp\u003edomain-specificなアプリケーションをブーストできる知識\u003c/p\u003e\n\u003cp\u003ecommonsenseに関しては\u003c/p\u003e\n\u003cp\u003eConceptNetやTransOMCSは複数のドメインのcommonsenseをカバー\u003c/p\u003e\n\u003cp\u003eATOMICやASERはある特定のタイプのcommonsenseにフォーカスした知識ソース\u003c/p\u003e\n\u003ch2\u003eKnowledge-Intensive NLP Task\u003c/h2\u003e\n\u003ch3\u003e概要\u003c/h3\u003e\n\u003cp\u003eKnowledge-intensive NLP taskは必要とする知識ソースの種類で2つに分けられ，さらに詳細に分けることができる\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/ju1lqjam.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eencyclopedic knowledge-intensive NLP task\nencyclopedicの知識ソースを利用する\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eopen-domain QA\u003c/li\u003e\n\u003cli\u003efact verification\u003c/li\u003e\n\u003cli\u003eentity linking\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/kr89pm58.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ecommonsense knowledge-intensive NLP task\ncommonsenseの知識ソースを利用する\u003c/p\u003e\n\u003cp\u003ecommonsenseの多様性のために，タスクのタイプ自体も多様化している\u003c/p\u003e\n\u003cp\u003eモデルが正確に日常のシナリオを理解し，応答するか否かのテストにフォーカスしたタスク\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGeneral Commonsense\u003c/li\u003e\n\u003cli\u003eSocial Commonsense\u003c/li\u003e\n\u003cli\u003ePhysical Commonsense\u003c/li\u003e\n\u003cli\u003eTemporal Commonsense\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eKnowledge-Intensive Taskの特徴\u003c/h3\u003e\n\u003cp\u003e実際は，モデルにとってだけではなく，人間にとってもいかなる知識の参照なしに問題に答えるのは難しい．（バラクオバマの誕生日はいつ？など\u003c/p\u003e\n\u003cp\u003eしかも，外部知識が必要なのにinputとして必要な外部知識が渡されないため，とてもチャレンジングなタスクになっている\u003c/p\u003e\n\u003cp\u003eそもそも必要な外部知識にグラウンディングするモジュールをPLMKEsの設計に加えることを考慮するようになっている\u003c/p\u003e\n\u003ch2\u003eKnowledge Fusion Methods\u003c/h2\u003e\n\u003cp\u003eモデルが知識を統合するステージは二箇所あり，\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePre-fusion; pre-training\u003c/li\u003e\n\u003cli\u003ePost-fusion; fine-tuning\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eの二通りが考えられる（もしくはその両方のステージ\u003c/p\u003e\n\u003ch3\u003ePre-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/z4lvh39q.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epre-trainingのステージで知識を統合する手法\u003c/p\u003e\n\u003cp\u003eモデルに知識を入力するため，構造化された知識データを非構造化データのテキストコーパスへと処理→モデルに入力\u003c/p\u003e\n\u003cp\u003eテキストデータとして知識を入力するため，大きくモデルのアーキテクチャを変更する必要はない\u003c/p\u003e\n\u003cp\u003eただし，知識グラフのような構造化データを非構造化データへ変えることは難しいこともある\u003c/p\u003e\n\u003cp\u003e簡単な対処法はエンティティと関係性を結合するか，流暢な文章をconditional text generation modelに生成させるか\u003c/p\u003e\n\u003cp\u003eZhang et al. 2019 | Agarwal et al. 2021 を参照（必要になれば読む\u003c/p\u003e\n\u003ch3\u003ePost-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/bshr899d.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eまず，関連知識をキャプチャする\u003c/p\u003e\n\u003cp\u003e次に取得した関連知識をGNNなどのエンコーダでembeddingを得る\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eそれを追加特徴量としてpre-trained LMに与える（図でいうA）\u003c/li\u003e\n\u003cli\u003e直接pre-trained LMに入力する（図でいうB）\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eHybrid-Fusion Methods\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/1yg24grj.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epre-trainingとfine-tuningの両方のステージで知識を統合する\u003c/p\u003e\n\u003cp\u003e追加の学習されるretrieverによりaugmentされたpre-trained modelは，fine-tuningのステージでより効果的にretrieverからの知識を活用できる\u003c/p\u003e\n\u003cp\u003eretrieval-augmented pre-trainingでhybrid-fusionが広く使われている\u003c/p\u003e\n\u003ch3\u003e代表的なモデル\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/xh93uokd.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/cl36oka6.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eTable4/5はSOTAモデルを示す\u003c/p\u003e\n\u003cp\u003eencyclopedic knowledge-intensive taskにおいては，BOOLQをのぞき，全てpost-fusionを採用\u003c/p\u003e\n\u003cp\u003ecommonsense knowledge-intensive taskにおいては，CommonsenseQAをのぞき，全てpre-fusionを採用\u003c/p\u003e\n\u003cp\u003epre-fusionとpost-fusionの違いは何？\u003c/p\u003e\n\u003cp\u003epre-fusionは，知識を事前学習のパラメータに暗示的に保存数る\u003c/p\u003e\n\u003cp\u003e最終的にどの知識がパラメータに保存するのかを決定するのは難しい\u003c/p\u003e\n\u003cp\u003e知識の引き出しや利用の難しさが増す\u003c/p\u003e\n\u003cp\u003epost-fusionは，明示的で具体的なテキストの知識を推論できる\u003c/p\u003e\n\u003cp\u003epost-fusionの利点は，commonsense knolwedge-intensive taskでは欠点になりうる\u003c/p\u003e\n\u003cp\u003ecommonsenseはたいていテキストの中に暗示的に置かれていて，commonsenseの知識ソースのカバー範囲はencyclopedicの知識ソースのカバー範囲に比べればとても小さい\u003c/p\u003e\n\u003cp\u003elarge-scaleなcommonsenseのソースの利用がたとえ有用だとしても，日常生活で使われる大半のcommonsenseを見落としがちなまま\u003c/p\u003e\n\u003cp\u003e→commonsenseにおいて，post-fusionがあまり効かないのはそのためなのでは？\u003c/p\u003e\n\u003ch2\u003eChallenges and Future Directions\u003c/h2\u003e\n\u003ch3\u003eUnified PLMKEs Across Tasks and Domains\u003c/h3\u003e\n\u003cp\u003etask-specificなモデリングでは進展がある\u003c/p\u003e\n\u003cp\u003epost-fusionとhybrid-fusionはencyclopedicで適用されているが，commonsenseでは採用できておらず恩恵が得られていない\u003c/p\u003e\n\u003cp\u003e異なるタスク間でのPLMKEsはユニークであるため，各タスク間で互換性がない\u003c/p\u003e\n\u003cp\u003ebiomedicalやlegalの知識に関するknowledge-intensive NLP taskまで拡張されている\u003c/p\u003e\n\u003cp\u003e最近では，異なる時間や地域に存在する知識の多様性に対しても重要度を割り当てている\u003c/p\u003e\n\u003cp\u003eタスク間やdomain間でのunified PLMKEsの必要性がましている\u003c/p\u003e\n\u003ch3\u003eReliability of Kowledge Sources\u003c/h3\u003e\n\u003cp\u003e知識ソースの信頼性に関して\u003c/p\u003e\n\u003cp\u003e多くのlarge-scaleな知識ソースは自動的な知識獲得アルゴリズムで構築されている\u003c/p\u003e\n\u003cp\u003e→スケールと正確性はトレードオフになってしまう\u003c/p\u003e\n\u003cp\u003ePLMKEsにおけるバイアスの増幅はバイアスのある知識ソースによって構築されてしまう\u003c/p\u003e\n\u003cp\u003e知識獲得アルゴリズムの見直しや使う前の知識ソースの注意深い精査が必要である\u003c/p\u003e\n\u003ch3\u003eReasoning Module Design\u003c/h3\u003e\n\u003cp\u003eReasoningはknowledge-intensive NLP taskを解く上で重要なステップである\u003c/p\u003e\n\u003cp\u003ecommonsenseを考えるときは手順を踏んで，複雑な状況を把握する\u003c/p\u003e\n\u003cp\u003ee.g. \u003c/p\u003e\n\u003cp\u003eまず，床が綺麗でないことを把握\u003c/p\u003e\n\u003cp\u003eこぼした食べ物を踏んで他の人の靴が汚くなったのだろうと考える\u003c/p\u003e\n\u003cp\u003e↑上記状況を踏まえて，モップをかける意図が生まれる\u003c/p\u003e\n\u003cp\u003e人間のような日々の状況を認識する能力を獲得するには，multi-hopなreasoning moduleが必要になる（上の例みたいな形\u003c/p\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003c/blockquote\u003e","Title":"【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","Date":"2023-05-21","Category":"論文","Tags":["survey","NLP","knowledge-base","PLMKE","commonsense","encyclopedic","Knowledge-Intensive NLP"],"Authos":"ゆうぼう","Slug":"A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models","Thumbnail":"/images/thumbnails/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models.png","Description":"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ","Published":true}],"tag":"knowledge-base","categories":["論文","Web","JavaScript","Competition","Cloud","Python","Linux","ML","Go","SQL"],"tags":["Apache","Appium","ASR","atmaCup","AWS","brew","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","Contrastive Learning","CSS","Demo","Dialogue Structure Learning","dialogue system","DST","Emotion Recognition","empathetic dialogue system","encyclopedic","Error Correction","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Intent Classification","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","LLM","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","Merging Models","ML","Model Editing","Model Patching","MT","Multi-Hop Transformer","multi-modal","MySQL","NLG","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","SLU","Speech Disfluency","subprocess","Super-Resolution","survey","tensorflow","Tkinter","Transfer Learning","transformer","Weight Interpolation","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","聞き手反応","超解像"],"pages":1,"page":1},"__N_SSG":true},"page":"/tag/[tag]/[page]","query":{"tag":"knowledge-base","page":"1"},"buildId":"Crb-9VUq2liKCIMbDFwj0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>