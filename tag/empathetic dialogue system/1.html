<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>「<!-- -->empathetic dialogue system<!-- -->」<!-- -->1<!-- -->ページ目 | <!-- -->ゆうぼうの書跡棚</title><meta name="next-head-count" content="3"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/75506965150cde8a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/75506965150cde8a.css" data-n-g=""/><link rel="preload" href="/_next/static/css/71fbbc4c2f48f099.css" as="style"/><link rel="stylesheet" href="/_next/static/css/71fbbc4c2f48f099.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/tag/%5Btag%5D/%5Bpage%5D-f9e21eb9aa12ee31.js" defer=""></script><script src="/_next/static/xqdRocZsV0g1E4ufbXnYY/_buildManifest.js" defer=""></script><script src="/_next/static/xqdRocZsV0g1E4ufbXnYY/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><h1 class="header_header__title__uoTF0">ゆうぼうの書跡棚</h1></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"><a class="header_category__item__0CmfH" href="/category/%E8%AB%96%E6%96%87/1"><li>論文</li></a><a class="header_category__item__0CmfH" href="/category/Web/1"><li>Web</li></a><a class="header_category__item__0CmfH" href="/category/JavaScript/1"><li>JavaScript</li></a><a class="header_category__item__0CmfH" href="/category/Competition/1"><li>Competition</li></a><a class="header_category__item__0CmfH" href="/category/Cloud/1"><li>Cloud</li></a><a class="header_category__item__0CmfH" href="/category/Linux/1"><li>Linux</li></a><a class="header_category__item__0CmfH" href="/category/Python/1"><li>Python</li></a><a class="header_category__item__0CmfH" href="/category/ML/1"><li>ML</li></a><a class="header_category__item__0CmfH" href="/category/Go/1"><li>Go</li></a><a class="header_category__item__0CmfH" href="/category/SQL/1"><li>SQL</li></a></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__grid__Bpzhl"><div class="card_card__container__PrCEE"><a href="/A-survey-on-empathetic-dialogue-systems"><div class="card_card__s4JKv"><div class="card_card__thumbnail__XavfB"><img src="/images/thumbnails/A-survey-on-empathetic-dialogue-systems.png" alt="【論文まとめ】A survey on empathetic dialogue systems" class="card_card__thumbnail__img__fusOc" loading="lazy"/></div><div><div class="card_card__meta__NjslI"><time dateTime="2023-05-22" itemProp="published">2023-05-22</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__Nn7hR">【論文まとめ】A survey on empathetic dialogue systems</h2></div></div></a></div><div></div><div class="paginager_container____vsL"><ul class="paginager_container__pagers__1zmK9"><a class="paginager_container__pager__GaEzu" href="/tag/empathetic%20dialogue%20system/1"><li class="paginager_container__pager__page__2YOZs">&lt;&lt;</li></a><li class="paginager_container__pager_deactive__Gjmav">&lt;</li><li class="paginager_container__pager_active__k3Sib">1</li><li class="paginager_container__pager_deactive__Gjmav">&gt;</li><a class="paginager_container__pager__GaEzu" href="/tag/empathetic%20dialogue%20system/1"><li class="paginager_container__pager__page__2YOZs">&gt;&gt;</li></a></ul></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET/1">COMET</a><a class="tags_container__link__1Ts3a" href="/tag/commonsense/1">commonsense</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/Contrasive%20Learning/1">Contrasive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/Contrastive%20Learning/1">Contrastive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/Dialogue%20Structure%20Learning/1">Dialogue Structure Learning</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/DST/1">DST</a><a class="tags_container__link__1Ts3a" href="/tag/empathetic%20dialogue%20system/1">empathetic dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/encyclopedic/1">encyclopedic</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Gating%20Mechanism/1">Gating Mechanism</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/Highway%20Transformer/1">Highway Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection/1">humor detection</a><a class="tags_container__link__1Ts3a" href="/tag/Internet-Augmented/1">Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/KC-Net/1">KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/knowledge-base/1">knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/Knowledge-Intensive%20NLP/1">Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/laughter/1">laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20health/1">mental health</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20state%20knowledge/1">mental state knowledge</a><a class="tags_container__link__1Ts3a" href="/tag/mentalisation/1">mentalisation</a><a class="tags_container__link__1Ts3a" href="/tag/MentalRoBERTa/1">MentalRoBERTa</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/MT/1">MT</a><a class="tags_container__link__1Ts3a" href="/tag/Multi-Hop%20Transformer/1">Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/multi-modal/1">multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLG/1">NLG</a><a class="tags_container__link__1Ts3a" href="/tag/NLI/1">NLI</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/persona/1">persona</a><a class="tags_container__link__1Ts3a" href="/tag/PLMKE/1">PLMKE</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Prompt-Tuning/1">Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/Self-Dependency-Units%20(SDU)/1">Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/shared%20laughter/1">shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey/1">survey</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/transformer/1">transformer</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%81%9E%E3%81%8D%E6%89%8B%E5%8F%8D%E5%BF%9C/1">聞き手反応</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"TaggedPostData":[{"contentHtml":"\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: A survey on empathetic dialogue systems\u003c/p\u003e\n\u003cp\u003e研究会: Information Fusion 64\u003c/p\u003e\n\u003cp\u003e年度: 2020\u003c/p\u003e\n\u003cp\u003eキーワード: survey, dialogue system, empathetic dialogue system\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://sentic.net/empathetic-dialogue-systems.pdf\"\u003ehttps://sentic.net/empathetic-dialogue-systems.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDOI: \u003ca href=\"https://doi.org/10.1016/j.inffus.2020.06.011\"\u003ehttps://doi.org/10.1016/j.inffus.2020.06.011\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKeywords\u003c/strong\u003e:\u003c/p\u003e\n\u003cp\u003eArtificial Intelligence,\u003c/p\u003e\n\u003cp\u003eAffective computing,\u003c/p\u003e\n\u003cp\u003eDialogue system\u003c/p\u003e\n\u003cp\u003e共感的対話システム構築の最終目的\u003c/p\u003e\n\u003cp\u003e→ユーザの疑問や悩みに応えること\u003c/p\u003e\n\u003cp\u003eどのような機能が対話システムの共感的な振る舞いを可能にしたのかという，機能の観点から対話システムのユニークな側面に注目する．\u003c/p\u003e\n\u003cp\u003ePersonalization：　システムの一貫性と整合性を高める働き．\u003c/p\u003e\n\u003cp\u003e→ユーザ固有の情報\u003c/p\u003e\n\u003cp\u003eemotion，personalization，knowledge の3要素が重要\u003c/p\u003e\n\u003cp\u003eEmpathetic Dialogue System\u003c/p\u003e\n\u003cp\u003e感情の状態の感受や表現，個人的な嗜好，知識を強化する\u003c/p\u003e\n\u003cp\u003e3つの重要な特徴について\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eemotional-awareness\u003c/li\u003e\n\u003cli\u003ePersonality-awareness\u003c/li\u003e\n\u003cli\u003eKnowledge-accessibility\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/jj8cey5y.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e3つのサブトピックを扱う\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ePerceiving and expressing emotion\u003c/li\u003e\n\u003cli\u003eCaring each individual\u003c/li\u003e\n\u003cli\u003eCasting into knowledge\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e過去10年ぶんほどをカバー\u003c/p\u003e\n\u003ch2\u003ePropaedeutic background\u003c/h2\u003e\n\u003cp\u003ebackboneとして使われているアーキテクチャの紹介\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eNeural language model\n1. RNN (LSTM, GRUなど)\n\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/ab1tzbka.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-css\"\u003e  \t\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e. Sequence-\u003cspan class=\"hljs-selector-tag\"\u003eto\u003c/span\u003e-sequence model\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/vxnsfxcb.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/j79vo4ch.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eRNN\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003elong short-term memory, LSTM\n入力・忘却・出力の3つのゲート\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003egated recurrent unit, GRU\ngated関数は通常シグモイド関数．勾配のスケールを制限し，複数回の時間ステップの後に爆発するようにする．\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eSeq2Seq\nmodualizedなシステムは，通常以下の4パートからなる：\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eNatural Language Understanding, NLU\n入力から構造情報を抽出する\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ea Dialogue State Tracker, DST\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ea Dialogue Polich, DP\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ea response generator\n先行モジュールすべての出力に基づいた応答を生成する．\u003c/p\u003e\n\u003cp\u003e別名，エンコーダ・デコーダモデル．\u003c/p\u003e\n\u003cp\u003e条件付き対話生成のモデル化にはおそらく最も広く使われているニューラルアーキテクチャ．\u003c/p\u003e\n\u003cp\u003eエンコーダ，デコーダはそれぞれ，通常RNNをベースとしている．\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eAttention mechanism\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/ccvc5cuj.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs\"\u003eエンコーダが符号化できる最大ワード数の制限．入力単語数が大きくなると適切に符号化できない．\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e→デコーダが文脈の最も関連性の高い位置にアクセスすることが，この問題に効果的\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs\"\u003eRNNやseq2seqなどの，入力単語数の限界に対して対処できると，RNNやseq2seqでの問題の解消に一役買ったと紹介．\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eMemory networks; MMN\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/4dbq5m5d.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-wasm\"\u003eRNNの隠れ空間ではメモリは時間と共に更新されるものであるが，このメモリは小さかったり離れすぎていたりする．対話のような，文脈を理解するために長期的な記憶が必要な分野では上手くいかないことも．\n\n内部に必要な情報を保持できないため，外部メモリの機能を実装したのがこのMMN\n\n外部の\u003cspan class=\"hljs-keyword\"\u003ememory\u003c/span\u003e slotsに対して，attentionをかけてslotを更新するなどをする\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eVAE, Variational AutoEncoder\n条件付き確率分布に基づき，データ分布に近いように生成をする.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e通常のオートエンコーダ：\u003c/p\u003e\n\u003cp\u003e　入力→エンコーダが潜在変数を生成→デコーダ→出力（入力に似たものを生成）\u003c/p\u003e\n\u003cp\u003eVAE：\u003c/p\u003e\n\u003cp\u003e　潜在変数がN(0,1)の確率分布に従うと仮定する．\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-scss\"\u003e条件付き\u003cspan class=\"hljs-built_in\"\u003eVAE\u003c/span\u003e(CVAE)：条件付き確率分布 \u003cspan class=\"hljs-selector-tag\"\u003eP\u003c/span\u003e(出力応答 | 入力)をモデル化する．\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eGAN, Generative Adversarial Network\nGenerator G, Discriminator D　からなる．\u003c/p\u003e\n\u003cp\u003e画像生成から伝達学習までさまざまなタスクで大きな成果をあげている．\u003c/p\u003e\n\u003cp\u003eGenerator vs Discriminator：\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e生成器（G）は分類誤差を最大にして識別器（D）を欺くように訓練され，Dは分類誤差を最小にするように訓練される．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eRL, Reinforcement Learning（強化学習）\n以下のような一般的に用いられる目的関数は，対話システムの現実的な目標と明確な関連性を持っていない．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e尤度\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eELBO\nELBOを解く．\u003c/p\u003e\n\u003cp\u003e対話における各タイミングでの学習のフィードバックは，単語ごとではなく，まとまった文章が生成されたのちに与えられる．このため遅延報酬関数を使用できる．\u003c/p\u003e\n\u003cp\u003e論文の中でも，RLの重要性が何度も紹介されていた\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eAffective dialogue system\u003c/h2\u003e\n\u003cp\u003e感情は，反応と社会的行動で文化的な作用であり，これは人と環境の関係によって連続的に発展していくもの\u003c/p\u003e\n\u003cp\u003e感情のカテゴライズは，心理学者と哲学者の間でせわしく，長らく議論されてきた\u003c/p\u003e\n\u003cp\u003e感情は社会的な機能も持つ．そして情動は意思決定に関連する尺度である可能性が示唆されている．人間の会話行動のエミュレートだけでなく，システムとユーザとの感情的なつながりを強化することができる．\u003c/p\u003e\n\u003cp\u003e本書における affective dialogue system\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eperceiving emotion\u003c/li\u003e\n\u003cli\u003eunderstanding emotion\u003c/li\u003e\n\u003cli\u003eexpressing and regulating emotion\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e↓\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eemotion-awareness\n文脈の中の感情の表現に関係する，対話中のユーザの感情状態を検出できなければならない．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eemotion-expressiveness\n生成された応答に感情情報を取り入れることに関係する．\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e感情に関する理論は，感情の挿入がユーザとの感情の結びつきを強くするという利点をサポートしてくれる\u003c/p\u003e\n\u003ch3\u003eEmotion analysis\u003c/h3\u003e\n\u003cp\u003e一般的には，多くのcomputational modelは3つのカテゴリーに分けられる\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003edimensional approach（次元的）\u003c/li\u003e\n\u003cli\u003ediscrete approach（離散的）\u003c/li\u003e\n\u003cli\u003eappraisal approach（評価的）\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eDimensional approach\u003c/p\u003e\n\u003cp\u003e感情をベクトル（[覚醒]と[静寂]を表すもの）として表現する．\u003c/p\u003e\n\u003cp\u003e次元空間を持つことで，異なる感情の間でも類似度を計算できるのが利点\u003c/p\u003e\n\u003cp\u003eDiscrete approace\u003c/p\u003e\n\u003cp\u003e感情をいくつかのカテゴリーに分類する．\u003c/p\u003e\n\u003cp\u003eカテゴリ数は設定によって異なってくる．（2，32，64，など．emojiで表したり）\u003c/p\u003e\n\u003cp\u003eAppraisal approach\u003c/p\u003e\n\u003cp\u003e感情と引き起こされたリアクションの関係について学習する\u003c/p\u003e\n\u003cp\u003e分布型\u003c/p\u003e\n\u003cp\u003e感情の別の表現方法．embeddingを使う．\u003c/p\u003e\n\u003cp\u003eメリット：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e感情の種類が連続的になり，補完が可能になる\u003c/li\u003e\n\u003cli\u003eDLの入力として直接利用できる\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこの利点は，感情のタイプを連続値として扱えること\u003c/p\u003e\n\u003cp\u003eDeep learningのinputとして扱えること\u003c/p\u003e\n\u003cp\u003eもう一つのタイプは感情を，実際の効果として重視する\u003c/p\u003e\n\u003cp\u003esatisfactionやpolitenessとして分類する\u003c/p\u003e\n\u003cp\u003e文や文脈から感情・感情を予測するタスク\u003c/p\u003e\n\u003cp\u003e会話が与えられた時，感情ラベルを事前に予測する＝条件付き確率分布の学習と同義\u003c/p\u003e\n\u003cp\u003easpect-base分析\u003c/p\u003e\n\u003cp\u003e目的：アスペクトと文の両方から感情ラベルを予測することを学習する．\u003c/p\u003e\n\u003cp\u003e文に複数のアスペクトが付与されているとして，その種類に応じて予測を行う？\u003c/p\u003e\n\u003cp\u003e対話システムによる感情ラベル予測では，現在の時間ステップまでの対話履歴しか見えないことがることに注意\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eChallenges\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e感情は曖昧な方法で表現される\n\u003cul\u003e\n\u003cli\u003eコンテクストから理由づけを必要とする\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e対話で現れた感情は，過去から継続していて，文脈的な感情の状態にとても依存している\n\u003cul\u003e\n\u003cli\u003e発話者自身もだが，そのパーティにも影響を受ける\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eさまざまなモダリティを合わせて感情を表している\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eEmotion-aware encoders\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/zrlg6ntb.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eEmotion-aware encoderは，感情に関連した情報をエンコードする\u003c/p\u003e\n\u003cp\u003e得られる文脈ベクトルにも感情に関連した情報が含まれる．\u003c/p\u003e\n\u003cp\u003eモジュール化されたフレームワークは，POMDPとしてモデル化したものとして扱える\u003c/p\u003e\n\u003cp\u003e追加の特徴量として感情のラベルを与えることで機能する\u003c/p\u003e\n\u003cp\u003eただし，テスト時は感情ラベルがない\u003c/p\u003e\n\u003cp\u003e→emotion detector（＝追加の感情検出器）を加えて，暗示的に感情のラベルを推測することで機能させる\u003c/p\u003e\n\u003ch3\u003eEmotion-expressive decoder\u003c/h3\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/w0fopt7s.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e感情的なレスポンスを促進する目的で使われる\u003c/p\u003e\n\u003cp\u003econtrollable variableとして直接感情を与える\u003c/p\u003e\n\u003cp\u003eモデルはCVAEやGAN，RLなどを使うことが多いらしい\u003c/p\u003e\n\u003cp\u003econtrollable variableの想定\u003c/p\u003e\n\u003cp\u003e一つまたは複数の潜在的な変数が応答の生成に対して強制力を持っていること\u003c/p\u003e\n\u003cp\u003eそしてそのような変数が存在していること\u003c/p\u003e\n\u003cp\u003e潜在的な対話状態をモデリングするのに自然なアーキテクチャはCVAE\u003c/p\u003e\n\u003cp\u003e学習の際，微分できないことが多いので，誤差をフィードバックするにはRLを使うのが重要\u003c/p\u003e\n\u003ch3\u003eDiscussion\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eChallenges\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e感情のラベルの不足\n\u003cul\u003e\n\u003cli\u003e対話のアノテーション処理に時間がかかるため，人手が不足．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eweak supervisions を用いることで緩和可能：事前に学習された感情ラベルを使うとか，複数のデータソースを組み合わせて規模を拡大するとか\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e感情の評価\n\u003cul\u003e\n\u003cli\u003e単語レベルでは感情の手がかりが微妙なこともある．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eユーザの本質的な感情と実際の認識にギャップがある可能性　→ユーザの誘導とギャップをノイズとして扱うこと．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e他の目的における感情のcompliance\u003c/li\u003e\n\u003cli\u003eターンレベルでのcontrollable variableと生成される単語の依存性\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003ePersonalized dialogue system; PDS\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/A-survey-on-empathetic-dialogue-systems/kip5j4e8.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003epersonalized informationは，話者の意図や継続的な状態を知覚したり，結果的に適したレスポンスを生成するのを成功させる鍵になる\u003c/p\u003e\n\u003ch3\u003eUser modeling\u003c/h3\u003e\n\u003cp\u003eパーソナリティを表現する方法は，多くのパーソナリティ理論で重要になっている関心ごとである\u003c/p\u003e\n\u003cp\u003eこのサーベイでは，user modelingの方法として，二つに分類される\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eidentity-based\u003c/li\u003e\n\u003cli\u003eknowledge-based\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eIdentity-based user modeling\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eもっともシンプルな方法で，identityを静的な属性として与える\u003c/p\u003e\n\u003cp\u003eidentity-basedの特徴量は，信頼性があり，情報抽出するための追加のステップを必要とせずに直接的に扱うことができる\u003c/p\u003e\n\u003cp\u003eidentity-basedの特徴量のソースは主に，registrationで収集したメタデータである\u003c/p\u003e\n\u003cp\u003epersona factsとidentity featuresはパーソナライズされた応答の生成に効果があるため，unstructured dataとstructured dataの双方を使う\u003c/p\u003e\n\u003cp\u003eidentity-basedをニューラルネットに入れるときは，embedding layerを用いて，連続値のdense vectorにする\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge-based user modeling\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003estructured dataとpredefined rulesを用いる\u003c/p\u003e\n\u003cp\u003eidentity-basedと比べると，これはユーザのメタデータの制限がない\u003c/p\u003e\n\u003cp\u003estructuredとunstructured information data sourceを両方使用できる\u003c/p\u003e\n\u003cp\u003ePersonalized reasoningというタスク\u003c/p\u003e\n\u003cp\u003eknowledge baseから事実を取り出すことを目的にしている\u003c/p\u003e\n\u003ch3\u003ePersonalized response generation\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003egenerative methods\u003c/li\u003e\n\u003cli\u003eretrieval-based methods (ranking methods)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ePDSのメインの目標は，適した応答だけでなく，ユーザのじゅう雨よう（重要？）な知識に基づいた応答を生成すること\u003c/p\u003e\n\u003cp\u003eここでは二つのサブトピックの紹介があった\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003epersonality-aware model\u003c/li\u003e\n\u003cli\u003epersonality-infused model\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003ePersonality-aware model\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eユーザのパーソナリティ，もしくは会話のパーティに適応した応答を生成する\u003c/p\u003e\n\u003cp\u003eその応答には，ユーザの嗜好が含まれるということである\u003c/p\u003e\n\u003cp\u003eユーザのプロファイルや会話履歴は，話者の記憶の中で異なる役割をはたす→メモリ(MMNの話など)\u003c/p\u003e\n\u003cp\u003eシステムの中で多くのユーザの参加する大規模な環境においては，それぞれのユーザのタイプに十分なデータを持つのが難しくなりうる\u003c/p\u003e\n\u003cp\u003e→ユーザの知識を収集したり，転移することは可能\u003c/p\u003e\n\u003cp\u003e以降はtransfer learningの話がなされていた．RLも同様に使えるとのこと\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePersonality-infused agent dialogue systems\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e会話をスムーズで，柔軟で自然に行うために，システムにpersonalityを与える\u003c/p\u003e\n\u003cp\u003e3つのコンポーネントからなる\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eProfiler Detector\u003c/li\u003e\n\u003cli\u003eBidirectional Decoder\u003c/li\u003e\n\u003cli\u003ePosition Detector\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eProfile Detector\nどのprofileのvalueが生成された応答の中で言及されるべきかを選ぶ\u003c/p\u003e\n\u003cp\u003eMLPを使う\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBidirectional Decoder\nprofile valueが言及される中で応答を生成する目的のデコーダ\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePosition Detector\ndecoding positionのスタート位置を予測する\u003c/p\u003e\n\u003cp\u003eここで使うコンポーネントはbidirectional decoderで監視するように設計される\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003ePosition Detectorは，training dataをかえる性能があるらしい\u003c/p\u003e\n\u003cp\u003epre-specificなエージェントのprofileに沿った応答生成ができるモデルを提供してくれる\u003c/p\u003e\n\u003cp\u003epersona representationの後，以下の提案があった\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003ePersona Aware Attention\nそれぞれのdecoding positionに対するAttention weightsを生成する\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePersona Aware Bias\nデコーダのoutput layerの分散表現を差し込むことで生成分布を評価する\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAttentive Memory Network; AMNの提案\u003c/p\u003e\n\u003cp\u003eおそらく個人だけでなく，所属するグループの影響を加味するためのモデルだと思う\u003c/p\u003e\n\u003cp\u003eコンポーネント二つ\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAttentive Encoders\u003c/li\u003e\n\u003cli\u003eKnowledge-Store Memory Module\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3\u003eKnowledge-based dialogue system\u003c/h3\u003e\n\u003cp\u003ecurrent dialogue, personal background, external knowledge sourceからきた知識から探したり，コミュニケーションをとるプロセスを経る\u003c/p\u003e\n\u003cp\u003e→ knowledge graphなど\u003c/p\u003e\n\u003cp\u003eexternal knowledgeは重要な役割をはたすことができる\u003c/p\u003e\n\u003cp\u003eこのシステムはたいてい二つの追加のコンポーネントを持つ\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eknowledge encoder\u003c/li\u003e\n\u003cli\u003eknowledge-aware decoder\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eこれらによりcontextとexternal knowledgeの両方で応答に条件付けできる\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge encoding\u003c/strong\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eStructured knowledge\nlanguage understandingで重要な役割\u003c/p\u003e\n\u003cp\u003e扱うモデルの変遷\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBoW→Sequence→Data cell→Recursive graph\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs\"\u003e人の前処理やルールベースなどでフィルターをかけるステップが必要\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e\n\u003cp\u003eUnstructured knowledge\n制約が少ないため，扱えるデータの量が多い\u003c/p\u003e\n\u003cp\u003e分散表現に変換できるので，end-to-endのモデル\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cstrong\u003eKnowledge-aware decoding\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ehistorical knowledgeとしてknowledge source→contextなどとinputを一緒に入力にかける\u003c/p\u003e\n\u003cp\u003einputはembeddingされたもの\u003c/p\u003e\n\u003cp\u003e応答生成における2種類の知識ソース：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e対話の履歴から得られるもの\u003c/li\u003e\n\u003cli\u003e事前予知的知識\u003c/li\u003e\n\u003c/ul\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eKnowledge attention\nknowledge encoderの出力であるknowledge embeddingを使って，応答の生成に条件付けをする\u003c/p\u003e\n\u003cp\u003e文脈とknowledge embeddingのセットが与えられたら，関連する知識を読み取るか再認識する必要があり，それが応答性性の条件付けに使われる．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eCopy\nattention mechanismをベースにしている\u003c/p\u003e\n\u003cp\u003eattentionを入力から単語を選び，コピーするためのポインターに使う\u003c/p\u003e\n\u003cp\u003eseq2seqをコピー機構で拡張することで，検索ベースの手法より優れた性能を発揮する事が示された．\u003c/p\u003e\n\u003cp\u003e単語は決められた単語の分布から取るか，knowledge baseからの単語をコピーすることで生成される\u003c/p\u003e\n\u003cp\u003e高階層のmemory architectureの学習の提案をしている人もいる\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eFuture direction\u003c/h2\u003e\n\u003cp\u003eempathetic dialogue systemに残る研究課題：\u003c/p\u003e\n\u003cp\u003epersonalization, knowledge, and emotion の要素の組み合わせによる包括的な共感システムの構築なんかはあまり行われていなかった．\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eMulti-goal Management\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003eコミュニケーションには多くのobjective（目的）が乗っている\n→複数の目的によって過負荷になる事がある．感情や性格，知識を取り入れることでさらに顕著に．\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003edialogue agentは全ての異なる側面に取り入れるべき\nすべての異なる側面を考慮する必要があるから↓\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003euser's inherent states, communicating information, minimizing the communicative effortsなど\nこれらを同時に達成するための最適解をいかに効率的に探索するかが問題となる\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eExplicit Affective Policy\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e感情は明示的な行動と考えられる\u003c/li\u003e\n\u003cli\u003eagentが他の人の感情をミラーリングしたり，共感を示したりする\n並列共感（相手の感情のミラーリング）と反応的共感に対して異なる戦略を取る事ができる．\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eLong-term Empathy Modeling\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e対話中での共感はlong-termである\u003c/li\u003e\n\u003cli\u003eemotion, personality, knowledgeを静的，動的の双方で評価して，long-termで対応する\n静的で動的：安定的なベースを持ちながら，変化もしやすい．長期的なデータ収集において変化に適応する会話モデルの構築が課題．\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDialogue Generation with Target-dependent Emotion\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e感情は，話者と会話の参加者にアタッチされた特定の次元であるとして，target-dependent emotionをuser modelingに合わせる\n感情とターゲットの依存関係が省略されてきた．ターゲットに依存する感情をユーザモデリングと組み合わせることが望まれる（感情と人格の2次元の相関　←共同でモデル化する必要性）．\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDialogue Generation with Emotion Knowledge\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003esentimental, emotionalな知識を使って，感情の状態を認識する\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eIncorporate Cues from Multimodal Input\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e複数のモダリティを使って共感を示す\u003c/li\u003e\n\u003cli\u003ei.e. audio signals, body gestures\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePersonalized Diversifying Dialogue Generation\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eユーザに合わせて，生成する応答や検索する応答をカスタマイズする\u003c/li\u003e\n\u003cli\u003eグループごとに多様性はあるが，同グループ内での多様性はかけるのが問題\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eDeeper Conversation and User modeling\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e与えられたユーザからのクエリに対して，統計的にもっともらしい回答を取り出すのがシンプルなメインの目標なのが現在\u003c/li\u003e\n\u003cli\u003e将来的には，会話ごとにモデルを作ったり，どのようにユーザの感情が変わるかを理解したり，重要な会話や嗜好を覚えたり，ユーザのニーズや意図を汲み取る以上のことをするようになる(?)\u003c/li\u003e\n\u003cli\u003e↑そのためのサブタスク\n\u003col\u003e\n\u003cli\u003esarcasm detection（皮肉検出）\u003c/li\u003e\n\u003cli\u003etime expression（時間表現）\u003c/li\u003e\n\u003cli\u003enamed entity recognition（固有表現）\u003c/li\u003e\n\u003cli\u003eanaphora resolution\u003c/li\u003e\n\u003cli\u003emicrotext normalization\u003c/li\u003e\n\u003cli\u003eetc\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e@article{MA202050,\ntitle = {A survey on empathetic dialogue systems},\njournal = {Information Fusion},\nvolume = {64},\npages = {50-70},\nyear = {2020},\nissn = {1566-2535},\ndoi = {\u003ca href=\"https://doi.org/10.1016/j.inffus.2020.06.011%7D\"\u003ehttps://doi.org/10.1016/j.inffus.2020.06.011}\u003c/a\u003e,\nurl = {\u003ca href=\"https://www.sciencedirect.com/science/article/pii/S1566253520303092%7D\"\u003ehttps://www.sciencedirect.com/science/article/pii/S1566253520303092}\u003c/a\u003e,\nauthor = {Yukun Ma and Khanh Linh Nguyen and Frank Z. Xing and Erik Cambria},\nkeywords = {Artificial intelligence, Affective computing, Dialogue systems},\nabstract = {Dialogue systems have achieved growing success in many areas thanks to the rapid advances of machine learning techniques. In the quest for generating more human-like conversations, one of the major challenges is to learn to generate responses in a more empathetic manner. In this review article, we focus on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge. Accordingly, we identify three key features that underpin such systems: emotion-awareness, personality-awareness, and knowledge-accessibility. The main goal of this review is to serve as a comprehensive guide to research and development on empathetic dialogue systems and to suggest future directions in this domain.}\n}\u003c/p\u003e\n\u003c/blockquote\u003e","Title":"【論文まとめ】A survey on empathetic dialogue systems","Date":"2023-05-22","Category":"論文","Tags":["survey","dialogue system","empathetic dialogue system"],"Authos":"ゆうぼう","Slug":"A-survey-on-empathetic-dialogue-systems","Thumbnail":"/images/thumbnails/A-survey-on-empathetic-dialogue-systems.png","Description":"A survey on empathetic dialogue systemsのまとめ","Published":true}],"tag":"empathetic dialogue system","categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","Contrastive Learning","CSS","Dialogue Structure Learning","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLG","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","聞き手反応","超解像"],"pages":1,"page":1},"__N_SSG":true},"page":"/tag/[tag]/[page]","query":{"tag":"empathetic dialogue system","page":"1"},"buildId":"xqdRocZsV0g1E4ufbXnYY","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>