<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><title>ゆうぼうの書跡棚</title><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，データ分析関連やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta property="og:title" content="ゆうぼうの書跡棚"/><meta property="og:type" content="website"/><meta property="og:url" content="https://yuta0306.github.io"/><meta property="og:image" content="https://yuta0306.github.io/images/default.png"/><meta property="og:site_name" content="ゆうぼうの書跡棚"/><meta property="og:description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，データ分析関連やPython, JavaScriptによる開発についてまとめます．"/><meta name="twitter:card" content="summary_large_image"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><title>「データ分析」1ページ目 | ゆうぼうの書跡棚</title><meta name="next-head-count" content="3"/><link rel="preload" href="/_next/static/css/1e60eb7060c938e94058.css" as="style"/><link rel="stylesheet" href="/_next/static/css/1e60eb7060c938e94058.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd92aa6f5bef62d1d5fd.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd92aa6f5bef62d1d5fd.css" data-n-p=""/><noscript data-n-css=""></noscript><link rel="preload" href="/_next/static/chunks/webpack-189c53927ffd3caf09c3.js" as="script"/><link rel="preload" href="/_next/static/chunks/framework-fb2dd7aba3784ca05084.js" as="script"/><link rel="preload" href="/_next/static/chunks/main-71948af4b0f09c0fc30e.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/_app-20aa38351985c99d4121.js" as="script"/><link rel="preload" href="/_next/static/chunks/996-fa0b52be06882e958afa.js" as="script"/><link rel="preload" href="/_next/static/chunks/382-a31ac978fd260471df46.js" as="script"/><link rel="preload" href="/_next/static/chunks/pages/tag/%5Btag%5D/%5Bpage%5D-c8f22dfc6a27b7b1a686.js" as="script"/></head><body><div id="__next"><div class="header_container__3KxYs"><div class="header_container__inner__yjsY5"><header class="header_header__2L2uC"><a href="/"><h1 class="header_header__title__2PM5D">ゆうぼうの書跡棚</h1></a></header><div class="header_hamburger__2m01s"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1Q-5G"><ul class="header_nav__list__1evri"><li class="header_nav__item__3FLhh"><a href="/about">About</a></li><li class="header_nav__item_active__2oXbU"><a href="/">Blog</a></li><li class="header_nav__item__3FLhh"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__3K26U"><ul class="header_category__items__1jOIE"><a class="header_category__item__9QajB" href="/category/Web/1"><li>Web</li></a><a class="header_category__item__9QajB" href="/category/JavaScript/1"><li>JavaScript</li></a><a class="header_category__item__9QajB" href="/category/Competition/1"><li>Competition</li></a><a class="header_category__item__9QajB" href="/category/Cloud/1"><li>Cloud</li></a><a class="header_category__item__9QajB" href="/category/Linux/1"><li>Linux</li></a><a class="header_category__item__9QajB" href="/category/Python/1"><li>Python</li></a><a class="header_category__item__9QajB" href="/category/ML/1"><li>ML</li></a><a class="header_category__item__9QajB" href="/category/Go/1"><li>Go</li></a><a class="header_category__item__9QajB" href="/category/SQL/1"><li>SQL</li></a></ul></div><div class="main_main__EJIDe"><div class="main_main__container__2mPxL"><main class="main_main__container__inner__76cC6" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__grid__2j5sZ"><div class="card_card__container__1HXVB"><a href="/mscup-feedback"><div class="card_card__1XHqb"><div class="card_card__thumbnail__3rV6C"><img src="/images/thumbnails/mscup.jpg" alt="🛰MScupで11位だったけど，やったことまとめまくる" class="card_card__thumbnail__img__1f8pd" loading="lazy"/></div><div><div class="card_card__meta__3UO09"><time dateTime="2022-02-13" itemProp="published">2022-02-13</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__26MYL">🛰MScupで11位だったけど，やったことまとめまくる</h2></div></div></a></div><div class="card_card__container__1HXVB"><a href="/atmacup10-feedback"><div class="card_card__1XHqb"><div class="card_card__thumbnail__3rV6C"><img src="/images/thumbnails/atma%2310.png" alt="atmaCup#10大反省会(Public: 137位/Private: 130位)" class="card_card__thumbnail__img__1f8pd" loading="lazy"/></div><div><div class="card_card__meta__3UO09"><time dateTime="2021-03-14" itemProp="published">2021-03-14</time><a itemscope="" role="author" itemType="http://schema.org/Person" href="/about"><span itemProp="name">ゆうぼう</span></a></div><h2 class="card_card__title__26MYL">atmaCup#10大反省会(Public: 137位/Private: 130位)</h2></div></div></a></div><div class="paginager_container__3j3Qx"><ul class="paginager_container__pagers__1oXIX"><a class="paginager_container__pager__268RS" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1"><li class="paginager_container__pager__page__3c5sS">&lt;&lt;</li></a><li class="paginager_container__pager_deactive__3v2QM">&lt;</li><li class="paginager_container__pager_active__Fm_0T">1</li><li class="paginager_container__pager_deactive__3v2QM">&gt;</li><a class="paginager_container__pager__268RS" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1"><li class="paginager_container__pager__page__3c5sS">&gt;&gt;</li></a></ul></div></div></main><aside class="main_sidebar__2Zhb0"><div class="shortbio_container__11Rzx" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__38jvW"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__ZbrSN" itemscope="" itemProp="name">ゆうぼう</h3><p class="shortbio_container__paragraph__2Sxgf"></p><p class="shortbio_container__paragraph__2Sxgf">地方国立大学B3のナマケモノです．</p><p class="shortbio_container__paragraph__2Sxgf">最近ユーモア検出の研究を始めました(NLP)．</p><p class="shortbio_container__paragraph__2Sxgf">最終的には対話システムに応用していく研究をしていく予定です．</p><p class="shortbio_container__paragraph__2Sxgf">好きな技術は，FlaskとPytorchです．このブログはNext.jsで書いていて，Next.jsもスキ．</p><p class="shortbio_container__paragraph__2Sxgf"></p><p class="shortbio_container__paragraph__2Sxgf">Kaggle等のデータ分析コンペも一緒に楽しみたいです．</p><p class="shortbio_container__paragraph__2Sxgf"></p></div><div class="followme_container__3qQyP"><h3 class="followme_container__header__1IBfE">Follow Me</h3><div class="followme_container__links__3SmDO"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class=" adsbygoogle" style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__XA7T4"><h3 class="categories_container__header__1HMsA">Categories</h3><div class="categories_container__links__2_sET"><a class="categories_container__link__3wXMA" href="/category/Web/1">Web</a><a class="categories_container__link__3wXMA" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__3wXMA" href="/category/Competition/1">Competition</a><a class="categories_container__link__3wXMA" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__3wXMA" href="/category/Linux/1">Linux</a><a class="categories_container__link__3wXMA" href="/category/Python/1">Python</a><a class="categories_container__link__3wXMA" href="/category/ML/1">ML</a><a class="categories_container__link__3wXMA" href="/category/Go/1">Go</a><a class="categories_container__link__3wXMA" href="/category/SQL/1">SQL</a></div></div><div class="tags_container__2j2ju"><h3 class="tags_container__header__3imWv">Tags</h3><div class="tags_container__links__3WNOQ"><a class="tags_container__link__3DgcP" href="/tag/Apache/1">Apache</a><a class="tags_container__link__3DgcP" href="/tag/Appium/1">Appium</a><a class="tags_container__link__3DgcP" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__3DgcP" href="/tag/AWS/1">AWS</a><a class="tags_container__link__3DgcP" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__3DgcP" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__3DgcP" href="/tag/Colab/1">Colab</a><a class="tags_container__link__3DgcP" href="/tag/conda/1">conda</a><a class="tags_container__link__3DgcP" href="/tag/CSS/1">CSS</a><a class="tags_container__link__3DgcP" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__3DgcP" href="/tag/Flask/1">Flask</a><a class="tags_container__link__3DgcP" href="/tag/Go/1">Go</a><a class="tags_container__link__3DgcP" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__3DgcP" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__3DgcP" href="/tag/HTML/1">HTML</a><a class="tags_container__link__3DgcP" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__3DgcP" href="/tag/JSON/1">JSON</a><a class="tags_container__link__3DgcP" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__3DgcP" href="/tag/Linux/1">Linux</a><a class="tags_container__link__3DgcP" href="/tag/Mac/1">Mac</a><a class="tags_container__link__3DgcP" href="/tag/make/1">make</a><a class="tags_container__link__3DgcP" href="/tag/map/1">map</a><a class="tags_container__link__3DgcP" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__3DgcP" href="/tag/ML/1">ML</a><a class="tags_container__link__3DgcP" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__3DgcP" href="/tag/NLP/1">NLP</a><a class="tags_container__link__3DgcP" href="/tag/node.js/1">node.js</a><a class="tags_container__link__3DgcP" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__3DgcP" href="/tag/Python/1">Python</a><a class="tags_container__link__3DgcP" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__3DgcP" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__3DgcP" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__3DgcP" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__3DgcP" href="/tag/SISR/1">SISR</a><a class="tags_container__link__3DgcP" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__3DgcP" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__3DgcP" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__3DgcP" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__3DgcP" href="/tag/zsh/1">zsh</a><a class="tags_container__link__3DgcP" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__3DgcP" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__3DgcP" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__3DgcP" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__3DgcP" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class=" adsbygoogle" style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__3LSES"><div class="footer_footer__inner__1CIwJ"><div><a class="footer_footer__link__3Lvn-" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__37duk"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__1-CQk"><small>Powered by <a target="_blank" class="footer_footer__small__link__17tg2" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"TaggedPostData":[{"contentHtml":"\u003cp\u003e※諸注意\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003ecf. @solafune(\u003ca href=\"https://solafune.com\"\u003ehttps://solafune.com\u003c/a\u003e) コンテストの参加以外を目的とした利用及び商用利用は禁止されています。商用利用・その他当コンテスト以外で利用したい場合はお問い合わせください。(\u003ca href=\"https://solafune.com\"\u003ehttps://solafune.com\u003c/a\u003e)\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://solafune.com/\"\u003eSolafune\u003c/a\u003eというプラットフォームでのMScupで低解像度を超解像化する珍しいコンペが出てきて，楽しそうだと（実際楽しかったけど）2ヶ月従事したものの11位で終わってしまいました😭\u003c/p\u003e\n\u003cp\u003eでも，学べることがたくさんあったし，画像系コンペに出てこなかったので，画像系でも活かせそうな知見が得られて楽しいコンペでした．\u003c/p\u003e\n\u003cp\u003e実験してみて効いたこと効かなかったことや学んだことをまとめます．\u003c/p\u003e\n\u003ch2\u003e結果報告\u003c/h2\u003e\n\u003cp\u003e先に結果を報告してしまいます．\u003c/p\u003e\n\u003cp\u003eタイトルですでに出オチですが，\u003cstrong\u003e11位フィニッシュ\u003c/strong\u003eでした🎉\u003c/p\u003e\n\u003cp\u003ePublicもPrivateも共に11位だったので，Trust CV，Trust LBなコンペだったと思います．そのためとても取り組みやすかったです．\u003c/p\u003e\n\u003cp\u003eまた，ライセンス表記に対してシビアではありましたが，運営さんの方から使っていいライセンスが詳しく話されていたので，これに関しても取り組みやすかったと思っています．\u003c/p\u003e\n\u003cp\u003e結果で見れば悔しい結果ですが，総評してとても楽しかったです🤗\u003c/p\u003e\n\u003ch2\u003eコンペ概要\u003c/h2\u003e\n\u003cp\u003e概要は以下です．\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e衛星画像を活用する際の課題の一つに「解像度」の問題があります。人工衛星は広域を撮影できる一方で、解像度の低さがボトルネックになります。近年、解像度が高い衛星画像の提供・販売が始まっていますが、利用可能な高解像データは世界で最も解像度が高い画像でも30cm程度です。また、高解像度のデータは値段が高く、利用規約にも様々な制限が課せられています。さらに、現時点では高解像度の画像データは法律で利用を禁止している国もあります。 そのため、今回のコンテストでは高解像度のデータを安く利用するための手段として、超解像を扱います。将来的に高解像度の衛星画像を扱えるようになることを想定して、本コンテストでは25 cm解像度の画像データを扱います。「超解像」という技術を通して、衛星データや航空写真などの地理空間データの社会実装が加速することを期待しています。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e与えられて低解像度の画像に対して，高解像化をかけるモデル，アルゴリズムを作成し，SSIMが高くすることが課題でした．\u003c/p\u003e\n\u003cp\u003eSSIMは以下で表され，これを最大化することを目的とします．\u003c/p\u003e\n\u003cp\u003e$$\nSSIM(x, y) = \\frac{(2\\mu_x\\mu_y + c_1)(2\\sigma_{xy} + c_2)}{(\\mu_x^2 + \\mu_y^2 + c_1)(\\sigma_x^2 + \\sigma_y^2 + c_2)}\n$$\u003c/p\u003e\n\u003ch2\u003eMy Solution\u003c/h2\u003e\n\u003cp\u003e僕のSolutionは大したことができませんでした．というのも，たくさんの実験を試したのですが，ほとんどうまくいかず悪化し，結局Seed Averagingなどの手抜きアイデアが最終サブになってしまったからです．\u003c/p\u003e\n\u003cp\u003eとは言いつつも，おそらく僕独自の手法も入っているのではないかと思うので参考になればと思います．\u003c/p\u003e\n\u003ch3\u003eモデル概要\u003c/h3\u003e\n\u003cp\u003e訓練時は以下のようなモデル設計になっています．\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/mscup/mscup_train.jpg\" alt=\"訓練時モデル\"\u003e\u003c/p\u003e\n\u003cp\u003e推論時は\u003cstrong\u003eSeed Averaging\u003c/strong\u003eと**TTA（Test Time Augmentation）**を利用して，テストデータでの推論時にロバストに推論ができるようにしました．Seed Averagingは5つくらいのモデルの平均をとったはずです．\u003c/p\u003e\n\u003cp\u003eSeed AveragingやTTAは正直つまらない解法だと思っていますが，\u003cstrong\u003eSobel Filterを利用したLoss関数\u003c/strong\u003eや\u003cstrong\u003eCutMixやCutout\u003c/strong\u003eなどのData Augmentationが個人的な解法のウリではあります．\u003c/p\u003e\n\u003cp\u003eまた，僕がコンペを進める中での一番力を入れたことは，\u003cstrong\u003eLoss関数による精度向上\u003c/strong\u003eです．モデルも比較しましたが，結局SOTAモデルのSwinIRが圧巻で，Augmentationも思ったほど効かなかったので，Loss関数で制御することが最もの試みでした．これは独自の取り組みだと思っています（思いたい）\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"#%E5%AE%9F%E9%A8%93%E4%B8%AD%E3%81%AE%E8%AA%B2%E9%A1%8C%E6%84%9F%E3%81%A8%E5%B7%A5%E5%A4%AB\"\u003e次のセクション\u003c/a\u003eで，なぜその実装をしたかと結果を話したいと思います．\u003c/p\u003e\n\u003ch3\u003e実験中の課題感と対処法\u003c/h3\u003e\n\u003cp\u003e実験している中での課題をまずは簡単に．\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%81%8C%E5%B0%91%E3%81%AA%E3%81%84\"\u003eデータセットが少ない\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e画像が大きいので，クロップすればデータはたくさんあるのですが，多様性という面では多いとは言えなかったかもしれない．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e回転のAugmentationを加えるとノイズになる\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eエッジの再現性が重要となる超解像タスクでは，回転後のギザギザがノイズになってしまう．\u003c/li\u003e\n\u003cli\u003e初めて知ったけど， 超解像タスクでは90度単位での回転が基本動作．画像見比べてなるほどってなった．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e超解像時にエイリアシングが起きたとき，エッジの向きに再現性がない\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eデータを見ていてこれが問題と感じて，Sobel Filterを施そうと...\u003c/li\u003e\n\u003cli\u003e細くは改めて話します．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAugmentationなんでもいいと思いきや，CutBlurやMixupはノイズだった\n\u003cul\u003e\n\u003cli\u003e実装の苦労の割に大幅悪化で辛かった...\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eそれでは上記について，細かく述べていこうと思います．\u003c/p\u003e\n\u003ch4\u003eデータセットが少ない\u003c/h4\u003e\n\u003cp\u003e訓練データは60シーンあり，クロップすればデータは多く感じるものの，やはり多様性という時点では少ないなぁという印象でした．\u003c/p\u003e\n\u003cp\u003e上位者の公開Solutionでは外部データの利用が鍵になったという指摘もあり，ここの調べを怠ったのが大敗につながってしまったのかなとも思っています．\u003c/p\u003e\n\u003cp\u003eそうは言っても全く対処しなかったわけではなく，「\u003ca href=\"https://arxiv.org/abs/2004.00448\"\u003eRethinking Data Augmentation for Image Super-resolution: A Comprehensive Analysis and a New Strategy\u003c/a\u003e」で提案されたData Augmentationの手法をPytorchパイプラインに合うように再実装し，実験はしました．\u003c/p\u003e\n\u003cp\u003e効き目は以下のような感じでした．\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e手法\u003c/th\u003e\n\u003cth\u003e説明\u003c/th\u003e\n\u003cth\u003e効き目\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003eCutBlur\u003c/td\u003e\n\u003ctd\u003e低解像度に高解像度の画像を部分的に差し込む（またはその逆）\u003c/td\u003e\n\u003ctd\u003e×\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eCutout\u003c/td\u003e\n\u003ctd\u003e一定確率でピクセル値を0にする\u003c/td\u003e\n\u003ctd\u003e△\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eCutMix\u003c/td\u003e\n\u003ctd\u003e異なる画像を部分的に差し込む\u003c/td\u003e\n\u003ctd\u003e○\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eMixup\u003c/td\u003e\n\u003ctd\u003ebeta分布に従って異なる画像を混合する\u003c/td\u003e\n\u003ctd\u003e×\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eCutMixup\u003c/td\u003e\n\u003ctd\u003eCutMixとCutupを同時に行う\u003c/td\u003e\n\u003ctd\u003e×\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eBlend\u003c/td\u003e\n\u003ctd\u003e一様分布に従ってサンプリングされた色を混合する\u003c/td\u003e\n\u003ctd\u003e△\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eRGBPermutation\u003c/td\u003e\n\u003ctd\u003eRGBの順番を変える\u003c/td\u003e\n\u003ctd\u003e△\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e実際に効いているかはそこまで詳しく見ることはできていませんが，スコアや生成された高解像度画像を見ているとこんな感じだったと思います．\u003c/p\u003e\n\u003cp\u003e効き目の詳細は改めて話します．\u003c/p\u003e\n\u003ch4\u003e回転のAugmentationを加えるとノイズになる\u003c/h4\u003e\n\u003cp\u003eこれは最初気づかなくて，エッジがめちゃくちゃ鈍った画像が生成されたので分析した結果わかったことです．\u003c/p\u003e\n\u003cp\u003e画像ドメインを持っている人ならば当たり前に感じてしまうかもしれませんが，画像にドメインのない人にとっては最後まで気づかなくてもおかしくなかったと思っています．\u003c/p\u003e\n\u003cp\u003eライブラリの仕様でも，回転を加える関数には，\u003cem\u003einterpolation\u003c/em\u003eなどのデータ補間のための引数があるはずです．\u003c/p\u003e\n\u003cp\u003e例えば\u003cem\u003etorchvision\u003c/em\u003eですが，ランダムでの回転は以下で実装されます．\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cspan\u003eimport\u003c/span\u003e torchvision.transforms \u003cspan\u003eas\u003c/span\u003e T\n\n\u003cspan\u003e# ニアレストネイバーでの補間\u003c/span\u003e\ntransforms = T.RandomRotation(degrees=\u003cspan\u003e180\u003c/span\u003e, interpolation=T.InterpolationMode.NEAREST)\n\u003cspan\u003e# バイリニアでの補間\u003c/span\u003e\ntransforms = T.RandomRotation(degrees=\u003cspan\u003e180\u003c/span\u003e, interpolation=T.InterpolationMode.BILINEAR)\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eこの実装を見る限りでも，エッジの部分が補間されることで元の入力画像との再現が取れなくなってしまうことは想像できると思います．\u003c/p\u003e\n\u003cp\u003eこれは学びでしたが，超解像タスクにおいては，\u003cstrong\u003e回転のAugmentationは90度単位\u003c/strong\u003eというのが主流のようでした．\u003c/p\u003e\n\u003ch4\u003e超解像時にエイリアシングが起きたとき，エッジの向きに再現性がない\u003c/h4\u003e\n\u003cp\u003e本当は画像を見せた方が早いのですが，今回のコンペで使用された画像は公開できないので，手書きで頑張って表現しようと思います．\u003c/p\u003e\n\u003cp\u003e田んぼみたいに，ある程度イネを植えている方向に規則的な向きがあるような感覚を想像してください．\u003c/p\u003e\n\u003cp\u003e実験中下のような画像が生成されてしまいました．\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/mscup/edge.png\" alt=\"エッジが再現できない生成画像\"\u003e\u003c/p\u003e\n\u003cp\u003eSSIMを最適化するのですが，\u003ca href=\"https://kornia.readthedocs.io/en/latest/index.html\"\u003ekornia\u003c/a\u003eで実装されていた\u003cem\u003eSSIM Loss\u003c/em\u003eでは，入力画像をGaussian Filterで平滑化してからSSIMの計算をかけていたので，ぼやけた状態でうまくreconstructできるかを学習してしまっていたのだと思います．\u003c/p\u003e\n\u003cp\u003eそこで僕は追加で\u003cem\u003eSmooth L1 Loss\u003c/em\u003eをさらに追加しました．こちらはピクセルごとでロスが計算されるので細かいところまで再現できるかなと思ったのですが，MSEなどのピクセルを見るLoss関数は画像全体がぼやけてしまうらしいです．\u003c/p\u003e\n\u003cp\u003e結果行き着いた発想が，「\u003cstrong\u003eエッジに対してLossを計算してしまえばいいじゃない？？\u003c/strong\u003e」でした．\u003c/p\u003e\n\u003cp\u003eこれは結果的にスコア微増に起因したのですが，前に示した図のようなエイリアシングが取れていることが多く，実装と結果が直感的だったので最後まで採用しました．数学的に正しい感じは全くありませんが，なんかうまくいったので（正しいかは知りません．こいつほんまに微分可能なんか？ってお気持ちのままやってました笑）\u003c/p\u003e\n\u003cp\u003e実装上は，Sobel Filterをかけて，エッジ抽出された画像に対してSmooth L1 Lossを計算するように計算しました．\u003c/p\u003e\n\u003cp\u003e当時の実装を下記に載っけておきます．\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\u003cspan\u003e\u003cspan\u003eclass\u003c/span\u003e \u003cspan\u003eMeanSobelError\u003c/span\u003e(\u003cspan\u003enn.Module\u003c/span\u003e):\u003c/span\u003e\n   \u003cspan\u003e\"\"\"\n   Sobel Gradient Loss Function\n   \"\"\"\u003c/span\u003e\n   \u003cspan\u003e\u003cspan\u003edef\u003c/span\u003e \u003cspan\u003e__init__\u003c/span\u003e(\u003cspan\u003eself,\n      normalized: \u003cspan\u003ebool\u003c/span\u003e = \u003cspan\u003eTrue\u003c/span\u003e,\n      eps: \u003cspan\u003efloat\u003c/span\u003e = \u003cspan\u003e1e-6\u003c/span\u003e,\n      reduction: \u003cspan\u003estr\u003c/span\u003e = \u003cspan\u003e'mean'\u003c/span\u003e,\n   \u003c/span\u003e):\u003c/span\u003e\n      \u003cspan\u003esuper\u003c/span\u003e(MeanSobelError, self).__init__()\n      self.\u003cspan\u003efilter\u003c/span\u003e = kornia.filters.Sobel(\n         normalized=normalized,\n         eps=eps,\n      )\n      self.lossfn = nn.SmoothL1Loss(reduction=reduction)\n\n   \u003cspan\u003e\u003cspan\u003edef\u003c/span\u003e \u003cspan\u003eforward\u003c/span\u003e(\u003cspan\u003eself,\n      y_pred: torch.Tensor,\n      y_true: torch.Tensor,\n   \u003c/span\u003e):\u003c/span\u003e\n      filtered_pred = self.\u003cspan\u003efilter\u003c/span\u003e(y_pred)\n      filtered_true = self.\u003cspan\u003efilter\u003c/span\u003e(y_true)\n\n      loss = self.lossfn(filtered_pred, filtered_true)\n      \u003cspan\u003ereturn\u003c/span\u003e loss\u003c/code\u003e\u003c/pre\u003e\n\u003ch4\u003eAugmentationなんでもいいと思いきや，CutBlurやMixupはノイズだった\u003c/h4\u003e\n\u003cp\u003eSISRタスクにおいて提案されていたAugmentationは全部効くだろう！というスタンスで，\u003cstrong\u003eコンペ終盤に時間をめちゃくちゃかけて実装\u003c/strong\u003eし，全部ごちゃ混ぜでやってみたのですが，スコアが激減....\u003c/p\u003e\n\u003cp\u003e幾つかパターンを試しましたが，CutBlurやMixup系はスコアの悪化の原因だったっぽいです．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMixup\n\u003cul\u003e\n\u003cli\u003e画像を割合で混合するので，エッジが鈍りがちになってしまいました．\u003c/li\u003e\n\u003cli\u003e車や車線など，エッジがはっきりした画像生成が必要だったため，ノイズになってしまったのかもしれません．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCutBlur\n\u003cul\u003e\n\u003cli\u003eこちらは単純にモデル作成が下手くそなのかも知れないです．\u003c/li\u003e\n\u003cli\u003eSwinIRに入力する前に，ダウンサンプリング層を用意する必要がありました．\u003c/li\u003e\n\u003cli\u003e↑これがうまく学習できず，生成される画像の色がおかしかったです．\n\u003cul\u003e\n\u003cli\u003e一応ダウンサンプリング層のみのwarmupなども試したが，うまく適合できず，この実装はボツに...（めっちゃ時間かけたのに...）\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこんな感じで効くAugmentationと効かないAugmentationがあったので，早い段階でこの実装と実験ができていれば，もっと豊かな実験ができたかなと反省しています．\u003c/p\u003e\n\u003cp\u003eAugmentationはいずれコンペ中は確実に試すことになると思うので，早めに効くかどうか先にやっておくといいのかも（？）\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e最後に今回のコンペで得た知見をまとめたいと思います．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAugmentationはタスク依存．課題感を意識したり，早めに取り組んだ方がいいかも（？）\u003c/li\u003e\n\u003cli\u003eデータセットのやりくりはサボらない\n\u003cul\u003e\n\u003cli\u003e外部データの調査とかEDAとか\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eスコアだけでなく，予測値も確認してみる\n\u003cul\u003e\n\u003cli\u003e今回はラベル分布とかそういうのではないので，生成画像もしっかり確認するなど\u003c/li\u003e\n\u003cli\u003eそれを割としっかりやったのでSobel Filterに行き着いたと思っています．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e論文とにかく読んでアイデアを得よう\n\u003cul\u003e\n\u003cli\u003eめっちゃ読んで，実装して効かなかったアイデアが8割くらいだったけど，楽しかったです．\u003c/li\u003e\n\u003cli\u003e今，大学で取り組んでいるNLPの研究にアイデアが入ったりしているので，やり切るって大事！\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e楽しむ！！！\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eコンペは序盤と終盤がとても辛いです．\n\u003cul\u003e\n\u003cli\u003e序盤：バグが取れない．公開のやつに勝てない．\u003c/li\u003e\n\u003cli\u003e終盤：スコアが伸び悩む．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eでも，やり切れば結果楽しい（MScupが楽しかった説に一票ですが😂）\u003c/li\u003e\n\u003cli\u003eCVやLBをおかずに飯が食えるぞ？\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e僕が今回のMScupを通して学んだことはこんなところでしょうか．次もしSolafuneのコンペに参加することがあれば，しっかり賞金圏に入りたいと思います！\u003c/p\u003e\n\u003cp\u003e最後に今回のコンペで使ったライブラリや実装したコードを載せて終わりにしたいと思います．\u003c/p\u003e\n\u003cp\u003eつらつらと思うところを書きましたが，最後まで読んでいただきありがとうございます．意見やご指摘などがありましたら，Twitterなどでご連絡ください．\u003c/p\u003e\n\u003ch2\u003eよく使ったライブラリなど\u003c/h2\u003e\n\u003cp\u003e今回のコンペでよく使えたライブラリなどを載っけておきます．\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kornia.readthedocs.io/en/latest/index.html\"\u003ekornia\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003essim lossやsobel filterなど，画像処理で手前実装が大変でかゆいところに手が届きました．今後も自分は使うことがありそうだと感じました．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/JingyunLiang/SwinIR\"\u003eSwinIR\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eSISRにおけるSOTAモデル．事前学習済みモデルが公開されており，重宝しました．一番強かった...\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://arxiv.org/abs/2108.10257\"\u003epaper\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://huggingface.co/models?other=image-super-resolution\"\u003eimage-super-resolution\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eさまざまなSuper Resolutionタスクでのモデルの再現実装をされています．\u003c/li\u003e\n\u003cli\u003e今回のコンペでは精度が微妙だったのでサブには使いませんでしたが，SISRタスクで遊びたい時に簡単に扱えると思います．\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePytorch Lightning\n\u003cul\u003e\n\u003cli\u003e単純にファン．もう楽\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePytorch\u003c/li\u003e\n\u003cli\u003ecv2\n\u003cul\u003e\n\u003cli\u003eRGBの順番気をつけましょう．これで2週間くらい無駄にしました笑笑\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e実装したコード\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/yuta0306/SRAugmentation\"\u003eSRAugmentation\u003c/a\u003eにて公開しています．\u003c/p\u003e\n\u003cp\u003e初めてGitHubでスターをもらって喜んでいました（小並感\u003c/p\u003e\n\u003cp\u003eCutBlurなど，Single Image Super ResolutionにおけるData Augmentationの手法を改めてPytorchのパイプラインに組み込めるように再実装したものです．\u003c/p\u003e\n\u003cp\u003eこちらの論文で提案されています．\u003ca href=\"https://arxiv.org/abs/2004.00448\"\u003eRethinking Data Augmentation for Image Super-resolution: A Comprehensive Analysis and a New Strategy\u003c/a\u003e\u003c/p\u003e\n","Title":"🛰MScupで11位だったけど，やったことまとめまくる","Date":"2022-02-13","Category":"Python","Tags":["データ分析","超解像","SISR","Super-Resolution","Pytorch"],"Authors":"ゆうぼう","Slug":"mscup-feedback","Thumbnail":"/images/thumbnails/mscup.jpg","Description":"MScupで低解像度を超解像化する珍しいコンペが出てきて，2ヶ月従事したけど11位で終わってしまいました．でも，学べることがたくさんあったし，画像系コンペに出てこなかったので，画像系でも活かせそうな知見が得られて楽しいコンペでした．実験してみて効いたこと効かなかったことや学んだことをまとめます．","Published":true},{"contentHtml":"\u003cp\u003eatmaCup#10に参加しました。しっかりとコンペにフルコミットしたのは今回が初めてなので、ほぼ初参加と言っていいでしょう。しかし、結果はPublic: 137位でPrivate: 130位(+7)というクソ雑魚結果に...。\u003c/p\u003e\n\u003cp\u003eこれは大反省会をして次に生かすことに他ならないということで久々にブログに記します。誰かのお役に立てれば嬉しいかなと思いながら、大反省をしていきます。\u003c/p\u003e\n\u003ch2\u003eとりあえず結果から\u003c/h2\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth align=\"left\"\u003e\u003c/th\u003e\n\u003cth align=\"left\"\u003eRANKING\u003c/th\u003e\n\u003cth align=\"left\"\u003eRMSLE SCORE\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003ePublic\u003c/td\u003e\n\u003ctd align=\"left\"\u003e137\u003c/td\u003e\n\u003ctd align=\"left\"\u003e1.0213\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd align=\"left\"\u003ePrivate\u003c/td\u003e\n\u003ctd align=\"left\"\u003e130(+7)\u003c/td\u003e\n\u003ctd align=\"left\"\u003e1.0354(-0.0141)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e詳細な結果はご覧の通りです。\u003c/p\u003e\n\u003cp\u003eめっちゃクソ雑魚すぎて...。反省点は永遠に出てきそうですが、\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eどこで負けたのか。敗因はなんなのか？\u003c/li\u003e\n\u003cli\u003e参考になったディスカッション\u003c/li\u003e\n\u003cli\u003eこれから対策すること\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこの辺に沿って大反省をしていこうと思います。\u003c/p\u003e\n\u003ch2\u003eMyModel\u003c/h2\u003e\n\u003ch3\u003eモデル\u003c/h3\u003e\n\u003cp\u003e反省するために、自分のモデルと特徴量を整理していきます。\u003c/p\u003e\n\u003cp\u003eまず、僕の作成したモデルが以下になっています。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eModel: LightGBM (10 FoldのAverage)\u003c/li\u003e\n\u003cli\u003eKFold: Stratified 10-Fold\u003c/li\u003e\n\u003cli\u003eparameters:\n\u003cul\u003e\n\u003cli\u003e'boosting_type': 'gbdt',\u003c/li\u003e\n\u003cli\u003e'feature_pre_filter': False,\u003c/li\u003e\n\u003cli\u003e'lambda_l1': 0.00024503835566927994,\u003c/li\u003e\n\u003cli\u003e'lambda_l2': 9.900190817327861e-07,\u003c/li\u003e\n\u003cli\u003e'num_leaves': 56,\u003c/li\u003e\n\u003cli\u003e'feature_fraction': 0.8999999999999999,\u003c/li\u003e\n\u003cli\u003e'bagging_fraction': 1.0,\u003c/li\u003e\n\u003cli\u003e'bagging_freq': 0,\u003c/li\u003e\n\u003cli\u003e'min_child_samples': 20,\u003c/li\u003e\n\u003cli\u003e'num_iterations': 100000,\u003c/li\u003e\n\u003cli\u003e'early_stopping_round': 200,\u003c/li\u003e\n\u003cli\u003e'learning_rate': 0.02,\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記パラメータはoptunaでチューニングしました。チューニングで上がったCVスコアは\u003cem\u003e0.002\u003c/em\u003eくらいでしたね(笑)\u003c/p\u003e\n\u003cp\u003eほとんど寄与していないですが、気持ちチューニングしたって感じです。\u003c/p\u003e\n\u003ch3\u003e特徴量\u003c/h3\u003e\n\u003cp\u003e使用した特徴量をまとめます。\u003cbr\u003e\n一応効いた順に並べていきます。\u003c/p\u003e\n\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003e特徴量\u003c/th\u003e\n\u003cth\u003e寄与度\u003c/th\u003e\n\u003cth\u003e労力\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ecollection, techniques, materialのWord2Vec =\u003e PCA2次元\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e絶大\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://www.guruguru.science/competitions/16/discussions/2fafef06-5a26-4d33-b535-a94cc9549ac4/\"\u003eアライさんのディスカッション\u003c/a\u003eにより小\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eprincipal_makerのカテゴリ\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e絶大\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003eastype('category)なので小\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esubtitle =\u003e W,H,T,D\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e絶大\u003c/strong\u003e\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esubtitle =\u003e WxH\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emore_title, titleのTF-IDF =\u003e PCA2次元\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eprincipal_makerの出現回数\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003ctd\u003e小\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003edatingのUNIX時間 / 1E6\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eaquisition_dating - year_late\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003ctd\u003e中\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003edating_timeのカテゴリ変数化\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003ctd\u003e小\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eその他諸のカテゴリ変数\u003c/td\u003e\n\u003ctd\u003e皆無\u003c/td\u003e\n\u003ctd\u003e大\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epaletteの平均,分散,Top色\u003c/td\u003e\n\u003ctd\u003eほぼなし\u003c/td\u003e\n\u003ctd\u003e\u003cstrong\u003e絶大\u003c/strong\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003cstrong\u003eテキスト系\u003c/strong\u003eの特徴量がとても効いていたという印象があります。カラー系はそもそも絵画ということから、テーブルデータであることから離れて考えて、色々仮説は立てましたが、ほぼほぼ意味なかったというね。。。(笑)\u003c/p\u003e\n\u003cp\u003e色系統で立てた仮説は、こんな感じでした。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e色の統一感があった方が印象が一定? (分散を見ればわかるのでは)\u003c/li\u003e\n\u003cli\u003e割合上位色の平均とか分散に依存するのでは?\u003c/li\u003e\n\u003cli\u003e逆に割合下位色は差し色として効果があるのでは?\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eどれも工夫して結構特徴量に入れたのですが、ほとんどが効いていなくて半ば泣きそうでした(笑)\u003c/p\u003e\n\u003cp\u003e後半にディスカッションからピックアップしてきたテキスト系がうまいこと効いてくれて、最後の最後にスコアがなんと\u003cstrong\u003e0.02\u003c/strong\u003eも飛躍するということに...。\u003c/p\u003e\n\u003cp\u003e「おい、なんでお前はテキスト系にdeadline前日に目をつけてるんだよ」とかいうお気持ちになりましたが(笑)\u003c/p\u003e\n\u003cp\u003eま、それはそれで良い経験でした。\u003c/p\u003e\n\u003ch2\u003e敗因と今後の展望\u003c/h2\u003e\n\u003cp\u003e悲惨な結果になりましたので、ここでしっかり敗因を考えていこうと思います。\u003c/p\u003e\n\u003cp\u003eとにかく敗因は多いと思うので、列挙していこうと思います。この辺は同じような結果の人なら同じこと考えているんじゃないかな。。。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e自分なりのパイプラインがない(Kaggle routine的な)\u003c/li\u003e\n\u003cli\u003e実験管理が甘々(ファイル管理雑 =\u003e 前やったこととCV,LBがわからん)\u003c/li\u003e\n\u003cli\u003e関数とかクラスを用意しないから再利用生にかける\u003c/li\u003e\n\u003cli\u003eEDAが雑雑雑雑......\u003c/li\u003e\n\u003cli\u003e仮説と実験、立証の思考が浅い(仮説が正しくない時の次がない)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eテキスト特徴量\u003c/strong\u003eの効果に気づいたのが前日の金曜日()\u003c/li\u003e\n\u003cli\u003eディスカッションをみた後実装すぐしない\u003c/li\u003e\n\u003cli\u003e単純に経験と学習量が足りない\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e無限に出てきそうですが、とりあえず主要な原因は上記にあると思います。\u003c/p\u003e\n\u003cp\u003e最後の単純に経験と学習量に関しては気持ち程度の言い訳で、自分よりも経験が浅いだろう人は上位にたくさんいるので、やり方が悪いとしか思えません。というわけで、最も敗因になったであろうことを深ぼってみようと思います。\u003c/p\u003e\n\u003ch3\u003eEDAが雑\u003c/h3\u003e\n\u003cp\u003eEDAって一番地味だけど、仮説立てたり、相関をみつたりと各情報の作用を考える最も重要な時間になります。\u003c/p\u003e\n\u003cp\u003e今回はEDAが大事ということを肝に銘じた上でEDAを行ったつもりでしたが、それも「つもり」で終わってしまったような気がします。\u003c/p\u003e\n\u003cp\u003e色々変換したりグラフ化したりしてみましたが、今回はリレーショナルな情報が多かったです。例えば、principal_makerとかmaterialとか。メインのデータにあった特徴量や数値、時間と言った数値の連続値に変換しやすいデータに関しては結構データを読み込んだ感じでした。\u003c/p\u003e\n\u003cp\u003eしかし、テキストなどスパースで離散的なデータに関しては実験ベースでしっかり分析できていなかったです。特に、それを感じたのがこれもまた\u003cem\u003eアライさんのディスカッション\u003c/em\u003eでした。\u003ca href=\"https://www.guruguru.science/competitions/16/discussions/f463dac2-4233-42d2-8629-ca99a9689987/\"\u003eタイトルの言語判定特徴\u003c/a\u003eってやつですね。こんな情報まで気づくというのは、しっかり時間かけてEDAしているんだろうなぁ。自分は浅はかな分析しかできていないじゃないか。と思ったわけです。\u003c/p\u003e\n\u003cp\u003eYouTube講座第二回の時にも、RainCloudとかいうのもありましたし、もっと詳しく直感的なEDAをしていかないといけません。今回それができなかったのが大きな敗因でした。\u003c/p\u003e\n\u003ch3\u003eパイプライン的なのがない\u003c/h3\u003e\n\u003cp\u003eパイプライン的な物を持っていないというのが敗因というよりは、ライブラリを知らないという方がこの反省には近いかもしれません。\u003c/p\u003e\n\u003cp\u003eパイプラインはこれから作ろうと思いますし、今回のディスカッションの中でも今後パイプラインとなりうるのが沢山見つかっているので、これからそれらを自分の懐に隠していこうと思います(笑)\u003c/p\u003e\n\u003cp\u003eライブラリの使い方、なければ自分なりのモジュールを作る、それらを一連の流れとして蓄える。\u003c/p\u003e\n\u003cp\u003eこのフローを身につければ、労力がだんだん少なくなっていき、より深い思考フェーズに時間を割けるのだろうなと感じました。\u003c/p\u003e\n\u003ch3\u003e実験管理が甘々\u003c/h3\u003e\n\u003cp\u003e僕はとりわけ記憶力にかけているのにもかかわらず、特にメモもせずにおおよそ一つのnotebookで管理していました。\u003c/p\u003e\n\u003cp\u003eそりゃぁごっちゃになるに決まってるよ...。\u003c/p\u003e\n\u003cp\u003e管理の仕方は人それぞれだと思いますし、やりながら身につけていかなければならないでしょう。しかし、意識してやらないとベストプラクティスは見つからないわけで。。。\u003c/p\u003e\n\u003cp\u003e参考になるディスカッションがあったので、\u003ca href=\"https://www.guruguru.science/competitions/16/discussions/cc793380-410d-413e-bac4-f46d4aa836fd/\"\u003eこちら\u003c/a\u003eを参考に自分なりの手法を探るのが近道な気がします。\u003c/p\u003e\n\u003cp\u003eちなみに、昨日atmaCup#10が終わり、新しくコンペに参戦していますが、\u003cbr\u003e\ntokaiさんの「自分も1実験1ノートブックで、それぞれの実験に番号をつけてます。また特徴量にも番号をつけています。Google スプレッドシートでスコア管理していて、その際に、①model、②使用した特徴量（番号）③スコアを入力しています。」というコメントを参考にしています。\u003c/p\u003e\n\u003cp\u003eやりながら探っていこうと思います。\u003c/p\u003e\n\u003ch3\u003e\u003cstrong\u003eテキスト特徴量\u003c/strong\u003eの効果に気づいたのが前日の金曜日\u003c/h3\u003e\n\u003cp\u003eこれはいうまでもなくディスカッションをしっかりやらなかった自分が悪いです。\u003c/p\u003e\n\u003cp\u003e閉会式でもおっしゃられていましたが、\u003cstrong\u003eとにかくディスカッションは参考にやってみる\u003c/strong\u003eというのは確かにそうだなと思いました。\u003c/p\u003e\n\u003cp\u003e自分の仮説に拘るよりも、他の人が見つけた良い特徴量を試してみて、その後自分のやるもいいし、ディスカッションの中身を魔改造するもいいし、\u003cbr\u003e\nまずはディスカッションをやってみるのはベターな考え方だなと感心しました。\u003c/p\u003e\n\u003cp\u003e次からそうしよっと。\u003c/p\u003e\n\u003ch2\u003eこれから意識することとは\u003c/h2\u003e\n\u003cp\u003eここまで大反省会をしてきて(記事を書きながら自分の中のモヤモヤを精査する中で)、自分に足りない物が多すぎるということに直面しました。\u003c/p\u003e\n\u003cp\u003eただ、それでもやるべきことは決まってきたので、良い経験になったと思います。自分の課題は自分だけのものではないと思いますので、意識することをまた列挙していきます(ただ面倒臭くなっただけ)(笑)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eEDAはとにかく丁寧に。モデリングなんて二の次でいいくらい\u003c/li\u003e\n\u003cli\u003e実験管理をしよう!!! (とりあえずGoogle SpreadSheet試す)\u003c/li\u003e\n\u003cli\u003eディスカッションの内容はなるだけ拾い上げる!\u003c/li\u003e\n\u003cli\u003eベストプラクティスを見つけたら、すぐパイプライン化する\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e当面コンペに対して、経験を身に付けるまでは上記の内容を自然とできるように意識的に取り組んでいきます。\u003c/p\u003e\n\u003cp\u003eそして、これから意識することは多分この記事をみてくださった方にも共通することもあると思いますので、皆さんの反省会にも影響を与えられたらという淡い期待を持ちながら反省会を締めたいと思います。\u003c/p\u003e\n\u003cp\u003eとても楽しく学びになるコンペを設計してくださったことに感謝しつつ、次のatmaCupもすごく期待しております。\u003c/p\u003e\n\u003cp\u003eatmaCupの開催ありがとうございました、そして参加者のみなさまお疲れ様でした!!!!!\u003cstrong\u003e((感謝 + 労り) * inf)\u003c/strong\u003e\u003c/p\u003e\n","Title":"atmaCup#10大反省会(Public: 137位/Private: 130位)","Date":"2021-03-14","Category":"Competition","Tags":["Python","データ分析","atmaCup"],"Authors":"ゆうぼう","Slug":"atmacup10-feedback","Thumbnail":"/images/thumbnails/atma%2310.png","Description":"atmaCup#10に参加しました。しっかりとコンペにフルコミットしたのは今回が初めてなので、ほぼ初参加と言っていいでしょう。しかし、結果はPublic: 137位でPrivate: 130位(+7)というクソ雑魚結果に...。これは大反省会をして次に生かすことに他ならないということで久々にブログに記します。誰かのお役に立てれば嬉しいかなと思いながら、大反省をしていきます。","Published":true}],"tag":"データ分析","categories":["Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","conda","CSS","ffmpeg","Flask","Go","Google Colaboratory","Heroku","HTML","JavaScript","JSON","Kaggle","Linux","Mac","make","map","MeCab","ML","MySQL","NLP","node.js","Pandas","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","SISR","subprocess","Super-Resolution","tensorflow","Tkinter","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"pages":1,"page":1},"__N_SSG":true},"page":"/tag/[tag]/[page]","query":{"tag":"データ分析","page":"1"},"buildId":"jxfvMu6_tWEzBY3U7rzL9","isFallback":false,"gsp":true}</script><script nomodule="" src="/_next/static/chunks/polyfills-eef578260fd80f8fff94.js"></script><script src="/_next/static/chunks/webpack-189c53927ffd3caf09c3.js" async=""></script><script src="/_next/static/chunks/framework-fb2dd7aba3784ca05084.js" async=""></script><script src="/_next/static/chunks/main-71948af4b0f09c0fc30e.js" async=""></script><script src="/_next/static/chunks/pages/_app-20aa38351985c99d4121.js" async=""></script><script src="/_next/static/chunks/996-fa0b52be06882e958afa.js" async=""></script><script src="/_next/static/chunks/382-a31ac978fd260471df46.js" async=""></script><script src="/_next/static/chunks/pages/tag/%5Btag%5D/%5Bpage%5D-c8f22dfc6a27b7b1a686.js" async=""></script><script src="/_next/static/jxfvMu6_tWEzBY3U7rzL9/_buildManifest.js" async=""></script><script src="/_next/static/jxfvMu6_tWEzBY3U7rzL9/_ssgManifest.js" async=""></script></body></html>