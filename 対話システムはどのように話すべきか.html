<!DOCTYPE html><html lang="ja" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>【論文まとめ】対話システムはどのように話すべきか<!-- --> | <!-- -->ゆうぼうの書跡棚</title><meta name="description" content="対話システムはどのように話すべきかのまとめ"/><meta name="og:description" content="対話システムはどのように話すべきかのまとめ"/><meta property="og:type" content="website"/><meta property="og:title" content="【論文まとめ】対話システムはどのように話すべきか"/><meta property="og:url" content="https://yuta0306.github.io/対話システムはどのように話すべきか"/><script src="/js/toc.js"></script><meta name="next-head-count" content="9"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="HandheldFriendly" content="True"/><meta name="description" content="スキルや知識をつけて将来ナマケモノになるまでの技術ブログです．主に，機械学習やPython, JavaScriptによる開発についてまとめます．"/><meta name="author" content="ゆうぼう"/><meta name="twitter:card" content="summary"/><meta name="robots" content="index, follow"/><meta name="generator" content="Next.js"/><link rel="apple-touch-icon" sizes="180x180" href="/favicon_io/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon_io/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon_io/favicon-16x16.png"/><link rel="manifest" href="/favicon_io/site.webmanifest"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-147997959-2"></script><script>
                  window.dataLayer = window.dataLayer || [];
                  function gtag(){dataLayer.push(arguments);}
                  gtag('js', new Date());
                  gtag('config', 'UA-147997959-2', {
                    page_path: window.location.pathname,
                  });</script><script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="preload" href="/_next/static/css/75506965150cde8a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/75506965150cde8a.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a6e19106a865540a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a6e19106a865540a.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer=""></script><script src="/_next/static/chunks/framework-2c79e2a64abdb08b.js" defer=""></script><script src="/_next/static/chunks/main-7c8966651ff4862e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6312d3a6c9934c88.js" defer=""></script><script src="/_next/static/chunks/664-60e06c839f82ba03.js" defer=""></script><script src="/_next/static/chunks/768-c61e8ddb09e59da7.js" defer=""></script><script src="/_next/static/chunks/pages/%5Bslug%5D-b275297c06761584.js" defer=""></script><script src="/_next/static/JH1zPBZfb3-e96j1PXu_c/_buildManifest.js" defer=""></script><script src="/_next/static/JH1zPBZfb3-e96j1PXu_c/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="Home_container__bCOhY"><div class="header_container__IoqX_"><div class="header_container__inner__pDDDU"><header class="header_header__pKEQL"><a href="/"><div class="header_header__title__uoTF0">ゆうぼうの書跡棚</div></a></header><div class="header_hamburger__kYfxY"><div><img src="/icons/hamburger.png"/></div></div><nav class="header_nav__closed__1h469"><ul class="header_nav__list__eqFqF"><li class="header_nav__item__FNSzb"><a href="/about">About</a></li><li class="header_nav__item_active__qVXxE"><a href="/">Blog</a></li><li class="header_nav__item__FNSzb"><a href="https://docs.google.com/forms/d/e/1FAIpQLSdgyok9pi697ZJvVizRNEw0qghDWz517k1FrbcRmfvvERlraA/viewform">Contact</a></li></ul></nav></div></div><div class="header_category__WFSrL"><ul class="header_category__items____MmN"></ul></div><div class="main_main__VZQGI"><div class="main_main__container__PFqpL"><main class="main_main__container__inner__PWn1D" role="main" itemProp="mainContentOfPage" itemscope="" itemType="http://schema.org/Blog"><div class="main_content__V_9fG"><div itemscope="" itemType="http://schema.org/BlogPosting"><div style="background:url(/images/default.png);overflow:hidden"><div class="Home_thumbnail__xs1Hd" itemscope="" itemProp="image" itemType="https://schema.org/ImageObject"><img src="/images/default.png" alt="【論文まとめ】対話システムはどのように話すべきか" loading="lazy" style="height:100%;width:auto;margin:0 auto;display:block"/></div></div><time dateTime="2023-07-10" style="color:rgb(144, 144, 144)">2023-07-10</time><h1>【論文まとめ】対話システムはどのように話すべきか</h1><div id="TOC__mobile"></div><article style="margin-top:4rem" itemscope="" itemProp="text"><p>本記事において使用される図表は，原著論文内の図表を引用しています．</p>
<p>また，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．</p>
<h2>論文情報</h2>
<p>タイトル: 対話システムはどのように話すべきか</p>
<p>研究会: 日本音響学会誌</p>
<p>年度: 2022</p>
<p>キーワード: 聞き手反応, dialogue system</p>
<p>URL: <a href="https://www.jstage.jst.go.jp/article/jasj/78/5/78_283/_pdf">https://www.jstage.jst.go.jp/article/jasj/78/5/78_283/_pdf</a></p>
<p>DOI: <a href="https://doi.org/10.20697/jasj.78.5_283">https://doi.org/10.20697/jasj.78.5_283</a></p>
<p>データセット:</p>
<h2>概要</h2>
<p>「<strong>聞き手反応</strong>」をキーワードに，対話システムが発する音声をどのように生成するべきかという観点から音声対話システムとの自然な対話の実現に迫った研究の紹介．</p>
<h2>聞き手反応</h2>
<p>会話は話し手と聞き手の相互行為により産出されるもの</p>
<p>聞き手の反応を「相槌表現」として次の分類（Den et al., 2011）</p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/ake32nmz.png" alt=""></p>
<p><strong>聞き手の行動の観察は分析上不可欠</strong>であるが，音声対話システム研究ではほとんど考慮されない</p>
<p><strong>人はシステムに対して，（人同士の対話と異なり）ほとんど聞き手反応をしない</strong></p>
<p>人は，どのようにして声でシステムを操作するかを学</p>
<p>→ 機械は機械であり，人と同じようにコミュニケーションができないことを知っている</p>
<h2>聞き手反応を誘発する話し方</h2>
<p>音声対話システム vs 人における違い</p>
<ul>
<li>発話タイミングを含むターンテイキング</li>
<li><strong>話し方</strong>
<ul>
<li><strong>人同士の対話における発話は，必ずしも明瞭かつ流暢ではない．</strong></li>
</ul>
</li>
</ul>
<p>高津ら（2018）の研究では，人同士の対話にのみ存在する話し方の特徴を要因に分解し，次のコードで表す．</p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/3w6tk316.png" alt=""></p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/acfpbbc4.png" alt=""></p>
<p>そして，以下の3条件でWoZ対話的なことを行う</p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/hqhzjfod.png" alt=""></p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/lyovs6wf.png" alt=""></p>
<p>発話計画例と実験の結果は次のとおり</p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/yodnhyta.png" alt=""></p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/r2at9ofw.png" alt=""></p>
<p><strong>機械的な発話をすると，聞き手反応が減る</strong></p>
<h2>自発音声コーパスを元にした音声で話すエージェント（飯塚ら, 2019）</h2>
<p>読み上げ音声コーパスではなく，自然な会話コーパスを用いて音声合成を訓練することで，読み上げと会話の音声のギャップを埋めうる</p>
<p>しかし，そのような試みは少ない</p>
<p>以下が考えうる要因</p>
<ol>
<li>声のプロと違い，普通の人々の音声は正確性，明瞭性に欠けるから，音声合成に相応しくないという思い込み</li>
<li>会話音声の多様性．テキストだけでは説明できない音声のパラ言語的な特徴の変動が読み上げ音声に比べて大きく，モデル化が相対的に困難なこと</li>
<li><strong>会話コーパスの小ささ．音声合成ではデータりょうが品質に直結するが，会話コーパスの場合，話者一人当たりのデータ量が少なく，音声のモデル化が困難なこと</strong>
<ol>
<li>筆者ら研究チームでは，とりわけこれがネックだった</li>
<li>→ ニューラルボコーダ（高木, 2019）の登場によりインパクトに</li>
</ol>
</li>
</ol>
<p>実験として，読み上げ独話音声コーパスJSUT vs 自発対話音声コーパスUUDB（宇都宮大学パラ言語情報研究向け音声対話データベース）</p>
<p>音声合成にはTacotron 2，スペクトルからの波形生成にはMelGAN</p>
<p>UUDBでは女性話者1名のデータでfine-tuning</p>
<p>MMDAgentを利用して音声対話システムを構築（研究仮説を検証するため）</p>
<p>国当てクイズの対話シナリオ</p>
<p>実験結果とその対話動画視聴から得たアンケート結果</p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/863qbviy.png" alt=""></p>
<p><img src="/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/gi2f1kw7.png" alt=""></p>
<p><strong>自然な会話コーパス（ここではUUDB）を元にした合成音声で話すシステムとの対話の方が，人同士の対話に近い振る舞いをしている．</strong></p>
<p>感情表出系感動詞及び笑いの数に有意な差は認められず</p>
<p>「不気味の谷」？？？</p>
<h2>まとめ</h2>
<p>自然な音声対話の実現を望むならば，もっと本物の音声コミュニケーションと真剣に向き合わなければならないのではないか？</p>
<h2>その他（なぜ通ったか？等）</h2>
<h2>次読みたい論文</h2>
<h2>引用</h2>
<blockquote>
<p>@article{2022,
author = {森 大毅},</p>
</blockquote>
<p>doi = {10.20697/jasj.78.5_283},
journal = {日本音響学会誌},
number = {5},
pages = {283-288},
title = {対話システムはどのように話すべきか},
volume = {78},
year = {2022},
bdsk-url-1 = {<a href="https://doi.org/10.20697/jasj.78.5_283">https://doi.org/10.20697/jasj.78.5_283</a>}}</p></article><div class="socialshare_container__SSXJE"><h3>タメになったらSHARE!!!</h3><div class="socialshare_container__links__JZs4j"><a target="_blank" href="https://twitter.com/share?url=https://yuta0306.github.io/対話システムはどのように話すべきか"><img src="/icons/twitter.png" loading="lazy" alt="https://yuta0306.github.io/対話システムはどのように話すべきかをTwitterに共有する"/></a><a target="_blank" href="https://www.facebook.com/share.php?u=https://yuta0306.github.io/対話システムはどのように話すべきか"><img src="/icons/facebook.png" loading="lazy" alt="https://yuta0306.github.io/対話システムはどのように話すべきかをFacebookに共有する"/></a><a target="_blank" href="http://b.hatena.ne.jp/entry/https:/yuta0306.github.io/対話システムはどのように話すべきか"><img src="/icons/hatenablog.png" loading="lazy" alt="https://yuta0306.github.io/対話システムはどのように話すべきかをはてなブログに共有する"/></a></div></div></div></div></main><aside class="main_sidebar__tM28d"><div class="shortbio_container__4psan" itemscope="" itemProp="author" itemType="http://schema.org/Person"><div class="shortbio_container__image__eljVd"><img src="/images/profile.jpeg" alt="ゆうぼう" loading="lazy"/></div><h3 class="shortbio_author__A2bKB" itemscope="" itemProp="name">ゆうぼう</h3><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">国立大学院M1のナマケモノです．</p></div><div><p class="shortbio_container__paragraph__EJbWG">human-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．</p></div><div><p class="shortbio_container__paragraph__EJbWG">学部時代はコモンセンスを利用したユーモア検出の研究を行っていました(Knowledge-intensive NLP)．</p></div><div><p class="shortbio_container__paragraph__EJbWG">このブログはNext.jsで書いてます．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div><div><p class="shortbio_container__paragraph__EJbWG">Kaggle等のデータ分析コンペは活動休止中．</p></div><div><p class="shortbio_container__paragraph__EJbWG"></p></div></div><div class="followme_container__T1oVi"><h3 class="followme_container__header__Pt5SP">Follow Me</h3><div class="followme_container__links__b3XW5"><a target="_blank" href="https://github.com/yuta0306"><img src="/icons/github.png" alt="GitHub"/></a><a target="_blank" href="https://kaggle.com/yutasasaki"><img src="/icons/kaggle.png" alt="Kaggle"/></a><a target="_blank" href="https://twitter.com/Sloth65557166"><img src="/icons/twitter.png" alt="Twitter"/></a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div class="categories_container__J8nCF"><h3 class="categories_container__header__zt836">Categories</h3><div class="categories_container__links__MFrVK"><a class="categories_container__link__AuvVr" href="/category/%E8%AB%96%E6%96%87/1">論文</a><a class="categories_container__link__AuvVr" href="/category/Web/1">Web</a><a class="categories_container__link__AuvVr" href="/category/JavaScript/1">JavaScript</a><a class="categories_container__link__AuvVr" href="/category/Competition/1">Competition</a><a class="categories_container__link__AuvVr" href="/category/Cloud/1">Cloud</a><a class="categories_container__link__AuvVr" href="/category/Linux/1">Linux</a><a class="categories_container__link__AuvVr" href="/category/Python/1">Python</a><a class="categories_container__link__AuvVr" href="/category/ML/1">ML</a><a class="categories_container__link__AuvVr" href="/category/Go/1">Go</a><a class="categories_container__link__AuvVr" href="/category/SQL/1">SQL</a></div></div><div class="tags_container___e3ez"><h3 class="tags_container__header__hxPW8">Tags</h3><div class="tags_container__links__X38Ga"><a class="tags_container__link__1Ts3a" href="/tag/Apache/1">Apache</a><a class="tags_container__link__1Ts3a" href="/tag/Appium/1">Appium</a><a class="tags_container__link__1Ts3a" href="/tag/atmaCup/1">atmaCup</a><a class="tags_container__link__1Ts3a" href="/tag/AWS/1">AWS</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS7/1">CentOS7</a><a class="tags_container__link__1Ts3a" href="/tag/CentOS8/1">CentOS8</a><a class="tags_container__link__1Ts3a" href="/tag/Colab/1">Colab</a><a class="tags_container__link__1Ts3a" href="/tag/COMET/1">COMET</a><a class="tags_container__link__1Ts3a" href="/tag/commonsense/1">commonsense</a><a class="tags_container__link__1Ts3a" href="/tag/conda/1">conda</a><a class="tags_container__link__1Ts3a" href="/tag/Contrasive%20Learning/1">Contrasive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/Contrastive%20Learning/1">Contrastive Learning</a><a class="tags_container__link__1Ts3a" href="/tag/CSS/1">CSS</a><a class="tags_container__link__1Ts3a" href="/tag/Dialogue%20Structure%20Learning/1">Dialogue Structure Learning</a><a class="tags_container__link__1Ts3a" href="/tag/dialogue%20system/1">dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/DST/1">DST</a><a class="tags_container__link__1Ts3a" href="/tag/empathetic%20dialogue%20system/1">empathetic dialogue system</a><a class="tags_container__link__1Ts3a" href="/tag/encyclopedic/1">encyclopedic</a><a class="tags_container__link__1Ts3a" href="/tag/ESPNet/1">ESPNet</a><a class="tags_container__link__1Ts3a" href="/tag/ffmpeg/1">ffmpeg</a><a class="tags_container__link__1Ts3a" href="/tag/Flask/1">Flask</a><a class="tags_container__link__1Ts3a" href="/tag/Gating%20Mechanism/1">Gating Mechanism</a><a class="tags_container__link__1Ts3a" href="/tag/Go/1">Go</a><a class="tags_container__link__1Ts3a" href="/tag/Google%20Colaboratory/1">Google Colaboratory</a><a class="tags_container__link__1Ts3a" href="/tag/Heroku/1">Heroku</a><a class="tags_container__link__1Ts3a" href="/tag/Highway%20Transformer/1">Highway Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/HTML/1">HTML</a><a class="tags_container__link__1Ts3a" href="/tag/humor%20detection/1">humor detection</a><a class="tags_container__link__1Ts3a" href="/tag/Internet-Augmented/1">Internet-Augmented</a><a class="tags_container__link__1Ts3a" href="/tag/JavaScript/1">JavaScript</a><a class="tags_container__link__1Ts3a" href="/tag/JSON/1">JSON</a><a class="tags_container__link__1Ts3a" href="/tag/Kaggle/1">Kaggle</a><a class="tags_container__link__1Ts3a" href="/tag/KC-Net/1">KC-Net</a><a class="tags_container__link__1Ts3a" href="/tag/knowledge-base/1">knowledge-base</a><a class="tags_container__link__1Ts3a" href="/tag/Knowledge-Intensive%20NLP/1">Knowledge-Intensive NLP</a><a class="tags_container__link__1Ts3a" href="/tag/laughter/1">laughter</a><a class="tags_container__link__1Ts3a" href="/tag/Linux/1">Linux</a><a class="tags_container__link__1Ts3a" href="/tag/Mac/1">Mac</a><a class="tags_container__link__1Ts3a" href="/tag/make/1">make</a><a class="tags_container__link__1Ts3a" href="/tag/map/1">map</a><a class="tags_container__link__1Ts3a" href="/tag/MeCab/1">MeCab</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20health/1">mental health</a><a class="tags_container__link__1Ts3a" href="/tag/mental%20state%20knowledge/1">mental state knowledge</a><a class="tags_container__link__1Ts3a" href="/tag/mentalisation/1">mentalisation</a><a class="tags_container__link__1Ts3a" href="/tag/MentalRoBERTa/1">MentalRoBERTa</a><a class="tags_container__link__1Ts3a" href="/tag/ML/1">ML</a><a class="tags_container__link__1Ts3a" href="/tag/MT/1">MT</a><a class="tags_container__link__1Ts3a" href="/tag/Multi-Hop%20Transformer/1">Multi-Hop Transformer</a><a class="tags_container__link__1Ts3a" href="/tag/multi-modal/1">multi-modal</a><a class="tags_container__link__1Ts3a" href="/tag/MySQL/1">MySQL</a><a class="tags_container__link__1Ts3a" href="/tag/NLG/1">NLG</a><a class="tags_container__link__1Ts3a" href="/tag/NLI/1">NLI</a><a class="tags_container__link__1Ts3a" href="/tag/NLP/1">NLP</a><a class="tags_container__link__1Ts3a" href="/tag/Node/1">Node</a><a class="tags_container__link__1Ts3a" href="/tag/node.js/1">node.js</a><a class="tags_container__link__1Ts3a" href="/tag/npm/1">npm</a><a class="tags_container__link__1Ts3a" href="/tag/Pandas/1">Pandas</a><a class="tags_container__link__1Ts3a" href="/tag/persona/1">persona</a><a class="tags_container__link__1Ts3a" href="/tag/PLMKE/1">PLMKE</a><a class="tags_container__link__1Ts3a" href="/tag/Poetry/1">Poetry</a><a class="tags_container__link__1Ts3a" href="/tag/Prompt-Tuning/1">Prompt-Tuning</a><a class="tags_container__link__1Ts3a" href="/tag/Python/1">Python</a><a class="tags_container__link__1Ts3a" href="/tag/Pytorch/1">Pytorch</a><a class="tags_container__link__1Ts3a" href="/tag/pytorch-lightning/1">pytorch-lightning</a><a class="tags_container__link__1Ts3a" href="/tag/Scikit-learn/1">Scikit-learn</a><a class="tags_container__link__1Ts3a" href="/tag/Selenium/1">Selenium</a><a class="tags_container__link__1Ts3a" href="/tag/Self-Dependency-Units%20(SDU)/1">Self-Dependency-Units (SDU)</a><a class="tags_container__link__1Ts3a" href="/tag/shared%20laughter/1">shared laughter</a><a class="tags_container__link__1Ts3a" href="/tag/SISR/1">SISR</a><a class="tags_container__link__1Ts3a" href="/tag/subprocess/1">subprocess</a><a class="tags_container__link__1Ts3a" href="/tag/Super-Resolution/1">Super-Resolution</a><a class="tags_container__link__1Ts3a" href="/tag/survey/1">survey</a><a class="tags_container__link__1Ts3a" href="/tag/tensorflow/1">tensorflow</a><a class="tags_container__link__1Ts3a" href="/tag/Tkinter/1">Tkinter</a><a class="tags_container__link__1Ts3a" href="/tag/transformer/1">transformer</a><a class="tags_container__link__1Ts3a" href="/tag/zsh/1">zsh</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E6%8C%87%E5%90%91/1">オブジェクト指向</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%82%B3%E3%83%AC%E3%83%BC%E3%82%BF/1">デコレータ</a><a class="tags_container__link__1Ts3a" href="/tag/%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90/1">データ分析</a><a class="tags_container__link__1Ts3a" href="/tag/%E7%89%B9%E6%AE%8A%E3%83%A1%E3%82%BD%E3%83%83%E3%83%89/1">特殊メソッド</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%81%9E%E3%81%8D%E6%89%8B%E5%8F%8D%E5%BF%9C/1">聞き手反応</a><a class="tags_container__link__1Ts3a" href="/tag/%E8%B6%85%E8%A7%A3%E5%83%8F/1">超解像</a></div></div><ins class="adsbygoogle " style="display:block" data-ad-client="ca-pub-4998278830587376" data-ad-slot="8978700883" data-ad-layout="" data-ad-layout-key="" data-ad-format="auto" data-full-width-responsive="true"></ins><div id="TOC"></div></aside></div></div><footer class="footer_footer__WCChH"><div class="footer_footer__inner__287VQ"><div><a class="footer_footer__link__Ql5Ng" href="/privacy-policy">プライバシーポリシー</a></div><div class="footer_footer__title__PRn_u"><a href="/">ゆうぼうの書跡棚</a></div><div class="footer_footer__small__RlIHP"><small>Powered by <a target="_blank" class="footer_footer__small__link__u5kuV" href="https://twitter.com/Sloth65557166">ゆうぼう</a></small></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"postData":{"contentHtml":"\u003cp\u003e本記事において使用される図表は，原著論文内の図表を引用しています．\u003c/p\u003e\n\u003cp\u003eまた，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．\u003c/p\u003e\n\u003ch2\u003e論文情報\u003c/h2\u003e\n\u003cp\u003eタイトル: 対話システムはどのように話すべきか\u003c/p\u003e\n\u003cp\u003e研究会: 日本音響学会誌\u003c/p\u003e\n\u003cp\u003e年度: 2022\u003c/p\u003e\n\u003cp\u003eキーワード: 聞き手反応, dialogue system\u003c/p\u003e\n\u003cp\u003eURL: \u003ca href=\"https://www.jstage.jst.go.jp/article/jasj/78/5/78_283/_pdf\"\u003ehttps://www.jstage.jst.go.jp/article/jasj/78/5/78_283/_pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDOI: \u003ca href=\"https://doi.org/10.20697/jasj.78.5_283\"\u003ehttps://doi.org/10.20697/jasj.78.5_283\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eデータセット:\u003c/p\u003e\n\u003ch2\u003e概要\u003c/h2\u003e\n\u003cp\u003e「\u003cstrong\u003e聞き手反応\u003c/strong\u003e」をキーワードに，対話システムが発する音声をどのように生成するべきかという観点から音声対話システムとの自然な対話の実現に迫った研究の紹介．\u003c/p\u003e\n\u003ch2\u003e聞き手反応\u003c/h2\u003e\n\u003cp\u003e会話は話し手と聞き手の相互行為により産出されるもの\u003c/p\u003e\n\u003cp\u003e聞き手の反応を「相槌表現」として次の分類（Den et al., 2011）\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/ake32nmz.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e聞き手の行動の観察は分析上不可欠\u003c/strong\u003eであるが，音声対話システム研究ではほとんど考慮されない\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e人はシステムに対して，（人同士の対話と異なり）ほとんど聞き手反応をしない\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e人は，どのようにして声でシステムを操作するかを学\u003c/p\u003e\n\u003cp\u003e→ 機械は機械であり，人と同じようにコミュニケーションができないことを知っている\u003c/p\u003e\n\u003ch2\u003e聞き手反応を誘発する話し方\u003c/h2\u003e\n\u003cp\u003e音声対話システム vs 人における違い\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e発話タイミングを含むターンテイキング\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e話し方\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e人同士の対話における発話は，必ずしも明瞭かつ流暢ではない．\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e高津ら（2018）の研究では，人同士の対話にのみ存在する話し方の特徴を要因に分解し，次のコードで表す．\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/3w6tk316.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/acfpbbc4.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eそして，以下の3条件でWoZ対話的なことを行う\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/hqhzjfod.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/lyovs6wf.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e発話計画例と実験の結果は次のとおり\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/yodnhyta.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/r2at9ofw.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e機械的な発話をすると，聞き手反応が減る\u003c/strong\u003e\u003c/p\u003e\n\u003ch2\u003e自発音声コーパスを元にした音声で話すエージェント（飯塚ら, 2019）\u003c/h2\u003e\n\u003cp\u003e読み上げ音声コーパスではなく，自然な会話コーパスを用いて音声合成を訓練することで，読み上げと会話の音声のギャップを埋めうる\u003c/p\u003e\n\u003cp\u003eしかし，そのような試みは少ない\u003c/p\u003e\n\u003cp\u003e以下が考えうる要因\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e声のプロと違い，普通の人々の音声は正確性，明瞭性に欠けるから，音声合成に相応しくないという思い込み\u003c/li\u003e\n\u003cli\u003e会話音声の多様性．テキストだけでは説明できない音声のパラ言語的な特徴の変動が読み上げ音声に比べて大きく，モデル化が相対的に困難なこと\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e会話コーパスの小ささ．音声合成ではデータりょうが品質に直結するが，会話コーパスの場合，話者一人当たりのデータ量が少なく，音声のモデル化が困難なこと\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003e筆者ら研究チームでは，とりわけこれがネックだった\u003c/li\u003e\n\u003cli\u003e→ ニューラルボコーダ（高木, 2019）の登場によりインパクトに\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e実験として，読み上げ独話音声コーパスJSUT vs 自発対話音声コーパスUUDB（宇都宮大学パラ言語情報研究向け音声対話データベース）\u003c/p\u003e\n\u003cp\u003e音声合成にはTacotron 2，スペクトルからの波形生成にはMelGAN\u003c/p\u003e\n\u003cp\u003eUUDBでは女性話者1名のデータでfine-tuning\u003c/p\u003e\n\u003cp\u003eMMDAgentを利用して音声対話システムを構築（研究仮説を検証するため）\u003c/p\u003e\n\u003cp\u003e国当てクイズの対話シナリオ\u003c/p\u003e\n\u003cp\u003e実験結果とその対話動画視聴から得たアンケート結果\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/863qbviy.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/article/%E5%AF%BE%E8%A9%B1%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AF%E3%81%A9%E3%81%AE%E3%82%88%E3%81%86%E3%81%AB%E8%A9%B1%E3%81%99%E3%81%B9%E3%81%8D%E3%81%8B/gi2f1kw7.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e自然な会話コーパス（ここではUUDB）を元にした合成音声で話すシステムとの対話の方が，人同士の対話に近い振る舞いをしている．\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e感情表出系感動詞及び笑いの数に有意な差は認められず\u003c/p\u003e\n\u003cp\u003e「不気味の谷」？？？\u003c/p\u003e\n\u003ch2\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e自然な音声対話の実現を望むならば，もっと本物の音声コミュニケーションと真剣に向き合わなければならないのではないか？\u003c/p\u003e\n\u003ch2\u003eその他（なぜ通ったか？等）\u003c/h2\u003e\n\u003ch2\u003e次読みたい論文\u003c/h2\u003e\n\u003ch2\u003e引用\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e@article{2022,\nauthor = {森 大毅},\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003edoi = {10.20697/jasj.78.5_283},\njournal = {日本音響学会誌},\nnumber = {5},\npages = {283-288},\ntitle = {対話システムはどのように話すべきか},\nvolume = {78},\nyear = {2022},\nbdsk-url-1 = {\u003ca href=\"https://doi.org/10.20697/jasj.78.5_283\"\u003ehttps://doi.org/10.20697/jasj.78.5_283\u003c/a\u003e}}\u003c/p\u003e","Title":"【論文まとめ】対話システムはどのように話すべきか","Date":"2023-07-10","Category":"論文","Tags":["聞き手反応","dialogue system"],"Authos":"ゆうぼう","Slug":"対話システムはどのように話すべきか","Description":"対話システムはどのように話すべきかのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","Contrastive Learning","CSS","Dialogue Structure Learning","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLG","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","聞き手反応","超解像"]},"__N_SSG":true},"page":"/[slug]","query":{"slug":"対話システムはどのように話すべきか"},"buildId":"JH1zPBZfb3-e96j1PXu_c","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>