{"pageProps":{"TaggedPostData":[{"contentHtml":"<p>Transformersã‚’ä½¿ã£ã¦å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’tokenizeã™ã‚‹ã¨ãã«ï¼Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒå¤§ãã‹ã£ãŸã®ã§ï¼Œãƒãƒƒãƒå˜ä½ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸã‹ã£ãŸæ™‚ãŒã‚ã‚Šã¾ã—ãŸï¼</p>\n<p>ã“ã®æ™‚ï¼Œcollate_fnã«å¯¾ã—ã¦è¤‡æ•°ã®å¼•æ•°ã‚’ä¸ãˆãŸã‹ã£ãŸçŠ¶æ³ã®æ™‚ã®å¯¾å‡¦æ³•ã§ã™ï¼(æ—¥æœ¬èªå¤‰ã‹?)</p>\n<h2>ã‚„ã‚ŠãŸã‹ã£ãŸã“ã¨</h2>\n<p>DataLoaderã‚’å®šç¾©ã™ã‚‹ã¨ãã«ï¼Œ<code>collate_fn</code>ã®ã¨ã“ã‚ã§è‡ªä½œcollate_fnã‚’æŒ‡å®šã—ã¦ï¼Œbatchå˜ä½ã§æµã‚Œã¦ãã‚‹ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ï¼</p>\n<p>ã“ã‚ŒãŒã‚„ã‚ŠãŸã„ã“ã¨ã«ãªã‚Šã¾ã™ï¼ã¤ã¾ã‚Šã“ã‚“ãªæ„Ÿã˜</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyDataset</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=custom_collate_fn)  <span class=\"hljs-comment\"># &#x3C;--- ã“ã“ã§è‡ªä½œcollate_fnã‚’æŒ‡å®šã—ã¦åˆ¶å¾¡</span>\n</code></pre>\n<h2>ã‚„ã£ã¦ã†ã¾ãã„ã‹ãªã‹ã£ãŸã“ã¨</h2>\n<p>å…ˆã«ã‚„ã£ã¦ã†ã¾ãã„ã‹ãªã‹ã£ãŸã“ã¨ã‚’å…±æœ‰ã—ã¦ãŠãã¾ã™ï¼</p>\n<p>è‡ªåˆ†ãŒä½¿ã£ã¦ã„ã‚‹ã®ãŒï¼Œ<code>pytorch-lightning</code>ãªã®ã§ãã®ã›ã„ã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼ãªã®ã§ï¼Œã‚‚ã—ã‹ã—ãŸã‚‰æ™®é€šã«ç´ ã®Pytorchãªã‚‰ã†ã¾ãã„ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼</p>\n<p>æ•™ãˆã¦ãã ã•ã„ğŸ™</p>\n<h3>lambdaå¼ã§åˆ¶å¾¡ã™ã‚‹ (functools.partialã‚’ä½¿ã†)</h3>\n<p>ã“ã‚“ãªã“ã¨ã‚’ã—ã¾ã—ãŸï¼</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyDataset</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n        <span class=\"hljs-keyword\">return</span> text, label\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">custom_collate_fn</span>(<span class=\"hljs-params\">data, tokenizer, max_length</span>):\n    texts, labels = <span class=\"hljs-built_in\">zip</span>(*data)\n    texts = <span class=\"hljs-built_in\">list</span>(texts)\n    texts = tokenizer.batch_encode_plus(\n        texts,\n        padding=<span class=\"hljs-literal\">True</span>,\n        truncation=<span class=\"hljs-literal\">True</span>,\n        max_length=max_length,\n        return_tensors=<span class=\"hljs-string\">'pt'</span>,\n    )\n    labels = torch.LongTensor(labels)\n    <span class=\"hljs-keyword\">return</span> texts, labels\n\ntokenizer = AutoTokenizer.from_pretrained(...)\nmax_length = <span class=\"hljs-number\">256</span>\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=<span class=\"hljs-keyword\">lambda</span> data: custom_collate_fn(data, tokenizer, max_length))\n</code></pre>\n<p><code>pytorch-lightning</code>ã®ä»•æ§˜ã ã¨ã¯æ€ã†ã®ã§ã™ãŒï¼Œ<code>pickle</code>ã§åœ§ç¸®ã™ã‚‹ã‚‰ã—ããã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã‚¨ãƒ©ãƒ¼ã‚’åã‹ã‚Œã¾ã—ãŸï¼</p>\n<p>ãªãœã ã‚ã†...æœ‰è­˜è€…ã®æ–¹æ•™ãˆã¦ãã ã•ã„...</p>\n<h2>ã€è§£æ±ºç­–ã€‘ classã§å®šç¾©ã™ã‚‹</h2>\n<p>lambdaå¼ã§ãƒ€ãƒ¡ã ã£ãŸã®ã§ï¼Œã‚‚ã†ã‚¯ãƒ©ã‚¹ã®å†…éƒ¨ã«å¿…è¦ãªã‚‚ã®ã‚’ä¿æŒã•ã›ã¦ãŠã“ã†ã¨ã„ã†ã“ã¨ã«ãªã‚Šã¾ã—ãŸï¼(åƒ•ã®ä¸­ã§ã¯)</p>\n<p>æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ãªæ„Ÿã˜ã§è§£æ±ºã—ã¾ã—ãŸï¼</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyDataset</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n        <span class=\"hljs-keyword\">return</span> text, label\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CollateFn</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, tokenizer, max_length: <span class=\"hljs-built_in\">int</span></span>) -> <span class=\"hljs-literal\">None</span>:\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        os.environ[<span class=\"hljs-string\">\"TOKENIZERS_PARALLELISM\"</span>] = <span class=\"hljs-string\">\"true\"</span>  <span class=\"hljs-comment\"># &#x3C;--- å¤šåˆ†ã“ã‚Œã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã—ãªã„ã¨æ€’ã‚‰ã‚Œã¾ã™ (true|false)</span>\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__call__</span>(<span class=\"hljs-params\">self, data</span>):\n        texts, labels = <span class=\"hljs-built_in\">zip</span>(*data)\n        texts = <span class=\"hljs-built_in\">list</span>(texts)\n        texts = self.tokenizer.batch_encode_plus(\n            texts,\n            padding=<span class=\"hljs-literal\">True</span>,\n            truncation=<span class=\"hljs-literal\">True</span>,\n            max_length=self.max_length,\n            return_tensors=<span class=\"hljs-string\">'pt'</span>,\n        )\n        labels = torch.LongTensor(labels)\n        <span class=\"hljs-keyword\">return</span> texts, labels\n\ntokenizer = AutoTokenizer.from_pretrained(...)\nmax_length = <span class=\"hljs-number\">256</span>\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=CollateFn(tokenizer, max_length))\n</code></pre>\n<h2>ã¾ã¨ã‚</h2>\n<p>ç´ ã®Pytorchã§çµ„ã‚ã°å•é¡Œãªã‹ã£ãŸã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒï¼Œ<code>pytorch-lightning</code>ã‚’ä½¿ã£ã¦ã„ã‚‹æ–¹ã¯åŒã˜çŠ¶æ³ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼</p>\n<p>ãã®æ™‚ã¯ï¼Œãœã²å‚è€ƒã«classã§collate_fnã§å®Ÿè£…ã—ã¦ã¿ã¦è§£æ±ºã®ä¸€åŠ©ã¨ãªã‚ŒãŸã‚‰å¹¸ã„ã§ã™ï¼</p>","Title":"collate_fnã§è¤‡æ•°ã®å¼•æ•°ã‚’å–ã‚ŠãŸã„!!","Date":"2021-12-24","Category":"Python","Tags":["ML","Python","Pytorch"],"Authors":"ã‚†ã†ã¼ã†","Slug":"pytorch-collate_fn-args","Thumbnail":"/images/thumbnails/pytorch-logo.jpg","Description":"Transformersã‚’ä½¿ã£ã¦å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’tokenizeã™ã‚‹ã¨ãã«ï¼Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒå¤§ãã‹ã£ãŸã®ã§ï¼Œãƒãƒƒãƒå˜ä½ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸã‹ã£ãŸæ™‚ãŒã‚ã‚Šã¾ã—ãŸï¼ã“ã®æ™‚ï¼Œcollate_fnã«å¯¾ã—ã¦è¤‡æ•°ã®å¼•æ•°ã‚’ä¸ãˆãŸã‹ã£ãŸçŠ¶æ³ã®æ™‚ã®å¯¾å‡¦æ³•ã§ã™ï¼(æ—¥æœ¬èªå¤‰ã‹ã‚‚)","Published":true},{"contentHtml":"<p>ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’scikit-learnã§å®Ÿè£…ã—ã¦ã„ã‚‹ã¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯L2æ­£å‰‡åŒ–ã§ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸ãˆã¦ã„ã¾ã™ã€‚</p>\n<p>ãã“ã§ã€ã‚‚ã£ã¨ã‚¹ãƒ‘ãƒ¼ã‚¹ã«ã—ã¦ã‚„ã‚ã†ã¨L1æ­£å‰‡åŒ–ã‚’è¡ŒãŠã†ã¨ã—ãŸã®ã ãŒã€ã‚¨ãƒ©ãƒ¼ã‚’åã‹ã‚ŒãŸã€‚ãã®æ™‚ã®è§£æ±ºç­–ã‚’å…±æœ‰ã—ã¾ã™ã€‚</p>\n<h2>ã‚¨ãƒ©ãƒ¼ã‚’åã‹ã‚ŒãŸæ™‚ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³</h2>\n<p>ä¸€å¿œæœ€è¿‘é–‹ç™ºãŒç«‹ã¦è¾¼ã‚“ã§ã„ã‚‹ã®ã§ã€Anacondaã‚’ä½¿ã£ã¦é–‹ç™ºç’°å¢ƒã‚’åˆ†ã‘ã¦ã„ã‚‹ã®ã§ã™ãŒã€</p>\n<pre><code class=\"hljs language-bash\">(base)$ conda activate ML\n(ML)$ conda list    (pip listã§ã‚‚è¡Œã‘ã‚‹)\n......\n......\nscikit-learn           0.23.1    \n......\n</code></pre>\n<p>ã¨ã„ã†ã“ã¨ã§ã€scikit-learnã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯<em>0.23.1</em>ã§ã—ãŸã€‚</p>\n<h2>å®Ÿè£…ã—ã¦ã¿ã‚‹</h2>\n<p>ãã‚Œã§ã¯å®Ÿè£…ã—ã¦ã¿ã¾ã™ã€‚è‡³ã£ã¦ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆã§å‹•ãæƒ³å®šã§ã‚„ã£ã¦ã„ãã¾ã™ã€‚ã“ã¡ã‚‰ã§å¤‰åŒ–ã•ã›ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã«ãªã‚Šã¾ã™ã€‚</p>\n<table>\n<thead>\n<tr>\n<th>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>\n<th>å€¤</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>C(æ­£å‰‡åŒ–ã®ã¤ã‚ˆã•)</td>\n<td>1(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)</td>\n</tr>\n<tr>\n<td>penalty</td>\n<td>L1æ­£å‰‡åŒ–</td>\n</tr>\n<tr>\n<td>max_iter(ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸Šé™)</td>\n<td>100000</td>\n</tr>\n</tbody>\n</table>\n<p>ã¾ãŸã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿(X_train, y_train)ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿(X_test, y_test)ã«åˆ†ã‘ã¦ã‚ã‚‹ã“ã¨ã«ã—ã¾ã™ã€‚</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> sklearn.linear_model <span class=\"hljs-keyword\">import</span> LogisticRegression\n\nlr_l1 = LogisticRegression(penalty=<span class=\"hljs-string\">'l1'</span>, max_iter=<span class=\"hljs-number\">100000</span>).fit(X_train, y_train)\n</code></pre>\n<p>ã™ã‚‹ã¨ã“ã‚“ãªã‚¨ãƒ©ãƒ¼ãŒè¿”ã£ã¦ãã¾ã™ã€‚</p>\n<pre><code class=\"hljs language-bash\">~/opt/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py <span class=\"hljs-keyword\">in</span> fit(self, X, y, sample_weight)\n1302         The SAGA solver supports both float64 and float32 bit arrays.\n1303         <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n-> 1304         solver = _check_solver(self.solver, self.penalty, self.dual)\n1305 \n1306         if not isinstance(self.C, numbers.Number) or self.C &#x3C; 0:\n\n~/opt/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py in _check_solver(solver, penalty, dual)\n441     if solver not in ['liblinear', 'saga'] and penalty not in ('l2', 'none'):\n442         raise ValueError(\"</span>Solver %s supports only <span class=\"hljs-string\">'l2'</span> or <span class=\"hljs-string\">'none'</span> penalties, <span class=\"hljs-string\">\"\n--> 443                          \"</span>got %s penalty.<span class=\"hljs-string\">\" % (solver, penalty))\n444     if solver != 'liblinear' and dual:\n445         raise ValueError(\"</span>Solver %s supports only <span class=\"hljs-string\">\"\n\nValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n</span></code></pre>\n<p>ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ã‚Šã‹ã¯äººãã‚Œãã‚Œã§ã™ãŒã€ã‚¨ãƒ©ãƒ¼ã¯è¿”ã£ã¦ãã¾ã™ã€‚<br>\nãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®<strong>SolverãŒlbfgs</strong>ã«å¤‰ã‚ã£ã¦ã„ãŸãã†ã§ã€l2ã¾ãŸã¯noneã—ã‹ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ãã†ã§ã™ã€‚</p>\n<p>ã¨ã„ã†ã‚ã‘ã§ã€Solverã«<strong>liblinear</strong>ã‚’æŒ‡å®šã—ãªã„ã¨ã„ã‘ãªã„ã‚ˆã†ã§ã™ã­ã€‚</p>\n<h2>liblinearã‚’æŒ‡å®šã™ã‚‹</h2>\n<p>å…ˆã»ã©ã®ã‚¨ãƒ©ãƒ¼ã‚’ãªãã™ãŸã‚ã€æ–°ãŸã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¶³ã—ã¾ã™ã€‚</p>\n<table>\n<thead>\n<tr>\n<th>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</th>\n<th>å€¤</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>C(æ­£å‰‡åŒ–ã®ã¤ã‚ˆã•)</td>\n<td>1(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)</td>\n</tr>\n<tr>\n<td>penalty</td>\n<td>L1æ­£å‰‡åŒ–</td>\n</tr>\n<tr>\n<td>max_iter(ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸Šé™)</td>\n<td>100000</td>\n</tr>\n<tr>\n<td>solver</td>\n<td>liblinear</td>\n</tr>\n</tbody>\n</table>\n<p>ã§ã¯è¶³ã—ã¾ã™ã€‚</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> sklearn.linear_model <span class=\"hljs-keyword\">import</span> LogisticRegression\n\nlr_l1 = LogisticRegression(penalty=<span class=\"hljs-string\">'l1'</span>, solver=<span class=\"hljs-string\">'liblinear'</span>, max_iter=<span class=\"hljs-number\">100000</span>).fit(X_train, y_train)\n</code></pre>\n<p>ã“ã‚Œã§ç„¡äº‹å‹•ãã‚ˆã†ã«ãªã‚Šã¾ã—ãŸ!!!</p>\n<h2>ã¾ã¨ã‚</h2>\n<p>ã¾ã¨ã‚ã§ã™ã€‚<br>\nscikit-learnã‚’ç”¨ã„ã¦ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’ä½¿ã†æ™‚ã€ã•ã‚‰ã«L1æ­£å‰‡åŒ–ã‚’ã‹ã‘ãŸã„æ™‚ã¯**solver='liblinear'**ã‚’å¼•æ•°ã«è¿½åŠ ã—ã¾ã—ã‚‡ã†ã€‚</p>\n<p>ã“ã®å‘¨ã‚Šã¯è‰²ã€…ã¨å¤‰åŒ–ãŒæ—©ã„ã®ã§ã€æœ¬ã‚’è²·ã†éš›ã«ã‚‚åˆç‰ˆç­‰ã‚‚ç¢ºèªã—ã¤ã¤è²·ã£ãŸæ–¹ãŒè‰¯ã„æ°—ãŒã—ã¾ã—ãŸã€‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèªã‚‚å¤§åˆ‡ã«ã€‚</p>","Title":"ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã§L1æ­£å‰‡åŒ–ã‚’åˆ©ç”¨ã§ããªã„å•é¡Œã®è§£æ±ºæ³•","Date":"2020-08-01","Category":"Python","Tags":["ML","Python","Scikit-learn"],"Authors":"ã‚†ã†ã¼ã†","Slug":"logistic-with-l1","Thumbnail":"/images/thumbnails/network.jpg","Description":"ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã‚’scikit-learnã§å®Ÿè£…ã—ã¦ã„ã‚‹ã¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯L2æ­£å‰‡åŒ–ã§ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸ãˆã¦ã„ã¾ã™ã€‚ãã“ã§ã€ã‚‚ã£ã¨ã‚¹ãƒ‘ãƒ¼ã‚¹ã«ã—ã¦ã‚„ã‚ã†ã¨L1æ­£å‰‡åŒ–ã‚’è¡ŒãŠã†ã¨ã—ãŸã®ã ãŒã€ã‚¨ãƒ©ãƒ¼ã‚’åã‹ã‚ŒãŸã€‚ãã®æ™‚ã®è§£æ±ºç­–ã‚’å…±æœ‰ã—ã¾ã™ã€‚","Published":true},{"contentHtml":"<p>ä¸€å¿œå‚è€ƒæ›¸é€šã‚Šã«å­¦ç¿’ã™ã‚‹ã®ã ãŒã€åŸºæœ¬çš„ã«ã¯ã„ã¤ã‚‚æœ€æ–°ç‰ˆã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ä½¿ã†äººé–“ãªã‚‚ã®ã§ã€WarningåŠã³Errorã¨ã®æˆ¦ã„ã¯ã‚ˆãã‚ã‚‹ã“ã¨ã§ã™ã€‚ã®ã§ã€Warningã¨ã‹ãŒå‡ºã‚‹ã¨ã†ã£ã¨èº«æ§‹ãˆã¦ã—ã¾ã†ã®ã§ã€å›°ã‚‰ãªã„ã‚ˆã†ã«å‚™å¿˜éŒ²ã‹ã¤åé¢æ•™å¸«ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚</p>\n<h2>ã¨ã‚Šã‚ãˆãšmake_forge()ã‚’ã‚„ã£ã¦ã¿ã‚ˆã†ã‹</h2>\n<p>ã¨ã‚Šã‚ãˆãšmake_forge()ã§forgeãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€Warningã•ã›ã¦ã¿ã¾ã™ã‹ã­ã€‚ã€‚ã€‚</p>\n<p>ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯mglearnã‚’ä½¿ã†ã®ã§pipç’°å¢ƒãŒã‚ã‚‹äººã¯ã€<strong>pip install mglearn</strong>ã‚’ã—ã¦ãã ã•ã„ã€‚ãã®ä¸Šã§ã€</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> mglearn    <span class=\"hljs-comment\"># mglearnã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ</span>\nX, y = mglearn.datasets.make_forge()    <span class=\"hljs-comment\"># make_forgeãƒ¡ã‚½ãƒƒãƒ‰ã§ç”Ÿæˆ</span>\n</code></pre>\n<p>ä»¥ä¸‹ãŒã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã§ã™ã€‚</p>\n<pre><code class=\"hljs language-bash\">/Users/user/opt/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/utils/deprecation.py:86: FutureWarning: Function make_blobs is deprecated; Please import make_blobs directly from scikit-learn\nwarnings.warn(msg, category=FutureWarning)\n</code></pre>\n<p>ãªã‚“ã ã‹Warningã§æ€’ã‚‰ã‚Œã¾ã—ãŸorz</p>\n<p>å°†æ¥çš„ã«sklearn.datasets.makeblobs()ã¨è¢«ã‚‹ã‚ˆã£ã¦ã“ã¨ã‚’è¨€ã„ãŸã„ã‚‰ã—ã„ã§ã™ã€‚<em>scikit-learnã‹ã‚‰ç›´æ¥make_blobsã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã‚</em>ã¨ã‹è¨€ã£ã¦ã¾ã™ã­ã€‚\næ¬¡ã‹ã‚‰Warningã‚’é¿ã‘ã¦è¡Œãã¾ã™ã€‚</p>\n<h2>make_blobsã«ä¹—ã‚Šæ›ãˆã‚‹</h2>\n<p>make_blobsãƒ¡ã‚½ãƒƒãƒ‰ã«ä¹—ã‚Šæ›ãˆã¦è¡Œãã¾ã™ã€‚ã“ã‚Œã¯scikit-learnã®datasetsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å«ã¾ã‚Œã¦ã„ã‚‹ã¿ãŸã„ãªã®ã§ã€ã“ã„ã¤ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦è¡Œãã¾ã™ã€‚</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> sklearn.datasets <span class=\"hljs-keyword\">import</span> make_blobs    <span class=\"hljs-comment\"># ã“ã‚Œã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†</span>\n</code></pre>\n<p>ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒã†ã¾ãã„ã£ãŸã‚‰æ¬¡ã¯ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚</p>\n<pre><code class=\"hljs language-python\">X, y = make_blobs()\n</code></pre>\n<p>ã“ã‚Œã§ãƒ‡ãƒ¼ã‚¿ãŒã†ã¾ãç”Ÿæˆã•ã‚ŒãŸã‚ˆã†ã§ã™ã€‚ç„¡äº‹Warningã‚‚å‡ºã¦ãã¾ã›ã‚“!!!\nå¿µã®ãŸã‚ã€Xã®å‹ã‚’ã¿ã¦è¡Œãã¾ã™ã€‚</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"X.shape: {}\"</span>.<span class=\"hljs-built_in\">format</span>(X.shape))\n\n<span class=\"hljs-comment\"># -> X.shape: (100, 2)</span>\n</code></pre>\n<p>è©°ã¾ã‚‹ã¨ã“ã‚ã€2ã¤ã®ç‰¹å¾´é‡ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ãŒ100å€‹ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚100*2ã®è¡Œåˆ—ã§ã™ã­ã€‚\nmake_forge()ã®ã¨ãã¯2ã¤ã®ç‰¹å¾´é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒ26å€‹ã‚’æœŸå¾…ã—ã¦ã„ãŸã‚ˆã†ãªã®ã§ã€ãƒ‡ãƒ¼ã‚¿é‡ãŒå¢—ãˆãŸã¿ãŸã„ã§ã™ã­ã€‚</p>\n<h2>ã¾ã¨ã‚</h2>\n<p>mglearn.datasets.make_forge()ã§Warningã‚’å›é¿ã™ã‚‹æ–¹æ³•ã®ã¾ã¨ã‚ãŒã“ã¡ã‚‰ã§ã™ã€‚</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> sklearn.datasets <span class=\"hljs-keyword\">import</span> make_blobs    <span class=\"hljs-comment\"># ã‚¤ãƒ³ãƒãƒ¼ãƒˆ</span>\nX, y = make_blobs()    <span class=\"hljs-comment\"># make_blobsãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè¡Œ</span>\n\n<span class=\"hljs-string\">\"\"\"\nç¢ºèªã®ãŠã¾ã‘\n\"\"\"</span>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"X.shape: {}\"</span>.<span class=\"hljs-built_in\">format</span>(X.shape))\n\n<span class=\"hljs-comment\">#-> X.shape: (100, 2)    # ç‰¹å¾´é‡ã‚’2ã¤æŒã¤100å€‹ã®ãƒ‡ãƒ¼ã‚¿</span>\n</code></pre>\n<p>scikit-learnå‘¨ã‚Šã¯ã€ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãŒæ—©ã„ã®ã§å°‘ã—å¤ã„æŠ€è¡“æ›¸ãªã ã‘ã§ã‚‚ã€Future WarningãŒå‡ºãŸã‚Šã€ErrorãŒå‡ºãŸã‚Šã™ã‚‹ã“ã¨ãŒå¤šã€…ã‚ã‚Šã¾ã™ã€‚\næ°—ã‚’ã¤ã‘ãªãŒã‚‰å­¦ç¿’ã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚Šãã†ã§ã™ã­ã€‚ã§ã¯ã€ä»Šå›ã¯ã“ã“ã¾ã§ï¼</p>","Title":"scikit-learnã®make_blobsã«ä¹—ã‚Šæ›ãˆã‚ˆã†!!","Date":"2020-07-21","Category":"Python","Tags":["ML","Python","Scikit-learn"],"Authors":"ã‚†ã†ã¼ã†","Slug":"prefer-to-make_blobs","Thumbnail":"/images/thumbnails/python.jpg","Description":"Pythonã§ã¯ã˜ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’ã‚’ã‚„ã£ã¦ã„ã‚‹æœ€ä¸­ã«ã€mglearnã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰make_forge()ãƒ¡ã‚½ãƒƒãƒ‰ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã£ãŸã®ã§ã™ãŒã€WarningãŒå‡ºã¦æ€’ã‚‰ã‚ŒãŸã®ã§ã€æ¨å¥¨ã•ã‚Œã‚‹å½¢ã«æˆ»ã™ãŸã‚ã«äº’æ›æ€§ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã«ç›´ã—ã¾ã™ã€‚","Published":true},{"contentHtml":"<h2>ã‚³ãƒ¼ãƒ‘ã‚¹ã¨ã¯</h2>\n<p>**ã‚³ãƒ¼ãƒ‘ã‚¹(corpus)**ã¨ã¯ã€é›†ã‚ãŸæ–‡æ›¸ã®ã“ã¨ã‚’ã„ã„ã¾ã™ã€‚</p>\n<p>ã‚‚ã¨ã‚‚ã¨ã®åŸç¾©ã¨ã—ã¦ã¯ã€ã‚ã‚‹ä¸»é¡Œã¨ã‹ã‚ã‚‹ä½œè€…ã«é–¢ã™ã‚‹æ–‡æ›¸ã‚’é›†ã‚ãŸã‚‚ã®ãŒã‚³ãƒ¼ãƒ‘ã‚¹ã¨å‘¼ã°ã‚Œã¦ã„ãŸãã†ã§ã™ã€‚</p>\n<p>ç¾åœ¨ã¯ã‚‚ã†å°‘ã—åºƒç¾©ã§æ‰ãˆã‚‰ã‚Œã€<strong>æ–‡æ›¸ã‚„éŸ³å£°ã‚’é›†ã‚ãŸãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®ã€ã‚ã‚‹ã„ã¯ãƒ‡ãƒ¼ã‚¿ã«æƒ…å ±ã‚’ä»˜ä¸ã—ã¦åŠ å·¥ã—ãŸã‚‚ã®</strong>ã‚’ç·ç§°ã—ã¦ã‚³ãƒ¼ãƒ‘ã‚¹ã¨ã„ã†ãã†ã§ã™ã€‚</p>\n<p>æœ€è¿‘ã®è‡ªç„¶è¨€èªå‡¦ç†ã®ã‚¿ã‚¹ã‚¯ã®é€²å±•ã¯ã€ã“ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã«æ´»ç”¨ã«ã‚ˆã‚‹éƒ¨åˆ†ãŒå¤šã„ã§ã™ã€‚</p>\n<h2>ç”Ÿã‚³ãƒ¼ãƒ‘ã‚¹(raw corpus)</h2>\n<p>å‰ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è©±ã—ãŸã‚ˆã†ã«ã€ã‚³ãƒ¼ãƒ‘ã‚¹ã«ã¯åŠ å·¥ã‚’åŠ ãˆãŸã‚‚ã®ã¨ã€ãã®ã¾ã¾ç”Ÿãƒ‡ãƒ¼ã‚¿ã®ã‚‚ã®ã¨äºŒé€šã‚Šè€ƒãˆã‚‰ã‚Œã¾ã—ãŸã€‚</p>\n<p>ãã“ã§ã€ç”Ÿãƒ‡ãƒ¼ã‚¿ã®ã¾ã¾ã®æ–‡ç« ã‚„éŸ³å£°ã‚’ã€Œ<strong>ç”Ÿã‚³ãƒ¼ãƒ‘ã‚¹(raw corpus)</strong>ã€ã¨å‘¼ã¶ã“ã¨ãŒã§ãã¾ã™ã€‚</p>\n<h2>ç¿»è¨³ã«é–¢ã™ã‚‹ã‚³ãƒ¼ãƒ‘ã‚¹ã®åˆ†é¡</h2>\n<p>ç”Ÿã‚³ãƒ¼ãƒ‘ã‚¹ã®ä¸­ã§ã‚‚ã€ãã®ç¨®ã¯ã„ãã¤ã‹å­˜åœ¨ã—ã¾ã™ã€‚\nã“ã®ãƒˆãƒ”ãƒƒã‚¯ã§ã¯æ©Ÿæ¢°ç¿»è¨³ã§æ‰±ã‚ã‚Œã‚‹ã‚ˆã†ãªã‚³ãƒ¼ãƒ‘ã‚¹ã®åˆ†é¡ã«ã¤ã„ã¦ãŠè©±ã—ã¾ã™ã€‚</p>\n<h2>#å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹</h2>\n<p>ã¾ãšã¯ã€ã€Œ<strong>å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹(bilingual corpus)</strong>ã€ã¾ãŸã¯ã€Œ<strong>ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹(parallel corpus)</strong>ã€ã§ã™ã€‚</p>\n<p>ã“ã®å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã¨ã¯ã€ç¿»è¨³é–¢ä¿‚ã«ã‚ã‚‹2è¨€èªã®æ–‡æ›¸å¯¾ã‚’åé›†ã—ãŸç”Ÿã‚³ãƒ¼ãƒ‘ã‚¹ã«ãªã‚Šã¾ã™ã€‚ã“ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã¯ã€éå¸¸ã«è²´é‡ã§ã¯ã‚ã‚Šã¾ã™ãŒã€ãªã‹ãªã‹å…¥æ‰‹ã—ã«ãã„å¸Œå°‘ãªãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚ã—ã‹ã—ã€ã“ã®å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã¯æ©Ÿæ¢°ç¿»è¨³ã«ãŠã„ã¦ã¨ã¦ã‚‚é‡è¦ãªçŸ¥è­˜æºã¨ãªã£ã¦ã„ã‚‹ã“ã¨ã¯ç¢ºã‹ã§ã™ã€‚</p>\n<h2>#ã‚³ãƒ³ãƒ‘ãƒ©ãƒ–ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹</h2>\n<p>å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã§ã¯ã€å¸Œå°‘ãªã‚³ãƒ¼ãƒ‘ã‚¹ã§ã‚ã£ãŸã®ã«å¯¾ã—ã¦ã€  ã€Œ<strong>ã‚³ãƒ³ãƒ‘ãƒ©ãƒ–ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹(comparable corpus)</strong>ã€ã¯ã€ã—ã£ã‹ã‚Šã¨ã—ãŸå¯¾è¨³é–¢ä¿‚ã«ãªã„ã«ã—ã¦ã‚‚ã€åŒã˜ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã—ã¦2è¨€èªã®æ–‡æ›¸å¯¾ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã§ã™ã€‚</p>\n<p>ã‚³ãƒ³ãƒ‘ãƒ©ãƒ–ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã¯ã€å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã»ã©ãã£ã¡ã‚Šã¨ã—ãŸå¯¾è¨³ãŒåˆ¶ç´„ã•ã‚Œãªã„ã®ã§ã€ã“ã®ã‚ˆã†ãªæ–‡æ›¸ã¯å¤§é‡ã«å­˜åœ¨ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ–‡æ›¸ã‚’åé›†ã—ãŸã‚‚ã®ãŒã‚³ãƒ³ãƒ‘ãƒ©ãƒ–ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã§ã™ã€‚</p>\n<p>ä¾‹ã¨ã—ã¦ã‚ã‹ã‚Šã‚„ã™ã„ã®ã¯ã€Wikipedeaã§ã—ã‚‡ã†ã€‚  Wikipediaã§ã¯è¨€èªãƒªãƒ³ã‚¯ã§ã¤ãªãŒã£ãŸè¤‡æ•°ã®è¨€èªã§ã®ãƒšãƒ¼ã‚¸ãŒå­˜åœ¨ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æ–‡æ›¸å¯¾ã§ã¯ãã£ã¡ã‚Šã¨ã—ãŸå¯¾è¨³ã¯ä¿è¨¼ã•ã‚Œã¾ã›ã‚“ãŒã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¥æ‰‹ã™ã‚‹ã“ã¨ãŒã§ãã€ã“ã‚Œã‚‚æ¥µã‚ã¦é‡è¦ãªçŸ¥è­˜æºã¨ãªã‚Šã¾ã™ã€‚</p>\n<h2>ã¾ã¨ã‚</h2>\n<p>ä»¥ä¸ŠãŒã‚³ãƒ¼ãƒ‘ã‚¹ã«é–¢ã™ã‚‹ç°¡å˜ãªèª¬æ˜ã§ã—ãŸã€‚ä»–ã«ã‚‚å‡è¡¡ã‚³ãƒ¼ãƒ‘ã‚¹(balanced corpus)ã‚„æ³¨é‡ˆã‚³ãƒ¼ãƒ‘ã‚¹(annotated corpus)ã¨ã„ã£ãŸåˆ†é¡ã‚‚ã‚ã‚Šã¾ã™ã€‚</p>\n<p>ã“ã“ã§æŠ‘ãˆã‚‹ã¹ãé‡è¦ãªã“ã¨ã¯ã€ã‚³ãƒ¼ãƒ‘ã‚¹ã¨ã¯åºƒç¾©ã§<strong>æ–‡æ›¸ã‚„éŸ³å£°ã‚’é›†ã‚ãŸãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®ã€ã‚ã‚‹ã„ã¯ãƒ‡ãƒ¼ã‚¿ã«æƒ…å ±ã‚’ä»˜ä¸ã—ã¦åŠ å·¥ã—ãŸã‚‚ã®</strong>ã¨ã„ã†ã“ã¨ã§ã—ã‚‡ã†ã€‚</p>\n<p>ä»Šå›ã¯ä¸»ã«ã‚³ãƒ¼ãƒ‘ã‚¹ã®èª¬æ˜ã¨ã¨ã‚‚ã«ç”Ÿã‚³ãƒ¼ãƒ‘ã‚¹ã«ã¤ã„ã¦ã®èª¬æ˜ã‚’ã—ã¦ã„ãã¾ã—ãŸã€‚å®Ÿéš›ã«åŠ å·¥ã‚’åŠ ãˆãŸã‚³ãƒ¼ãƒ‘ã‚¹ã«é–¢ã—ã¦ã¯ã€ã¾ãŸåˆ¥ã®è¨˜äº‹ã«ã—ãŸã„ã¨æ€ã„ã¾ã™!</p>","Title":"è‡ªç„¶è¨€èªå‡¦ç†(NLP)ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã£ã¦ä½•ãªã‚“ï¼Ÿ","Date":"2020-07-11","Category":"ML","Tags":["ML","NLP"],"Authors":"ã‚†ã†ã¼ã†","Slug":"corpus","Thumbnail":"/images/thumbnails/network.jpg","Description":"è‡ªç„¶è¨€èªå‡¦ç†ã¨ã„ã†æ©Ÿæ¢°å­¦ç¿’ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€Œã‚³ãƒ¼ãƒ‘ã‚¹ã€ã¨ã„ã†è¨€è‘‰ãŒå‡ºã¦ãã¾ã™ã€‚ãã®ã‚³ãƒ¼ãƒ‘ã‚¹ã«ã¤ã„ã¦ãŠè©±ã‚’ã—ã¦ã„ãã¾ã™ã€‚","Published":true}],"tag":"ML","categories":["è«–æ–‡","Web","JavaScript","Competition","Cloud","Python","Linux","ML","Go","SQL"],"tags":["Apache","Appium","ASR","atmaCup","AWS","brew","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","Contrastive Learning","CSS","Demo","Dialogue Structure Learning","dialogue system","DST","Emotion Recognition","empathetic dialogue system","encyclopedic","Error Correction","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Intent Classification","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","LLM","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","Merging Models","ML","Model Editing","Model Patching","MT","Multi-Hop Transformer","multi-modal","MySQL","NLG","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","SLU","Speech Disfluency","subprocess","Super-Resolution","survey","tensorflow","Tkinter","Transfer Learning","transformer","Weight Interpolation","zsh","ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘","ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿","ãƒ‡ãƒ¼ã‚¿åˆ†æ","ç‰¹æ®Šãƒ¡ã‚½ãƒƒãƒ‰","èãæ‰‹åå¿œ","è¶…è§£åƒ"],"pages":1,"page":1},"__N_SSG":true}