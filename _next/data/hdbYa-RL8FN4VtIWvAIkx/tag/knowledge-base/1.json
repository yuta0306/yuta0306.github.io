{"pageProps":{"TaggedPostData":[{"contentHtml":"<p>本記事において使用される図表は，原著論文内の図表を引用しています．</p>\n<p>また，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．</p>\n<h2>論文情報</h2>\n<p>タイトル: 知識源との一対多関係を有する対話コーパスによる発話生成</p>\n<p>研究会: NLP</p>\n<p>年度: 2022</p>\n<p>キーワード: dialogue system, knowledge-base</p>\n<p>URL: <a href=\"https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-3.pdf\">https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/B2-3.pdf</a></p>\n<p>データセット:</p>\n<h2>概要</h2>\n<p>ある文脈において利用可能な知識は一意とは限らず，実際に利用された知識意外にも利用可能な知識は存在する可能性がある</p>\n<p>→　旅行代理店における対話を題材として，基準対話データセットを作成（知識が一意）</p>\n<p>→　基準対話データセットを元にマルチラベル対話データセットを作成（知識が複数対応）</p>\n<p>マルチラベル対話データセットを発話生成モデルの生成に用いると，多様で適切な応答が可能になることが示唆</p>\n<h2>提案手法</h2>\n<p><img src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/4tpxgaoh.png\" alt=\"\"></p>\n<p><img src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/6h5aq4kv.png\" alt=\"\"></p>\n<p><strong>基準対話データセットの構築</strong></p>\n<p>クラウドソーシングを利用して，東京と大阪の観光地441件を対象に，観光地に関する対話おw収集</p>\n<p>知識情報として，基礎情報はじゃらんからスクレイピング，レビュー情報にはGoogle Map APIを用いて取得</p>\n<p>店発話は，知識情報をなるべく用いて発話し，使用できる知識情報源は最大で2つとした</p>\n<p>相槌など知識情報を使用しない発話にはnoneのラベルを付与</p>\n<p><strong>マルチラベルデータセットの構築</strong></p>\n<p>利用していない知識は，「利用できない知識」ではなく「利用していない知識」</p>\n<p>→　基準対話データセットから400件を抽出し，対象の発話において利用可能な知識をアノテーション</p>\n<p>基準対話データセットの分布とマルチラベル対話データセットの分布を比較すると，多くの知識源が利用可能であるとわかる</p>\n<h2>新規性</h2>\n<p>一つの発話に対して複数の知識を対応させたマルチラベル対話データセットを作成</p>\n<h2>実験</h2>\n<p>Laboro製BERTを用いて利用可能な知識情報を選択</p>\n<p>→　TransformerベースのNTT製大規模対話モデルhobbyistを用いて，知識情報を用いた応答生成</p>\n<h2>まとめ</h2>\n<p><img src=\"/images/article/%E7%9F%A5%E8%AD%98%E6%BA%90%E3%81%A8%E3%81%AE%E4%B8%80%E5%AF%BE%E5%A4%9A%E9%96%A2%E4%BF%82%E3%82%92%E6%9C%89%E3%81%99%E3%82%8B%E5%AF%BE%E8%A9%B1%E3%82%B3%E3%83%BC%E3%83%91%E3%82%B9%E3%81%AB%E3%82%88%E3%82%8B%E7%99%BA%E8%A9%B1%E7%94%9F%E6%88%90/yy6uxb1q.png\" alt=\"\"></p>\n<p>BERTを用いた知識選択</p>\n<p>シングルtestが0.46，マルチtestが0.90</p>\n<p>適切な知識が選択できていれば正解なので，マルチが高くなるのはそれはそう</p>\n<p>マルチラベル対話データセットを使用した応答生成は，全て文脈として正しく，知識を反映した多様かつ適切な生成ができていた</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h2>次読みたい論文</h2>\n<h2>引用</h2>\n<blockquote>\n</blockquote>","Title":"【論文まとめ】知識源との一対多関係を有する対話コーパスによる発話生成","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","knowledge-base"],"Authos":"ゆうぼう","Slug":"知識源との一対多関係を有する対話コーパスによる発話生成","Thumbnail":"/images/thumbnails/知識源との一対多関係を有する対話コーパスによる発話生成.png","Description":"知識源との一対多関係を有する対話コーパスによる発話生成のまとめ","Published":true},{"contentHtml":"<p>本記事において使用される図表は，原著論文内の図表を引用しています．</p>\n<p>また，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．</p>\n<h2>論文情報</h2>\n<p>タイトル: A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models</p>\n<p>研究会: arxiv</p>\n<p>年度: 2022</p>\n<p>キーワード: survey, NLP, knowledge-base, PLMKE, commonsense, encyclopedic, Knowledge-Intensive NLP</p>\n<p>URL: <a href=\"https://arxiv.org/pdf/2202.08772.pdf\">https://arxiv.org/pdf/2202.08772.pdf</a></p>\n<p>DOI: <a href=\"https://doi.org/10.48550/arXiv.2202.08772\">https://doi.org/10.48550/arXiv.2202.08772</a></p>\n<p>データセット:</p>\n<p>まとめること</p>\n<ol>\n<li>Knowledge-Intensive NLPの概要</li>\n<li>Knowledge Sources\n<ol>\n<li>Encyclopedic Knowledge</li>\n<li>Commonsense Knowledge</li>\n<li>最近のKnowledge Sourcesの特徴</li>\n</ol>\n</li>\n<li>Knowledge-Intensive NLP Task\n<ol>\n<li>Knowledge-Intensive NLP Taskの概要</li>\n<li>Knowledge-Intensive NLP Taskの特徴</li>\n</ol>\n</li>\n<li>Knowledge Fusion Methodsについて\n<ol>\n<li>Pre-Fusion Methods</li>\n<li>Post-Fusion Methods</li>\n<li>Hybrid-Fusion Methods</li>\n<li>代表的なモデルの紹介</li>\n</ol>\n</li>\n<li>Challengingなことと今後の方向性\n<ol>\n<li>Unified PLMKEs Across Tasks and Domains</li>\n<li>Reliability of Knowledge Sources</li>\n<li>Reasoning Module Design</li>\n</ol>\n</li>\n</ol>\n<h2>概要</h2>\n<p>事前学習済みモデルにより，モデルのcapacityは増加傾向にあるが，encyclopedicやcommonsenseを用いた，knowledgeableなNLPモデルの需要の高まりが生じている</p>\n<p>**PLMKEs (Pre-trained Language Model-based Knowledge-Enhanced models)**についてまとめたsurvey論文</p>\n<p>linguistic or factual knowledgeは暗示的にモデルのパラメータに保存される</p>\n<p>→事前学習済みのNLPモデルがより汎用的な能力を持つことを一部ではあるが説明できる</p>\n<p>今のpre-trained LMは，明示的なencyclopedicやcommonsenseのレバレッジ能力に欠けている</p>\n<p>PLMKEsは，関連する外部知識を取り出すモジュールと知識を混ぜるモジュールがある</p>\n<p>PLMKEsに関連した重要な3つの要素がある</p>\n<ol>\n<li>Knowledge Sources</li>\n<li>Knowledge-Intensive NLP Tasks</li>\n<li>Knowledge Fusion Methods</li>\n</ol>\n<h2>Knowledge Sources</h2>\n<h3>Encyclopedic knowledge</h3>\n<p>エンティティに関する属性とエンティティ間の関係性をもった知識</p>\n<p>Entity: person → Attributes: age → Relations: educated at</p>\n<p>Wikipediaは大量のencyclopedicな知識を持っている</p>\n<p>人物の経歴やイベントの背景などを含んでいる</p>\n<p>一般的にはtripletsで構成されていることが多い</p>\n<p>e.g. &#x3C;Tom Hanks, occupation, actor></p>\n<p>Wikidataのような知識データがPLMKEsに広く使用されている</p>\n<h3>Commonsense Knowledge</h3>\n<p>日常生活のなかでの状況に関する知識</p>\n<p>イベントとその影響を記す</p>\n<p>e.g. mop up the floor if we split food over it / study hard to win scholarship / goat has four legs</p>\n<p>commonsenseの特徴</p>\n<p>多くの人の間で共有されている知識であり，コミュニケーションの中で暗示的に想定されている知識である</p>\n<p>commonsenseもtripletsで表現される</p>\n<p>最近のPLMKEsでは，ConceptNetとATOMICが外部知識として使用されることが多い</p>\n<h3>Knowledge Sourcesの特徴</h3>\n<p><img src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/gcgqsmdk.png\" alt=\"\"></p>\n<p>large-scaleでdiverse</p>\n<p>現在のソースはより正確で安定的に作られている</p>\n<p>アノテーションのプロセスは部分的に自動化されていて，非エキスパートにもaccessibleになっている</p>\n<p>知識データがカバーするドメインは多様</p>\n<p>オープンドメインのものもあれば，specificなドメインのものも</p>\n<p>Wikipedia, DBPedia, Freebaseなどはオープンドメイン</p>\n<p>UMLSやAMinerなどはbiomedicineやscienceの特定ドメイン</p>\n<p>domain-specificなアプリケーションをブーストできる知識</p>\n<p>commonsenseに関しては</p>\n<p>ConceptNetやTransOMCSは複数のドメインのcommonsenseをカバー</p>\n<p>ATOMICやASERはある特定のタイプのcommonsenseにフォーカスした知識ソース</p>\n<h2>Knowledge-Intensive NLP Task</h2>\n<h3>概要</h3>\n<p>Knowledge-intensive NLP taskは必要とする知識ソースの種類で2つに分けられ，さらに詳細に分けることができる</p>\n<p><img src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/ju1lqjam.png\" alt=\"\"></p>\n<ul>\n<li>\n<p>encyclopedic knowledge-intensive NLP task\nencyclopedicの知識ソースを利用する</p>\n<ul>\n<li>open-domain QA</li>\n<li>fact verification</li>\n<li>entity linking</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/kr89pm58.png\" alt=\"\"></p>\n<ul>\n<li>\n<p>commonsense knowledge-intensive NLP task\ncommonsenseの知識ソースを利用する</p>\n<p>commonsenseの多様性のために，タスクのタイプ自体も多様化している</p>\n<p>モデルが正確に日常のシナリオを理解し，応答するか否かのテストにフォーカスしたタスク</p>\n<ul>\n<li>General Commonsense</li>\n<li>Social Commonsense</li>\n<li>Physical Commonsense</li>\n<li>Temporal Commonsense</li>\n</ul>\n</li>\n</ul>\n<h3>Knowledge-Intensive Taskの特徴</h3>\n<p>実際は，モデルにとってだけではなく，人間にとってもいかなる知識の参照なしに問題に答えるのは難しい．（バラクオバマの誕生日はいつ？など</p>\n<p>しかも，外部知識が必要なのにinputとして必要な外部知識が渡されないため，とてもチャレンジングなタスクになっている</p>\n<p>そもそも必要な外部知識にグラウンディングするモジュールをPLMKEsの設計に加えることを考慮するようになっている</p>\n<h2>Knowledge Fusion Methods</h2>\n<p>モデルが知識を統合するステージは二箇所あり，</p>\n<ul>\n<li>Pre-fusion; pre-training</li>\n<li>Post-fusion; fine-tuning</li>\n</ul>\n<p>の二通りが考えられる（もしくはその両方のステージ</p>\n<h3>Pre-Fusion Methods</h3>\n<p><img src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/z4lvh39q.png\" alt=\"\"></p>\n<p>pre-trainingのステージで知識を統合する手法</p>\n<p>モデルに知識を入力するため，構造化された知識データを非構造化データのテキストコーパスへと処理→モデルに入力</p>\n<p>テキストデータとして知識を入力するため，大きくモデルのアーキテクチャを変更する必要はない</p>\n<p>ただし，知識グラフのような構造化データを非構造化データへ変えることは難しいこともある</p>\n<p>簡単な対処法はエンティティと関係性を結合するか，流暢な文章をconditional text generation modelに生成させるか</p>\n<p>Zhang et al. 2019 | Agarwal et al. 2021 を参照（必要になれば読む</p>\n<h3>Post-Fusion Methods</h3>\n<p><img src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/bshr899d.png\" alt=\"\"></p>\n<p>まず，関連知識をキャプチャする</p>\n<p>次に取得した関連知識をGNNなどのエンコーダでembeddingを得る</p>\n<ul>\n<li>それを追加特徴量としてpre-trained LMに与える（図でいうA）</li>\n<li>直接pre-trained LMに入力する（図でいうB）</li>\n</ul>\n<h3>Hybrid-Fusion Methods</h3>\n<p><img src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/1yg24grj.png\" alt=\"\"></p>\n<p>pre-trainingとfine-tuningの両方のステージで知識を統合する</p>\n<p>追加の学習されるretrieverによりaugmentされたpre-trained modelは，fine-tuningのステージでより効果的にretrieverからの知識を活用できる</p>\n<p>retrieval-augmented pre-trainingでhybrid-fusionが広く使われている</p>\n<h3>代表的なモデル</h3>\n<p><img src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/xh93uokd.png\" alt=\"\"></p>\n<p><img src=\"/images/article/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models/cl36oka6.png\" alt=\"\"></p>\n<p>Table4/5はSOTAモデルを示す</p>\n<p>encyclopedic knowledge-intensive taskにおいては，BOOLQをのぞき，全てpost-fusionを採用</p>\n<p>commonsense knowledge-intensive taskにおいては，CommonsenseQAをのぞき，全てpre-fusionを採用</p>\n<p>pre-fusionとpost-fusionの違いは何？</p>\n<p>pre-fusionは，知識を事前学習のパラメータに暗示的に保存数る</p>\n<p>最終的にどの知識がパラメータに保存するのかを決定するのは難しい</p>\n<p>知識の引き出しや利用の難しさが増す</p>\n<p>post-fusionは，明示的で具体的なテキストの知識を推論できる</p>\n<p>post-fusionの利点は，commonsense knolwedge-intensive taskでは欠点になりうる</p>\n<p>commonsenseはたいていテキストの中に暗示的に置かれていて，commonsenseの知識ソースのカバー範囲はencyclopedicの知識ソースのカバー範囲に比べればとても小さい</p>\n<p>large-scaleなcommonsenseのソースの利用がたとえ有用だとしても，日常生活で使われる大半のcommonsenseを見落としがちなまま</p>\n<p>→commonsenseにおいて，post-fusionがあまり効かないのはそのためなのでは？</p>\n<h2>Challenges and Future Directions</h2>\n<h3>Unified PLMKEs Across Tasks and Domains</h3>\n<p>task-specificなモデリングでは進展がある</p>\n<p>post-fusionとhybrid-fusionはencyclopedicで適用されているが，commonsenseでは採用できておらず恩恵が得られていない</p>\n<p>異なるタスク間でのPLMKEsはユニークであるため，各タスク間で互換性がない</p>\n<p>biomedicalやlegalの知識に関するknowledge-intensive NLP taskまで拡張されている</p>\n<p>最近では，異なる時間や地域に存在する知識の多様性に対しても重要度を割り当てている</p>\n<p>タスク間やdomain間でのunified PLMKEsの必要性がましている</p>\n<h3>Reliability of Kowledge Sources</h3>\n<p>知識ソースの信頼性に関して</p>\n<p>多くのlarge-scaleな知識ソースは自動的な知識獲得アルゴリズムで構築されている</p>\n<p>→スケールと正確性はトレードオフになってしまう</p>\n<p>PLMKEsにおけるバイアスの増幅はバイアスのある知識ソースによって構築されてしまう</p>\n<p>知識獲得アルゴリズムの見直しや使う前の知識ソースの注意深い精査が必要である</p>\n<h3>Reasoning Module Design</h3>\n<p>Reasoningはknowledge-intensive NLP taskを解く上で重要なステップである</p>\n<p>commonsenseを考えるときは手順を踏んで，複雑な状況を把握する</p>\n<p>e.g. </p>\n<p>まず，床が綺麗でないことを把握</p>\n<p>こぼした食べ物を踏んで他の人の靴が汚くなったのだろうと考える</p>\n<p>↑上記状況を踏まえて，モップをかける意図が生まれる</p>\n<p>人間のような日々の状況を認識する能力を獲得するには，multi-hopなreasoning moduleが必要になる（上の例みたいな形</p>\n<h2>引用</h2>\n<blockquote>\n</blockquote>","Title":"【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","Date":"2023-05-21","Category":"論文","Tags":["survey","NLP","knowledge-base","PLMKE","commonsense","encyclopedic","Knowledge-Intensive NLP"],"Authos":"ゆうぼう","Slug":"A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models","Thumbnail":"/images/thumbnails/A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models.png","Description":"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ","Published":true}],"tag":"knowledge-base","categories":["論文","Web","JavaScript","Competition","Cloud","Python","Linux","ML","Go","SQL"],"tags":["Apache","Appium","ASR","atmaCup","AWS","brew","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","Contrastive Learning","CSS","Demo","Dialogue Structure Learning","dialogue system","DST","Emotion Recognition","empathetic dialogue system","encyclopedic","Error Correction","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Intent Classification","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","LLM","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","Merging Models","ML","Model Editing","Model Patching","MT","Multi-Hop Transformer","multi-modal","MySQL","NLG","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","SLU","Speech Disfluency","subprocess","Super-Resolution","survey","tensorflow","Tkinter","Transfer Learning","transformer","Weight Interpolation","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","聞き手反応","超解像"],"pages":1,"page":1},"__N_SSG":true}