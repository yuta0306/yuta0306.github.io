{"pageProps":{"TaggedPostData":[{"contentHtml":"<p>※諸注意</p>\n<blockquote>\n<p>cf. @solafune(<a href=\"https://solafune.com\">https://solafune.com</a>) コンテストの参加以外を目的とした利用及び商用利用は禁止されています。商用利用・その他当コンテスト以外で利用したい場合はお問い合わせください。(<a href=\"https://solafune.com\">https://solafune.com</a>)</p>\n</blockquote>\n<p><a href=\"https://solafune.com/\">Solafune</a>というプラットフォームでのMScupで低解像度を超解像化する珍しいコンペが出てきて，楽しそうだと（実際楽しかったけど）2ヶ月従事したものの11位で終わってしまいました😭</p>\n<p>でも，学べることがたくさんあったし，画像系コンペに出てこなかったので，画像系でも活かせそうな知見が得られて楽しいコンペでした．</p>\n<p>実験してみて効いたこと効かなかったことや学んだことをまとめます．</p>\n<h2>結果報告</h2>\n<p>先に結果を報告してしまいます．</p>\n<p>タイトルですでに出オチですが，<strong>11位フィニッシュ</strong>でした🎉</p>\n<p>PublicもPrivateも共に11位だったので，Trust CV，Trust LBなコンペだったと思います．そのためとても取り組みやすかったです．</p>\n<p>また，ライセンス表記に対してシビアではありましたが，運営さんの方から使っていいライセンスが詳しく話されていたので，これに関しても取り組みやすかったと思っています．</p>\n<p>結果で見れば悔しい結果ですが，総評してとても楽しかったです🤗</p>\n<h2>コンペ概要</h2>\n<p>概要は以下です．</p>\n<blockquote>\n<p>衛星画像を活用する際の課題の一つに「解像度」の問題があります。人工衛星は広域を撮影できる一方で、解像度の低さがボトルネックになります。近年、解像度が高い衛星画像の提供・販売が始まっていますが、利用可能な高解像データは世界で最も解像度が高い画像でも30cm程度です。また、高解像度のデータは値段が高く、利用規約にも様々な制限が課せられています。さらに、現時点では高解像度の画像データは法律で利用を禁止している国もあります。 そのため、今回のコンテストでは高解像度のデータを安く利用するための手段として、超解像を扱います。将来的に高解像度の衛星画像を扱えるようになることを想定して、本コンテストでは25 cm解像度の画像データを扱います。「超解像」という技術を通して、衛星データや航空写真などの地理空間データの社会実装が加速することを期待しています。</p>\n</blockquote>\n<p>与えられて低解像度の画像に対して，高解像化をかけるモデル，アルゴリズムを作成し，SSIMが高くすることが課題でした．</p>\n<p>SSIMは以下で表され，これを最大化することを目的とします．</p>\n<p>$$\nSSIM(x, y) = \\frac{(2\\mu_x\\mu_y + c_1)(2\\sigma_{xy} + c_2)}{(\\mu_x^2 + \\mu_y^2 + c_1)(\\sigma_x^2 + \\sigma_y^2 + c_2)}\n$$</p>\n<h2>My Solution</h2>\n<p>僕のSolutionは大したことができませんでした．というのも，たくさんの実験を試したのですが，ほとんどうまくいかず悪化し，結局Seed Averagingなどの手抜きアイデアが最終サブになってしまったからです．</p>\n<p>とは言いつつも，おそらく僕独自の手法も入っているのではないかと思うので参考になればと思います．</p>\n<h3>モデル概要</h3>\n<p>訓練時は以下のようなモデル設計になっています．</p>\n<p><img src=\"/images/article/mscup/mscup_train.jpeg\" alt=\"訓練時モデル\"></p>\n<p>推論時は<strong>Seed Averaging</strong>と**TTA（Test Time Augmentation）**を利用して，テストデータでの推論時にロバストに推論ができるようにしました．Seed Averagingは5つくらいのモデルの平均をとったはずです．</p>\n<p>Seed AveragingやTTAは正直つまらない解法だと思っていますが，<strong>Sobel Filterを利用したLoss関数</strong>や<strong>CutMixやCutout</strong>などのData Augmentationが個人的な解法のウリではあります．</p>\n<p>また，僕がコンペを進める中での一番力を入れたことは，<strong>Loss関数による精度向上</strong>です．モデルも比較しましたが，結局SOTAモデルのSwinIRが圧巻で，Augmentationも思ったほど効かなかったので，Loss関数で制御することが最もの試みでした．これは独自の取り組みだと思っています（思いたい）</p>\n<p><a href=\"#%E5%AE%9F%E9%A8%93%E4%B8%AD%E3%81%AE%E8%AA%B2%E9%A1%8C%E6%84%9F%E3%81%A8%E5%B7%A5%E5%A4%AB\">次のセクション</a>で，なぜその実装をしたかと結果を話したいと思います．</p>\n<h3>実験中の課題感と対処法</h3>\n<p>実験している中での課題をまずは簡単に．</p>\n<ol>\n<li><a href=\"#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88%E3%81%8C%E5%B0%91%E3%81%AA%E3%81%84\">データセットが少ない</a>\n<ul>\n<li>画像が大きいので，クロップすればデータはたくさんあるのですが，多様性という面では多いとは言えなかったかもしれない．</li>\n</ul>\n</li>\n<li><strong>回転のAugmentationを加えるとノイズになる</strong>\n<ul>\n<li>エッジの再現性が重要となる超解像タスクでは，回転後のギザギザがノイズになってしまう．</li>\n<li>初めて知ったけど， 超解像タスクでは90度単位での回転が基本動作．画像見比べてなるほどってなった．</li>\n</ul>\n</li>\n<li><strong>超解像時にエイリアシングが起きたとき，エッジの向きに再現性がない</strong>\n<ul>\n<li>データを見ていてこれが問題と感じて，Sobel Filterを施そうと...</li>\n<li>細くは改めて話します．</li>\n</ul>\n</li>\n<li>Augmentationなんでもいいと思いきや，CutBlurやMixupはノイズだった\n<ul>\n<li>実装の苦労の割に大幅悪化で辛かった...</li>\n</ul>\n</li>\n</ol>\n<p>それでは上記について，細かく述べていこうと思います．</p>\n<h4>データセットが少ない</h4>\n<p>訓練データは60シーンあり，クロップすればデータは多く感じるものの，やはり多様性という時点では少ないなぁという印象でした．</p>\n<p>上位者の公開Solutionでは外部データの利用が鍵になったという指摘もあり，ここの調べを怠ったのが大敗につながってしまったのかなとも思っています．</p>\n<p>そうは言っても全く対処しなかったわけではなく，「<a href=\"https://arxiv.org/abs/2004.00448\">Rethinking Data Augmentation for Image Super-resolution: A Comprehensive Analysis and a New Strategy</a>」で提案されたData Augmentationの手法をPytorchパイプラインに合うように再実装し，実験はしました．</p>\n<p>効き目は以下のような感じでした．</p>\n<table>\n<thead>\n<tr>\n<th>手法</th>\n<th>説明</th>\n<th align=\"center\">効き目</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CutBlur</td>\n<td>低解像度に高解像度の画像を部分的に差し込む（またはその逆）</td>\n<td align=\"center\">×</td>\n</tr>\n<tr>\n<td>Cutout</td>\n<td>一定確率でピクセル値を0にする</td>\n<td align=\"center\">△</td>\n</tr>\n<tr>\n<td>CutMix</td>\n<td>異なる画像を部分的に差し込む</td>\n<td align=\"center\">○</td>\n</tr>\n<tr>\n<td>Mixup</td>\n<td>beta分布に従って異なる画像を混合する</td>\n<td align=\"center\">×</td>\n</tr>\n<tr>\n<td>CutMixup</td>\n<td>CutMixとCutupを同時に行う</td>\n<td align=\"center\">×</td>\n</tr>\n<tr>\n<td>Blend</td>\n<td>一様分布に従ってサンプリングされた色を混合する</td>\n<td align=\"center\">△</td>\n</tr>\n<tr>\n<td>RGBPermutation</td>\n<td>RGBの順番を変える</td>\n<td align=\"center\">△</td>\n</tr>\n</tbody>\n</table>\n<p>実際に効いているかはそこまで詳しく見ることはできていませんが，スコアや生成された高解像度画像を見ているとこんな感じだったと思います．</p>\n<p>効き目の詳細は改めて話します．</p>\n<h4>回転のAugmentationを加えるとノイズになる</h4>\n<p>これは最初気づかなくて，エッジがめちゃくちゃ鈍った画像が生成されたので分析した結果わかったことです．</p>\n<p>画像ドメインを持っている人ならば当たり前に感じてしまうかもしれませんが，画像にドメインのない人にとっては最後まで気づかなくてもおかしくなかったと思っています．</p>\n<p>ライブラリの仕様でも，回転を加える関数には，<em>interpolation</em>などのデータ補間のための引数があるはずです．</p>\n<p>例えば<em>torchvision</em>ですが，ランダムでの回転は以下で実装されます．</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> torchvision.transforms <span class=\"hljs-keyword\">as</span> T\n\n<span class=\"hljs-comment\"># ニアレストネイバーでの補間</span>\ntransforms = T.RandomRotation(degrees=<span class=\"hljs-number\">180</span>, interpolation=T.InterpolationMode.NEAREST)\n<span class=\"hljs-comment\"># バイリニアでの補間</span>\ntransforms = T.RandomRotation(degrees=<span class=\"hljs-number\">180</span>, interpolation=T.InterpolationMode.BILINEAR)\n</code></pre>\n<p>この実装を見る限りでも，エッジの部分が補間されることで元の入力画像との再現が取れなくなってしまうことは想像できると思います．</p>\n<p>これは学びでしたが，超解像タスクにおいては，<strong>回転のAugmentationは90度単位</strong>というのが主流のようでした．</p>\n<h4>超解像時にエイリアシングが起きたとき，エッジの向きに再現性がない</h4>\n<p>本当は画像を見せた方が早いのですが，今回のコンペで使用された画像は公開できないので，手書きで頑張って表現しようと思います．</p>\n<p>田んぼみたいに，ある程度イネを植えている方向に規則的な向きがあるような感覚を想像してください．</p>\n<p>実験中下のような画像が生成されてしまいました．</p>\n<p><img src=\"/images/article/mscup/edge.png\" alt=\"エッジが再現できない生成画像\"></p>\n<p>SSIMを最適化するのですが，<a href=\"https://kornia.readthedocs.io/en/latest/index.html\">kornia</a>で実装されていた<em>SSIM Loss</em>では，入力画像をGaussian Filterで平滑化してからSSIMの計算をかけていたので，ぼやけた状態でうまくreconstructできるかを学習してしまっていたのだと思います．</p>\n<p>そこで僕は追加で<em>Smooth L1 Loss</em>をさらに追加しました．こちらはピクセルごとでロスが計算されるので細かいところまで再現できるかなと思ったのですが，MSEなどのピクセルを見るLoss関数は画像全体がぼやけてしまうらしいです．</p>\n<p>結果行き着いた発想が，「<strong>エッジに対してLossを計算してしまえばいいじゃない？？</strong>」でした．</p>\n<p>これは結果的にスコア微増に起因したのですが，前に示した図のようなエイリアシングが取れていることが多く，実装と結果が直感的だったので最後まで採用しました．数学的に正しい感じは全くありませんが，なんかうまくいったので（正しいかは知りません．こいつほんまに微分可能なんか？ってお気持ちのままやってました笑）</p>\n<p>実装上は，Sobel Filterをかけて，エッジ抽出された画像に対してSmooth L1 Lossを計算するように計算しました．</p>\n<p>当時の実装を下記に載っけておきます．</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title hljs-class\">MeanSobelError</span>(nn.Module):\n   <span class=\"hljs-string\">\"\"\"\n   Sobel Gradient Loss Function\n   \"\"\"</span>\n   <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__init__</span>(<span class=\"hljs-params\">self,\n      normalized: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">True</span>,\n      eps: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">1e-6</span>,\n      reduction: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-string\">'mean'</span>,\n   </span>):\n      <span class=\"hljs-built_in\">super</span>(MeanSobelError, self).__init__()\n      self.<span class=\"hljs-built_in\">filter</span> = kornia.filters.Sobel(\n         normalized=normalized,\n         eps=eps,\n      )\n      self.lossfn = nn.SmoothL1Loss(reduction=reduction)\n\n   <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">forward</span>(<span class=\"hljs-params\">self,\n      y_pred: torch.Tensor,\n      y_true: torch.Tensor,\n   </span>):\n      filtered_pred = self.<span class=\"hljs-built_in\">filter</span>(y_pred)\n      filtered_true = self.<span class=\"hljs-built_in\">filter</span>(y_true)\n\n      loss = self.lossfn(filtered_pred, filtered_true)\n      <span class=\"hljs-keyword\">return</span> loss\n</code></pre>\n<h4>Augmentationなんでもいいと思いきや，CutBlurやMixupはノイズだった</h4>\n<p>SISRタスクにおいて提案されていたAugmentationは全部効くだろう！というスタンスで，<strong>コンペ終盤に時間をめちゃくちゃかけて実装</strong>し，全部ごちゃ混ぜでやってみたのですが，スコアが激減....</p>\n<p>幾つかパターンを試しましたが，CutBlurやMixup系はスコアの悪化の原因だったっぽいです．</p>\n<ul>\n<li>Mixup\n<ul>\n<li>画像を割合で混合するので，エッジが鈍りがちになってしまいました．</li>\n<li>車や車線など，エッジがはっきりした画像生成が必要だったため，ノイズになってしまったのかもしれません．</li>\n</ul>\n</li>\n<li>CutBlur\n<ul>\n<li>こちらは単純にモデル作成が下手くそなのかも知れないです．</li>\n<li>SwinIRに入力する前に，ダウンサンプリング層を用意する必要がありました．</li>\n<li>↑これがうまく学習できず，生成される画像の色がおかしかったです．\n<ul>\n<li>一応ダウンサンプリング層のみのwarmupなども試したが，うまく適合できず，この実装はボツに...（めっちゃ時間かけたのに...）</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>こんな感じで効くAugmentationと効かないAugmentationがあったので，早い段階でこの実装と実験ができていれば，もっと豊かな実験ができたかなと反省しています．</p>\n<p>Augmentationはいずれコンペ中は確実に試すことになると思うので，早めに効くかどうか先にやっておくといいのかも（？）</p>\n<h2>まとめ</h2>\n<p>最後に今回のコンペで得た知見をまとめたいと思います．</p>\n<ul>\n<li>Augmentationはタスク依存．課題感を意識したり，早めに取り組んだ方がいいかも（？）</li>\n<li>データセットのやりくりはサボらない\n<ul>\n<li>外部データの調査とかEDAとか</li>\n</ul>\n</li>\n<li>スコアだけでなく，予測値も確認してみる\n<ul>\n<li>今回はラベル分布とかそういうのではないので，生成画像もしっかり確認するなど</li>\n<li>それを割としっかりやったのでSobel Filterに行き着いたと思っています．</li>\n</ul>\n</li>\n<li>論文とにかく読んでアイデアを得よう\n<ul>\n<li>めっちゃ読んで，実装して効かなかったアイデアが8割くらいだったけど，楽しかったです．</li>\n<li>今，大学で取り組んでいるNLPの研究にアイデアが入ったりしているので，やり切るって大事！</li>\n</ul>\n</li>\n<li><strong>楽しむ！！！</strong>\n<ul>\n<li>コンペは序盤と終盤がとても辛いです．\n<ul>\n<li>序盤：バグが取れない．公開のやつに勝てない．</li>\n<li>終盤：スコアが伸び悩む．</li>\n</ul>\n</li>\n<li>でも，やり切れば結果楽しい（MScupが楽しかった説に一票ですが😂）</li>\n<li>CVやLBをおかずに飯が食えるぞ？</li>\n</ul>\n</li>\n</ul>\n<p>僕が今回のMScupを通して学んだことはこんなところでしょうか．次もしSolafuneのコンペに参加することがあれば，しっかり賞金圏に入りたいと思います！</p>\n<p>最後に今回のコンペで使ったライブラリや実装したコードを載せて終わりにしたいと思います．</p>\n<p>つらつらと思うところを書きましたが，最後まで読んでいただきありがとうございます．意見やご指摘などがありましたら，Twitterなどでご連絡ください．</p>\n<h2>よく使ったライブラリなど</h2>\n<p>今回のコンペでよく使えたライブラリなどを載っけておきます．</p>\n<ul>\n<li><a href=\"https://kornia.readthedocs.io/en/latest/index.html\">kornia</a>\n<ul>\n<li>ssim lossやsobel filterなど，画像処理で手前実装が大変でかゆいところに手が届きました．今後も自分は使うことがありそうだと感じました．</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/JingyunLiang/SwinIR\">SwinIR</a>\n<ul>\n<li>SISRにおけるSOTAモデル．事前学習済みモデルが公開されており，重宝しました．一番強かった...</li>\n<li><a href=\"https://arxiv.org/abs/2108.10257\">paper</a></li>\n</ul>\n</li>\n<li><a href=\"https://huggingface.co/models?other=image-super-resolution\">image-super-resolution</a>\n<ul>\n<li>さまざまなSuper Resolutionタスクでのモデルの再現実装をされています．</li>\n<li>今回のコンペでは精度が微妙だったのでサブには使いませんでしたが，SISRタスクで遊びたい時に簡単に扱えると思います．</li>\n</ul>\n</li>\n<li>Pytorch Lightning\n<ul>\n<li>単純にファン．もう楽</li>\n</ul>\n</li>\n<li>Pytorch</li>\n<li>cv2\n<ul>\n<li>RGBの順番気をつけましょう．これで2週間くらい無駄にしました笑笑</li>\n</ul>\n</li>\n</ul>\n<h2>実装したコード</h2>\n<p><a href=\"https://github.com/yuta0306/SRAugmentation\">SRAugmentation</a>にて公開しています．</p>\n<p>初めてGitHubでスターをもらって喜んでいました（小並感</p>\n<p>CutBlurなど，Single Image Super ResolutionにおけるData Augmentationの手法を改めてPytorchのパイプラインに組み込めるように再実装したものです．</p>\n<p>こちらの論文で提案されています．<a href=\"https://arxiv.org/abs/2004.00448\">Rethinking Data Augmentation for Image Super-resolution: A Comprehensive Analysis and a New Strategy</a></p>","Title":"【🛰MScup】超解像コンペで11位だったけど，やったことまとめまくる","Date":"2022-02-13","Category":"Python","Tags":["データ分析","超解像","SISR","Super-Resolution","Pytorch"],"Authors":"ゆうぼう","Slug":"mscup-feedback","Thumbnail":"/images/thumbnails/mscup.jpg","Description":"MScupで低解像度を超解像化する珍しいコンペが出てきて，2ヶ月従事したけど11位で終わってしまいました．でも，学べることがたくさんあったし，画像系コンペに出てこなかったので，画像系でも活かせそうな知見が得られて楽しいコンペでした．実験してみて効いたこと効かなかったことや学んだことをまとめます．","Published":true},{"contentHtml":"<p>Transformersを使って入力テキストをtokenizeするときに，データセットのサイズが大きかったので，バッチ単位でエンコードしたかった時がありました．</p>\n<p>この時，collate_fnに対して複数の引数を与えたかった状況の時の対処法です．(日本語変か?)</p>\n<h2>やりたかったこと</h2>\n<p>DataLoaderを定義するときに，<code>collate_fn</code>のところで自作collate_fnを指定して，batch単位で流れてくるデータに対してエンコードすること．</p>\n<p>これがやりたいことになります．つまりこんな感じ</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title hljs-class\">MyDataset</span>(<span class=\"hljs-title hljs-class hljs-inherited\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=custom_collate_fn)  <span class=\"hljs-comment\"># &#x3C;--- ここで自作collate_fnを指定して制御</span>\n</code></pre>\n<h2>やってうまくいかなかったこと</h2>\n<p>先にやってうまくいかなかったことを共有しておきます．</p>\n<p>自分が使っているのが，<code>pytorch-lightning</code>なのでそのせいもあるかもしれません．なので，もしかしたら普通に素のPytorchならうまくいくかもしれません．</p>\n<p>教えてください🙏</p>\n<h3>lambda式で制御する (functools.partialを使う)</h3>\n<p>こんなことをしました．</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title hljs-class\">MyDataset</span>(<span class=\"hljs-title hljs-class hljs-inherited\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n        <span class=\"hljs-keyword\">return</span> text, label\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">custom_collate_fn</span>(<span class=\"hljs-params\">data, tokenizer, max_length</span>):\n    texts, labels = <span class=\"hljs-built_in\">zip</span>(*data)\n    texts = <span class=\"hljs-built_in\">list</span>(texts)\n    texts = tokenizer.batch_encode_plus(\n        texts,\n        padding=<span class=\"hljs-literal\">True</span>,\n        truncation=<span class=\"hljs-literal\">True</span>,\n        max_length=max_length,\n        return_tensors=<span class=\"hljs-string\">'pt'</span>,\n    )\n    labels = torch.LongTensor(labels)\n    <span class=\"hljs-keyword\">return</span> texts, labels\n\ntokenizer = AutoTokenizer.from_pretrained(...)\nmax_length = <span class=\"hljs-number\">256</span>\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=<span class=\"hljs-keyword\">lambda</span> data: custom_collate_fn(data, tokenizer, max_length))\n</code></pre>\n<p><code>pytorch-lightning</code>の仕様だとは思うのですが，<code>pickle</code>で圧縮するらしくそのタイミングでエラーを吐かれました．</p>\n<p>なぜだろう...有識者の方教えてください...</p>\n<h2>【解決策】 classで定義する</h2>\n<p>lambda式でダメだったので，もうクラスの内部に必要なものを保持させておこうということになりました．(僕の中では)</p>\n<p>次のコードのような感じで解決しました．</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title hljs-class\">MyDataset</span>(<span class=\"hljs-title hljs-class hljs-inherited\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n        <span class=\"hljs-keyword\">return</span> text, label\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title hljs-class\">CollateFn</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__init__</span>(<span class=\"hljs-params\">self, tokenizer, max_length: <span class=\"hljs-built_in\">int</span></span>) -> <span class=\"hljs-literal\">None</span>:\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        os.environ[<span class=\"hljs-string\">\"TOKENIZERS_PARALLELISM\"</span>] = <span class=\"hljs-string\">\"true\"</span>  <span class=\"hljs-comment\"># &#x3C;--- 多分これを明示的に指定しないと怒られます (true|false)</span>\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title hljs-function\">__call__</span>(<span class=\"hljs-params\">self, data</span>):\n        texts, labels = <span class=\"hljs-built_in\">zip</span>(*data)\n        texts = <span class=\"hljs-built_in\">list</span>(texts)\n        texts = self.tokenizer.batch_encode_plus(\n            texts,\n            padding=<span class=\"hljs-literal\">True</span>,\n            truncation=<span class=\"hljs-literal\">True</span>,\n            max_length=self.max_length,\n            return_tensors=<span class=\"hljs-string\">'pt'</span>,\n        )\n        labels = torch.LongTensor(labels)\n        <span class=\"hljs-keyword\">return</span> texts, labels\n\ntokenizer = AutoTokenizer.from_pretrained(...)\nmax_length = <span class=\"hljs-number\">256</span>\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=CollateFn(tokenizer, max_length))\n</code></pre>\n<h2>まとめ</h2>\n<p>素のPytorchで組めば問題なかったのかもしれませんが，<code>pytorch-lightning</code>を使っている方は同じ状況になるかもしれません．</p>\n<p>その時は，ぜひ参考にclassでcollate_fnで実装してみて解決の一助となれたら幸いです．</p>","Title":"collate_fnで複数の引数を取りたい!!","Date":"2021-12-24","Category":"Python","Tags":["ML","Python","Pytorch"],"Authors":"ゆうぼう","Slug":"pytorch-collate_fn-args","Thumbnail":"/images/thumbnails/pytorch-logo.jpg","Description":"Transformersを使って入力テキストをtokenizeするときに，データセットのサイズが大きかったので，バッチ単位でエンコードしたかった時がありました．この時，collate_fnに対して複数の引数を与えたかった状況の時の対処法です．(日本語変かも)","Published":true}],"tag":"Pytorch","categories":["Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","conda","CSS","ffmpeg","Flask","Go","Google Colaboratory","Heroku","HTML","JavaScript","JSON","Kaggle","Linux","Mac","make","map","MeCab","ML","MySQL","NLP","node.js","Pandas","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","SISR","subprocess","Super-Resolution","tensorflow","Tkinter","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"pages":1,"page":1},"__N_SSG":true}