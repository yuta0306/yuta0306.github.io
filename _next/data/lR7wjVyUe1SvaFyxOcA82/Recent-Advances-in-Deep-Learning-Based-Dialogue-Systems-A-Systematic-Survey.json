{"pageProps":{"postData":{"contentHtml":"<p>本記事において使用される図表は，原著論文内の図表を引用しています．</p>\n<p>また，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．</p>\n<h2>論文情報</h2>\n<p>タイトル: Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey</p>\n<p>研究会: arxiv</p>\n<p>年度: 2021</p>\n<p>キーワード: survey, dialogue system</p>\n<p>URL: <a href=\"https://arxiv.org/pdf/2105.04387.pdf\">https://arxiv.org/pdf/2105.04387.pdf</a></p>\n<p>データセット:</p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ry2fz8tn.png\" alt=\"\"></p>\n<h2>概要</h2>\n<p>対話システムに関するサーベイ論文</p>\n<p>対話システムはNLPタスクの一種</p>\n<p>研究の価値が高いNLPタスクを多く含むため，対話システムは複雑と言える．</p>\n<p>ここ最近で良い成果をあげているもののほとんどがDL</p>\n<p>メインは，モデルタイプとシステムタイプについて述べられる．</p>\n<p>システムタイプ</p>\n<p>タスク指向型</p>\n<p>オープンドメイン型</p>\n<h3>Keywords</h3>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/8575dpgt.png\" alt=\"\"></p>\n<h3>サーベイの主張の流れ</h3>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/hpk33ao6.png\" alt=\"\"></p>\n<h2>まとめ</h2>\n<h3>Introduction</h3>\n<p>対話システムはNLPにおいてホットな話題であり，産業においても需要が非常に高い．</p>\n<p>タスク指向型とオープンドメイン型の対話システムが存在する．</p>\n<p>昔ながらのタスク指向型は，Natural Language Understanding, Dialogue State Tracking, Policy Learning, Natural Language Generationの4つからなっていた</p>\n<p>⇒</p>\n<p>最近のSoTAモデルでは，E2Eのタスク指向型の対話システムが多い．</p>\n<p>オープンドメイン型</p>\n<ul>\n<li>generative systems\n<ul>\n<li>seq2seqなモデル</li>\n<li>ユーザのメッセージや対話履歴を返答系列にマッピングする(Trainingデータに存在しないであろうものも含む)</li>\n<li>柔軟でコンテクストを読んだ返答をするが，時々主張が一貫しない返答や鈍感で面白くない返答を返す．</li>\n</ul>\n</li>\n<li>retrieval-based systems (検索)\n<ul>\n<li>返答の集合の中から，すでに存在する適した返答を探す．</li>\n<li>表面上では良い返答をする．ただし，返答集合は有限集合なので，対話上のコンテクストに対しては関係性があまりみられないこともある．</li>\n</ul>\n</li>\n<li>ensemble systems\n<ul>\n<li>上記二つを含む</li>\n<li>Generatie systemsは検索システムをよくするために使われる．</li>\n<li>検索システムはより適した返答を選ぶために使われる．</li>\n</ul>\n</li>\n</ul>\n<p>古典的な対話システムとして，finite state-basedとstatistical learningとmachine learning-basedが挙げられる．</p>\n<ul>\n<li>Finite State-based\n<ul>\n<li>対話の流れはあらかじめ決められている</li>\n<li>決まったシナリオの中でしか対応ができない．</li>\n</ul>\n</li>\n<li>Statistical Learning-based\n<ul>\n<li>Finite State-basedよりは柔軟である．あらかじめ対応が決められていないから．</li>\n</ul>\n</li>\n<li>machine learning-based\n<ul>\n<li>Deep learningが主流？</li>\n</ul>\n</li>\n</ul>\n<p>NLPの中には対話システムに近い領域がある．</p>\n<ul>\n<li>Q &#x26; A</li>\n<li>reading comprehension</li>\n<li>dialogue disentanglement</li>\n<li>visual dialogue</li>\n<li>visual Q &#x26; A</li>\n<li>dialogue reasoning</li>\n<li>conversational semantic parsing</li>\n<li>dialogue relation extraction</li>\n<li>dialogue sentiment analysis</li>\n<li>hate speech detection</li>\n<li>MISC detection (???)</li>\n</ul>\n<h3>Neural Models in Dialogue Sustems</h3>\n<ul>\n<li>CNN\n<ul>\n<li>ここ数年NLPの分野での応用も多いらしい</li>\n<li>フレーズや文章，パラグラフには意味づけをするのに有用でCNNがヒラルキーなモデルになる</li>\n<li>CNNは一条に乏しいため，最近のSoTAにおいては，テキストをencoderにかけたのちにCNNを用いてヒエラルキーな特徴抽出を行っている．</li>\n<li>欠点として入力系列の長さは固定長のため以下の使用例\n<ul>\n<li>encoderの出力をCNNでベクトル化</li>\n<li>contextと返答の候補を行列にして，CNNで近さを図ることによって，妥当な候補を選び出す</li>\n</ul>\n</li>\n<li>基本的にCNNとencoderはセットか？</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/37cmjuij.png\" alt=\"\"></p>\n<ul>\n<li>RNN and Vanilla seq2seq\n<ul>\n<li>系列として扱えるのが利点と考えるべき</li>\n<li>HMMや古典的な系列モデルだと，推論時のアルゴリズムの複雑さや考えるべき状態空間の増大に合わせて行列サイズが大きくなりすぎて，大きな状態空間を必要とするデータには対応しがたい．</li>\n<li>マルコフモデルは限られた条件下においては強力なモデルになりうる．</li>\n<li>RNNは最近では提案されないが，NLPタスクにおいては未だ現役として活躍することもある</li>\n<li>Jordan-Type &#x26; Elman-Type RNN</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ts6afg6g.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-graphql\">\t- Jordan-<span class=\"hljs-keyword\">Type</span> RNN\n</code></pre>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/mz0mr5oj.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">\t\t-</span> 最新の隠れ層の状態は，Input<span class=\"hljs-emphasis\">_tとOutput_</span>t-1による\n<span class=\"hljs-code\">\t\t\t\n</span>\n<span class=\"hljs-bullet\">\t-</span> Elman-Type RNN\n</code></pre>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/10bbby3m.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">\t\t-</span> 最新の隠れ層の状態は，Input<span class=\"hljs-emphasis\">_tとHidden_</span>t-1による\n<span class=\"hljs-bullet\">\t-</span> いずれにしてもシンプルなRNNは勾配消失か勾配爆発が大抵おこる\n<span class=\"hljs-code\">\t\n</span>\n<span class=\"hljs-bullet\">-</span> LSTM\n</code></pre>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/k21pyf3t.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">\t-</span> Gates\n<span class=\"hljs-bullet\">\t\t-</span> 入力ゲート\n<span class=\"hljs-bullet\">\t\t-</span> 忘却ゲート\n<span class=\"hljs-bullet\">\t\t-</span> 出力ゲート\n\n\n<span class=\"hljs-bullet\">-</span> GRU; Gated Recurrent Unit\n</code></pre>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/fs4fug4f.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">\t-</span> Gates\n<span class=\"hljs-bullet\">\t\t-</span> 更新ゲート\n<span class=\"hljs-bullet\">\t\t-</span> リセットゲート\n<span class=\"hljs-bullet\">\t-</span> パラメータが少ないため，\n<span class=\"hljs-bullet\">\t\t-</span> 早い\n<span class=\"hljs-bullet\">\t\t-</span> 汎化性がみられる\n<span class=\"hljs-bullet\">\t-</span> ただし，\n<span class=\"hljs-bullet\">\t\t-</span> 大きなデータセットには対応しきれないこともある\n<span class=\"hljs-code\">\t\t\n</span>\n<span class=\"hljs-bullet\">-</span> Bi-directional RNN\n</code></pre>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/vrdvputk.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">\t-</span> 双方向を考慮したRNN\n<span class=\"hljs-code\">\t\t\n</span>\n<span class=\"hljs-bullet\">-</span> seq2seq; Encoder-Decoder model\n<span class=\"hljs-bullet\">\t-</span> 初めは機械翻訳のために提案された手法\n<span class=\"hljs-bullet\">\t-</span> Encoderにより入力系列をベクトル化，その隠れ状態をDecodeして生成することを目指す\n</code></pre>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/56q5hqna.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">\t-</span> Encode時\n<span class=\"hljs-bullet\">\t\t-</span> t時刻のinputとt-1時刻のhiddenによって，t時刻のhiddenが決まる\n<span class=\"hljs-bullet\">\t-</span> Decode時\n<span class=\"hljs-bullet\">\t\t-</span> t時刻のhiddenとt-1時刻のoutputによって，t時刻のoutputをデコードする\n<span class=\"hljs-bullet\">\t-</span> 入力系列と出力系列の長さが固定長である必要はない．\n<span class=\"hljs-bullet\">\t\t-</span> その代わり，適応させる系列長と出力される系列長は同じになることは保証されない\n</code></pre>\n<ul>\n<li>Hierarchical Recurrent Encoder-Decoder; HRED</li>\n</ul>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/4s0olxfm.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-diff\"><span class=\"hljs-deletion\">- コンテクストを理解するためのseq2seqモデル</span>\n<span class=\"hljs-deletion\">- クエリの履歴を理解する？</span>\n<span class=\"hljs-deletion\">- トークンレベルとターンレベルで学習する</span>\n</code></pre>\n<ul>\n<li>Memory Networks</li>\n<li>Attention and Transformer\n<ul>\n<li>Attention</li>\n<li>Transformer\n<ul>\n<li>Muti-head Attention</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Pointer Net and CopyNet\n<ul>\n<li>Pointer Net</li>\n<li>CopyNet</li>\n</ul>\n</li>\n<li>Deep RL and GANs\n<ul>\n<li>Deep Q-Networks</li>\n<li>REINFORCE</li>\n<li>GANs</li>\n</ul>\n</li>\n<li>Knowledge Graph Augmented Neural Networks</li>\n</ul>\n<p>2章は途中から読むのやめた．使用されるネットワークよりも課題感の方が知りたい．</p>\n<h3>タスク指向型対話システム</h3>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/y29vzu3h.png\" alt=\"\"></p>\n<p>ドメインの決まったタスクにおいて特定の問題を解決する．</p>\n<ul>\n<li>Natural Language Understanding</li>\n</ul>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/1mx5wsm3.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">-</span> 3つのタスクを持つ\n<span class=\"hljs-bullet\">\t-</span> ドメイン分類\n<span class=\"hljs-bullet\">\t-</span> 意図の理解\n<span class=\"hljs-bullet\">\t-</span> スロット埋め\n<span class=\"hljs-bullet\">-</span> IOB; Inside Outside Beginning\n<span class=\"hljs-bullet\">-</span> NER; Named Entity Recognition\n<span class=\"hljs-bullet\">-</span> intent detectionにおいては，Task-Oriented Dialogue BERTがSoTA?\n<span class=\"hljs-bullet\">-</span> Domain classification &#x26; intent detectionは同カテゴリタスク\n\n\n<span class=\"hljs-bullet\">-</span> slot filling task = semantic tagging\n<span class=\"hljs-bullet\">-</span> NLUタスクを解く際に，音声データをそのままInputとして与える研究事例も出ているらしい\n<span class=\"hljs-bullet\">\t-</span> エラーが少なくロバストなモデルになったらしい？\n<span class=\"hljs-bullet\">-</span> Natural Language UnderstandingとNatural Language Generationは逆のプロセスをふむ\n<span class=\"hljs-bullet\">\t-</span> 同時にタスクを学習結果が得られるというアプローチも\n</code></pre>\n<ul>\n<li>Dialogue State Tracking</li>\n</ul>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/aao7x0r4.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">-</span> ユーザの目的と対話履歴を追跡する\n<span class=\"hljs-bullet\">-</span> NLUとDSTのタスクは近い関係にある．\n<span class=\"hljs-bullet\">-</span> NLUは単語にtagを割り振っていくイメージ\n<span class=\"hljs-bullet\">-</span> DSTはtagのplaceholderを会話の内容から埋めていくイメージ\n<span class=\"hljs-bullet\">-</span> Dialogue Stateには3つの要素からなる\n<span class=\"hljs-bullet\">\t-</span> Goal constraint corresponding with informable slots\n<span class=\"hljs-bullet\">\t\t-</span> 特別なvalueの制約で，ユーザによって言及されるか特別な値をとる\n<span class=\"hljs-bullet\">\t\t-</span> DontcareやNoneが特別な値にあたる\n<span class=\"hljs-bullet\">\t-</span> Requested slots\n<span class=\"hljs-bullet\">\t-</span> Search method of current turn\n<span class=\"hljs-bullet\">-</span> 古典的な手法でいくと，\n<span class=\"hljs-bullet\">\t-</span> ルールベースはエラーが多く，ドメイン適応が大変\n<span class=\"hljs-bullet\">\t-</span> 統計的手法はノイジーな状態や曖昧性に弱い\n<span class=\"hljs-bullet\">-</span> ニューラルネットな手法\n<span class=\"hljs-bullet\">\t-</span> slot-valueのペアを事前定義して学習\n<span class=\"hljs-bullet\">\t\t-</span> valueが大きくなると複雑性が増す\n<span class=\"hljs-bullet\">\t\t-</span> slot-valueのペアを読むだけでよく，2値分類タスクとして解ける\n<span class=\"hljs-bullet\">\t\t-</span> モデルの複雑性は避けられるが，反応速度が遅くなる可能性がある．\n<span class=\"hljs-bullet\">\t-</span> slot-valueのペアを定義せずに，対話の中から直接選ぶ\n</code></pre>\n<ul>\n<li>\n<p>Policy Learning</p>\n<ul>\n<li>DSTモジュールの出力結果からどう行動をとるか</li>\n<li>教師あり学習or 強化学習</li>\n<li>教師ありだとアノテショーンデータセットを作るのがとても大変</li>\n</ul>\n</li>\n<li>\n<p>Natural Language Generation; NLG</p>\n<ul>\n<li>タスク指向型対話システムにおける最終層のモジュール</li>\n<li>最終的な自然言語表現を生成するシステム</li>\n<li>4つのコンポーネントからなる</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/9ybi8yfr.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">\t-</span> Content Determination\n<span class=\"hljs-bullet\">\t-</span> Sentence Planning\n<span class=\"hljs-bullet\">\t-</span> Surface Realization\n<span class=\"hljs-bullet\">\t-</span> Lexicalization, Referring expression, aggregation\n<span class=\"hljs-bullet\">-</span> RNNに基づいた統計言語モデルにおいて，意味的制約や文法構造による返答生成を行うなど\n<span class=\"hljs-bullet\">-</span> コンテクストを理解した返答を生成することは重要である\n<span class=\"hljs-bullet\">-</span> タスク指向型においては，返答の多様性というよりも信頼性のほうが重要視されがち\n<span class=\"hljs-bullet\">-</span> 意味解析をビームサーチを使うことで，意味の正しさを改善する手法も提案された\n</code></pre>\n<ul>\n<li>E2E Methods\n<ul>\n<li>\n<p>end-to-endのパイプラインを組むことで高いパフォーマンスを発揮することがあるが，</p>\n</li>\n<li>\n<p>多くのモジュールを組み込むため，バックプロパゲーションで誤差が伝播しないこともある．</p>\n</li>\n<li>\n<p>すべてのモジュールが，返答の精度を向上するために，対等に重要であるとは限らない．</p>\n</li>\n<li>\n<p>違うドメインに差し替えるとき，オントロジーを事前学習させる必要があるため，困難が生じることもある</p>\n</li>\n<li>\n<p>やり方は大きく分けて2つ</p>\n<ul>\n<li>すべてのモジュールを展開して誤差逆伝播させる？</li>\n<li>知識ベースの検索システムと返答生成の双方を用いてパイプラインを組む</li>\n</ul>\n</li>\n<li>\n<p>タスク指向型においては，外部の知識源が必要なことが多い</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>オープンドメイン型対話システム</h3>\n<ul>\n<li>雑談対話システム，或いはタスク思考型ではない対話システムのこと</li>\n<li>SoTAを示しているオープンドメインは大抵ニューラルネットで解決している</li>\n<li>完全なるデータドリブンなものが多い</li>\n<li>オープンドメイン型対話システムは，大まか3つに分けられる\n<ul>\n<li>生成システム</li>\n<li>検索ベースシステム</li>\n<li>アンサンブルシステム</li>\n</ul>\n</li>\n</ul>\n<p>３つの話が以下</p>\n<ul>\n<li>生成システム\n<ul>\n<li>訓練コーパスに出てこないような返答に対して，ユーザのメッセージや対話履歴をマッピングするために，seq2seqなモデルを適用する</li>\n</ul>\n</li>\n<li>検索システム\n<ul>\n<li>決まった返答集合の中からすでに存在する返答を探そうとする</li>\n</ul>\n</li>\n<li>アンサンブルシステム\n<ul>\n<li>生成手法と検索手法を合わせる．</li>\n<li>生成された返答と検索された返答とを比べる．</li>\n<li>生成も，検索された返答を洗練するために用いられる．</li>\n</ul>\n</li>\n</ul>\n<p>特徴として，</p>\n<p>生成モデルは</p>\n<p>柔軟でコンテクストを読んだ返答をできるが，ときには理解に欠けていたり，怠けた返答を見せることがある</p>\n<p>検索ベースのモデルは</p>\n<p>人の返答の集合から実際の返答を選ぶため，返答の集合は有限集合であり，コンテクストと相関がないことがある．</p>\n<p>ただし，表面上のレベルでは，首尾一貫した返答することも多い</p>\n<p>以下は，オープンドメイン型対話システムにおける，難しさとホットなトピックをまとめる</p>\n<ul>\n<li>Context Awareness\n<ul>\n<li>対話コンテクストは会話のトピックを決定したり，ユーザの目標を決定したりと重要</li>\n<li>コンテクストを解釈した対話エージェントは，現メッセージだけではなく，対話履歴からももとにして返答する</li>\n<li>生成モデルも検索ベースも，どちらも対話コンテクストモデリングに依存する</li>\n<li>いくつかのモデルではAttentionが使用されているらしい</li>\n<li>構造化されたAttentionを用いることでコンテクストを読み取れる？</li>\n<li>対話をリライトする問題があるらしい\n<ul>\n<li>複数のメッセージから単一のメッセージに変換する目標</li>\n<li>ここではコンテクストを理解させることが重要</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Response Coherence\n<ul>\n<li>首尾一貫した返答は，良い生成器としての一つのクオリティ</li>\n<li>対話の中で，論理的で首尾一貫しているか？という指標</li>\n<li><ins>生成モデルにおいてホットなトピックとなっている（検索ベースはすでに人の返答をりようするのでもともと一貫性はあるという主張）</ins></li>\n<li>一貫性のない文の順序を見つけるタスクを解くことで，返答の一貫性を改善した事例もあり</li>\n</ul>\n</li>\n<li>Response Diversity\n<ul>\n<li>人が多用するような表現は訓練コーパスにも多く含まれ，それらばかりを返答してしまうことが問題となりうる</li>\n<li>かつては条件付き確率において，尤度関数を解くことで尤もらしい返答をもとめていた．</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/00fwhths.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">\t-</span> この手法では，返答の精度の安全性と適切さはトレードオフになっていた？\n<span class=\"hljs-bullet\">-</span> ビームサーチを提案されたことも\n<span class=\"hljs-bullet\">-</span> \n</code></pre>\n<ul>\n<li>Speaker Consistency and Personality-based Response\n<ul>\n<li>システムは，訓練コーパスからサンプリングされた分布に対して学習\n<ul>\n<li>対話者の趣味といった一貫性のないものに対する返答は．．．</li>\n<li>対話者の役割を理解し，その個人に合わせた返答が必要になる</li>\n</ul>\n</li>\n<li>1ステージではなく，3ステージで個人的な嗜好に対応した事例がある</li>\n<li></li>\n</ul>\n</li>\n<li>Empathetic Response\n<ul>\n<li>同情する対話システムは，ユーザの感情の変化や感情に伴った適切な返答をする</li>\n<li>雑談チャットについて，このトピックは重要</li>\n<li>CortanaやAlexaなどの製品にもモジュールが含まれている</li>\n<li>CoBERTのモデルなど</li>\n<li>感情対話システムのデータセットはとぼしいが，新たなデータセットとベンチマークが提供されたらしい</li>\n<li></li>\n</ul>\n</li>\n<li>Conversation Topics\n<ul>\n<li>トピックや目的は，会話に参加した人と会話を続けるための重要な役割を果たす</li>\n<li>トピックを理解させることが重要</li>\n<li></li>\n</ul>\n</li>\n<li>Knowledge-Grounded System\n<ul>\n<li>人は，会話のコンテクストと経験や記憶といったものとを関連付けて，返答をする（機会には難しい）</li>\n<li>生成モデルは，単なる機械翻訳よりも複雑\n<ul>\n<li>より自由度が高く，制約が曖昧なため</li>\n</ul>\n</li>\n<li>故に，雑談チャットは，外部から得られる常識と結びつけて，seq2seqなモデルによって生成する</li>\n<li>メモリーネットワークなどで，知識をグラウンディングする手法</li>\n<li>知識グラフは外部の情報をソースにするものもある．</li>\n<li>graph attentionを用いて，常識をグラフベースで学習する手法も</li>\n<li>主な考え方は，外部の知識グラフを使って，会話の論理の流れをモデリングする指標の一部として扱う</li>\n</ul>\n</li>\n<li>Interactive Training\n<ul>\n<li>別名；human-in-loop training</li>\n<li>アノテーションされたデータセットは限られている\n<ul>\n<li>すべての状況をカバーすることは不可能</li>\n</ul>\n</li>\n<li>ユーザとの対話の中で，システムを改善する</li>\n<li>強化学習における逐次学習を提案</li>\n<li>対話相手と話して，その相手からフィードバックを得る</li>\n<li>教師あり学習をした後，Interactive Trainingによってファインチューニングする</li>\n<li></li>\n</ul>\n</li>\n<li>Visual Dialogue</li>\n</ul>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/v3baquyk.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-markdown\"><span class=\"hljs-bullet\">-</span> Visual Q &#x26; Aなど\n<span class=\"hljs-bullet\">-</span> 画像あり対話システムのほか，映像あり対話システムも面白いトピックだが難題でもある\n<span class=\"hljs-bullet\">\t-</span> 特徴量抽出の複雑さも増す\n<span class=\"hljs-bullet\">-</span> visual dialogueのアノテーションは重労働であり，データセットに乏しいので，現在はデータの不十分さに悩まされている\n<span class=\"hljs-bullet\">-</span> \n</code></pre>\n<h3>評価のアプローチ</h3>\n<p>評価の仕方も重要なパートとなっている</p>\n<ul>\n<li>タスク指向型対話システムにおける評価\n<ul>\n<li>BLEUスコアを用いて，システムの返答と人の返答を比べるなど</li>\n<li>Task Completion Rate\n<ul>\n<li>すべてのタスクの試行に対して，いくつのイベントが成功したかの割合</li>\n</ul>\n</li>\n<li>Task Completion Cost\n<ul>\n<li>タスクをこなすのに使われたリソース</li>\n<li>解決までの時間が重視されるタスクにおいて用いられる</li>\n<li>なるべく短いターン数で完遂するのが良しとされる</li>\n</ul>\n</li>\n<li>Human-based Evaluation\n<ul>\n<li>ユーザの対話とユーザの満足度のスコアを提供</li>\n<li>方法はふたつ\n<ul>\n<li>クラウドソーシングで労働を雇う</li>\n<li>実際にローンチしてからユーザのフィードバックで評価する</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>オープンドメイン型対話システムにおける評価\n<ul>\n<li>明確なメトリックはない</li>\n<li>長らくHuman Evaluationを使ってきた</li>\n<li>Word-overlap Metrics\n<ul>\n<li>生成された系列と実際の系列の近さを計算する</li>\n<li>機械翻訳や要約タスクにおいて用いられる</li>\n<li>n-gramのものとして\n<ul>\n<li>BLEU</li>\n<li>ROUGE</li>\n<li>METEOR(BLUEの改良版)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Neural Metrics\n<ul>\n<li>ニューラルモデルによって計算させる</li>\n<li>RNNやCNN,GANの識別器を使うなどして，ターンレベルの特徴量抽出を行うなど</li>\n</ul>\n</li>\n<li>今もホットなトピックになっている</li>\n</ul>\n</li>\n</ul>\n<h3>データセット</h3>\n<p>タスク指向型対話システム</p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/4xcx432d.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/bvaa6edt.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/5nqvspiq.png\" alt=\"\"></p>\n<p>オープンドメイン型対話システム</p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ja1g5vzq.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ki5ab45o.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/ikzadi1i.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/nuxspw6o.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey/1u3frgui.png\" alt=\"\"></p>\n<h3>結論とトレンド</h3>\n<p>ココ最近のトレンド</p>\n<ul>\n<li>Mutlimodal dialogue systems\n<ul>\n<li>異なるモダリティを組み合わせる</li>\n</ul>\n</li>\n<li>Multitask dialogue systems\n<ul>\n<li>タスク指向型と知識グラウンディングさせたオープンドメイン型を組み合わせて，一つのフレームワークまたはシングルモデルとして完結させる</li>\n</ul>\n</li>\n<li>Corpus exploration on Internet\n<ul>\n<li>real-timeなコーパスをインターネットから取り出せるようになれば，期待がもてる</li>\n<li>研究に値するのでは？</li>\n</ul>\n</li>\n<li>User modeling\n<ul>\n<li>生成と評価の双方でホットなトピック</li>\n</ul>\n</li>\n<li>Dialogue generation with a long-term goal\n<ul>\n<li>日常的な雑談は特に目的はない</li>\n<li>しかし，会話が意図的にある特定の目的に向かうときは，ほんの少しでも状況があるはず</li>\n<li>現在のオープンドメイン型は，長期的な目的を除いてモデリングされがち\n<ul>\n<li>十分な知性を備えていない</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2>引用</h2>\n<blockquote>\n</blockquote>","Title":"【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey","Date":"2023-05-22","Category":"論文","Tags":["survey","dialogue system"],"Authos":"ゆうぼう","Slug":"Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey","Thumbnail":"/images/thumbnails/Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey.png","Description":"Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Surveyのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Python","Linux","ML","Go","SQL"],"tags":["Apache","Appium","ASR","atmaCup","AWS","brew","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","Contrastive Learning","CSS","Demo","Dialogue Structure Learning","dialogue system","DST","Emotion Recognition","empathetic dialogue system","encyclopedic","Error Correction","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Intent Classification","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","LLM","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","Merging Models","ML","Model Editing","Model Patching","MT","Multi-Hop Transformer","multi-modal","MySQL","NLG","NLI","NLP","Node","node.js","npm","Overleaf","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","SLU","Speech Disfluency","subprocess","Super-Resolution","survey","tensorflow","Tkinter","Transfer Learning","transformer","Weight Interpolation","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","聞き手反応","論文執筆","超解像"]},"__N_SSG":true}