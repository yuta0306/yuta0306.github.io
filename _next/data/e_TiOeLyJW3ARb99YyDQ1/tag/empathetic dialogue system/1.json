{"pageProps":{"TaggedPostData":[{"contentHtml":"<p>本記事において使用される図表は，原著論文内の図表を引用しています．</p>\n<p>また，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．</p>\n<h2>論文情報</h2>\n<p>タイトル: A survey on empathetic dialogue systems</p>\n<p>研究会: Information Fusion 64</p>\n<p>年度: 2020</p>\n<p>キーワード: survey, dialogue system, empathetic dialogue system</p>\n<p>URL: <a href=\"https://sentic.net/empathetic-dialogue-systems.pdf\">https://sentic.net/empathetic-dialogue-systems.pdf</a></p>\n<p>DOI: <a href=\"https://doi.org/10.1016/j.inffus.2020.06.011\">https://doi.org/10.1016/j.inffus.2020.06.011</a></p>\n<p>データセット:</p>\n<p><strong>Keywords</strong>:</p>\n<p>Artificial Intelligence,</p>\n<p>Affective computing,</p>\n<p>Dialogue system</p>\n<p>共感的対話システム構築の最終目的</p>\n<p>→ユーザの疑問や悩みに応えること</p>\n<p>どのような機能が対話システムの共感的な振る舞いを可能にしたのかという，機能の観点から対話システムのユニークな側面に注目する．</p>\n<p>Personalization：　システムの一貫性と整合性を高める働き．</p>\n<p>→ユーザ固有の情報</p>\n<p>emotion，personalization，knowledge の3要素が重要</p>\n<p>Empathetic Dialogue System</p>\n<p>感情の状態の感受や表現，個人的な嗜好，知識を強化する</p>\n<p>3つの重要な特徴について</p>\n<ol>\n<li>emotional-awareness</li>\n<li>Personality-awareness</li>\n<li>Knowledge-accessibility</li>\n</ol>\n<p><img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/jj8cey5y.png\" alt=\"\"></p>\n<p>3つのサブトピックを扱う</p>\n<ol>\n<li>Perceiving and expressing emotion</li>\n<li>Caring each individual</li>\n<li>Casting into knowledge</li>\n</ol>\n<p>過去10年ぶんほどをカバー</p>\n<h2>Propaedeutic background</h2>\n<p>backboneとして使われているアーキテクチャの紹介</p>\n<ul>\n<li>\n<p>Neural language model\n1. RNN (LSTM, GRUなど)\n<img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/ab1tzbka.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-css\">  \t<span class=\"hljs-number\">2</span>. Sequence-<span class=\"hljs-selector-tag\">to</span>-sequence model\n</code></pre>\n</li>\n</ul>\n<p><img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/vxnsfxcb.png\" alt=\"\"></p>\n<p><img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/j79vo4ch.png\" alt=\"\"></p>\n<ol>\n<li>\n<p>RNN</p>\n<ol>\n<li>\n<p>long short-term memory, LSTM\n入力・忘却・出力の3つのゲート</p>\n</li>\n<li>\n<p>gated recurrent unit, GRU\ngated関数は通常シグモイド関数．勾配のスケールを制限し，複数回の時間ステップの後に爆発するようにする．</p>\n</li>\n</ol>\n</li>\n<li>\n<p>Seq2Seq\nmodualizedなシステムは，通常以下の4パートからなる：</p>\n</li>\n<li>\n<p>Natural Language Understanding, NLU\n入力から構造情報を抽出する</p>\n</li>\n<li>\n<p>a Dialogue State Tracker, DST</p>\n</li>\n<li>\n<p>a Dialogue Polich, DP</p>\n</li>\n<li>\n<p>a response generator\n先行モジュールすべての出力に基づいた応答を生成する．</p>\n<p>別名，エンコーダ・デコーダモデル．</p>\n<p>条件付き対話生成のモデル化にはおそらく最も広く使われているニューラルアーキテクチャ．</p>\n<p>エンコーダ，デコーダはそれぞれ，通常RNNをベースとしている．</p>\n</li>\n</ol>\n<ul>\n<li>Attention mechanism</li>\n</ul>\n<p><img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/ccvc5cuj.png\" alt=\"\"></p>\n<pre><code class=\"hljs\">エンコーダが符号化できる最大ワード数の制限．入力単語数が大きくなると適切に符号化できない．\n</code></pre>\n<p>→デコーダが文脈の最も関連性の高い位置にアクセスすることが，この問題に効果的</p>\n<pre><code class=\"hljs\">RNNやseq2seqなどの，入力単語数の限界に対して対処できると，RNNやseq2seqでの問題の解消に一役買ったと紹介．\n</code></pre>\n<ul>\n<li>Memory networks; MMN</li>\n</ul>\n<p><img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/4dbq5m5d.png\" alt=\"\"></p>\n<pre><code class=\"hljs language-wasm\">RNNの隠れ空間ではメモリは時間と共に更新されるものであるが，このメモリは小さかったり離れすぎていたりする．対話のような，文脈を理解するために長期的な記憶が必要な分野では上手くいかないことも．\n\n内部に必要な情報を保持できないため，外部メモリの機能を実装したのがこのMMN\n\n外部の<span class=\"hljs-keyword\">memory</span> slotsに対して，attentionをかけてslotを更新するなどをする\n</code></pre>\n<ul>\n<li>VAE, Variational AutoEncoder\n条件付き確率分布に基づき，データ分布に近いように生成をする.</li>\n</ul>\n<p>通常のオートエンコーダ：</p>\n<p>　入力→エンコーダが潜在変数を生成→デコーダ→出力（入力に似たものを生成）</p>\n<p>VAE：</p>\n<p>　潜在変数がN(0,1)の確率分布に従うと仮定する．</p>\n<pre><code class=\"hljs language-scss\">条件付き<span class=\"hljs-built_in\">VAE</span>(CVAE)：条件付き確率分布 <span class=\"hljs-selector-tag\">P</span>(出力応答 | 入力)をモデル化する．\n</code></pre>\n<ul>\n<li>\n<p>GAN, Generative Adversarial Network\nGenerator G, Discriminator D　からなる．</p>\n<p>画像生成から伝達学習までさまざまなタスクで大きな成果をあげている．</p>\n<p>Generator vs Discriminator：</p>\n</li>\n</ul>\n<p>生成器（G）は分類誤差を最大にして識別器（D）を欺くように訓練され，Dは分類誤差を最小にするように訓練される．</p>\n<ul>\n<li>\n<p>RL, Reinforcement Learning（強化学習）\n以下のような一般的に用いられる目的関数は，対話システムの現実的な目標と明確な関連性を持っていない．</p>\n</li>\n<li>\n<p>尤度</p>\n</li>\n<li>\n<p>ELBO\nELBOを解く．</p>\n<p>対話における各タイミングでの学習のフィードバックは，単語ごとではなく，まとまった文章が生成されたのちに与えられる．このため遅延報酬関数を使用できる．</p>\n<p>論文の中でも，RLの重要性が何度も紹介されていた</p>\n</li>\n</ul>\n<h2>Affective dialogue system</h2>\n<p>感情は，反応と社会的行動で文化的な作用であり，これは人と環境の関係によって連続的に発展していくもの</p>\n<p>感情のカテゴライズは，心理学者と哲学者の間でせわしく，長らく議論されてきた</p>\n<p>感情は社会的な機能も持つ．そして情動は意思決定に関連する尺度である可能性が示唆されている．人間の会話行動のエミュレートだけでなく，システムとユーザとの感情的なつながりを強化することができる．</p>\n<p>本書における affective dialogue system</p>\n<ul>\n<li>perceiving emotion</li>\n<li>understanding emotion</li>\n<li>expressing and regulating emotion</li>\n</ul>\n<p>↓</p>\n<ol>\n<li>\n<p>emotion-awareness\n文脈の中の感情の表現に関係する，対話中のユーザの感情状態を検出できなければならない．</p>\n</li>\n<li>\n<p>emotion-expressiveness\n生成された応答に感情情報を取り入れることに関係する．</p>\n</li>\n</ol>\n<p>感情に関する理論は，感情の挿入がユーザとの感情の結びつきを強くするという利点をサポートしてくれる</p>\n<h3>Emotion analysis</h3>\n<p>一般的には，多くのcomputational modelは3つのカテゴリーに分けられる</p>\n<ol>\n<li>dimensional approach（次元的）</li>\n<li>discrete approach（離散的）</li>\n<li>appraisal approach（評価的）</li>\n</ol>\n<p>Dimensional approach</p>\n<p>感情をベクトル（[覚醒]と[静寂]を表すもの）として表現する．</p>\n<p>次元空間を持つことで，異なる感情の間でも類似度を計算できるのが利点</p>\n<p>Discrete approace</p>\n<p>感情をいくつかのカテゴリーに分類する．</p>\n<p>カテゴリ数は設定によって異なってくる．（2，32，64，など．emojiで表したり）</p>\n<p>Appraisal approach</p>\n<p>感情と引き起こされたリアクションの関係について学習する</p>\n<p>分布型</p>\n<p>感情の別の表現方法．embeddingを使う．</p>\n<p>メリット：</p>\n<ul>\n<li>感情の種類が連続的になり，補完が可能になる</li>\n<li>DLの入力として直接利用できる</li>\n</ul>\n<p>この利点は，感情のタイプを連続値として扱えること</p>\n<p>Deep learningのinputとして扱えること</p>\n<p>もう一つのタイプは感情を，実際の効果として重視する</p>\n<p>satisfactionやpolitenessとして分類する</p>\n<p>文や文脈から感情・感情を予測するタスク</p>\n<p>会話が与えられた時，感情ラベルを事前に予測する＝条件付き確率分布の学習と同義</p>\n<p>aspect-base分析</p>\n<p>目的：アスペクトと文の両方から感情ラベルを予測することを学習する．</p>\n<p>文に複数のアスペクトが付与されているとして，その種類に応じて予測を行う？</p>\n<p>対話システムによる感情ラベル予測では，現在の時間ステップまでの対話履歴しか見えないことがることに注意</p>\n<p><strong>Challenges</strong></p>\n<ul>\n<li>感情は曖昧な方法で表現される\n<ul>\n<li>コンテクストから理由づけを必要とする</li>\n</ul>\n</li>\n<li>対話で現れた感情は，過去から継続していて，文脈的な感情の状態にとても依存している\n<ul>\n<li>発話者自身もだが，そのパーティにも影響を受ける</li>\n</ul>\n</li>\n<li>さまざまなモダリティを合わせて感情を表している</li>\n</ul>\n<h3>Emotion-aware encoders</h3>\n<p><img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/zrlg6ntb.png\" alt=\"\"></p>\n<p>Emotion-aware encoderは，感情に関連した情報をエンコードする</p>\n<p>得られる文脈ベクトルにも感情に関連した情報が含まれる．</p>\n<p>モジュール化されたフレームワークは，POMDPとしてモデル化したものとして扱える</p>\n<p>追加の特徴量として感情のラベルを与えることで機能する</p>\n<p>ただし，テスト時は感情ラベルがない</p>\n<p>→emotion detector（＝追加の感情検出器）を加えて，暗示的に感情のラベルを推測することで機能させる</p>\n<h3>Emotion-expressive decoder</h3>\n<p><img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/w0fopt7s.png\" alt=\"\"></p>\n<p>感情的なレスポンスを促進する目的で使われる</p>\n<p>controllable variableとして直接感情を与える</p>\n<p>モデルはCVAEやGAN，RLなどを使うことが多いらしい</p>\n<p>controllable variableの想定</p>\n<p>一つまたは複数の潜在的な変数が応答の生成に対して強制力を持っていること</p>\n<p>そしてそのような変数が存在していること</p>\n<p>潜在的な対話状態をモデリングするのに自然なアーキテクチャはCVAE</p>\n<p>学習の際，微分できないことが多いので，誤差をフィードバックするにはRLを使うのが重要</p>\n<h3>Discussion</h3>\n<p><strong>Challenges</strong></p>\n<ul>\n<li>感情のラベルの不足\n<ul>\n<li>対話のアノテーション処理に時間がかかるため，人手が不足．</li>\n</ul>\n</li>\n</ul>\n<p>weak supervisions を用いることで緩和可能：事前に学習された感情ラベルを使うとか，複数のデータソースを組み合わせて規模を拡大するとか</p>\n<ul>\n<li>感情の評価\n<ul>\n<li>単語レベルでは感情の手がかりが微妙なこともある．</li>\n</ul>\n</li>\n</ul>\n<p>ユーザの本質的な感情と実際の認識にギャップがある可能性　→ユーザの誘導とギャップをノイズとして扱うこと．</p>\n<ul>\n<li>他の目的における感情のcompliance</li>\n<li>ターンレベルでのcontrollable variableと生成される単語の依存性</li>\n</ul>\n<h2>Personalized dialogue system; PDS</h2>\n<p><img src=\"/images/article/A-survey-on-empathetic-dialogue-systems/kip5j4e8.png\" alt=\"\"></p>\n<p>personalized informationは，話者の意図や継続的な状態を知覚したり，結果的に適したレスポンスを生成するのを成功させる鍵になる</p>\n<h3>User modeling</h3>\n<p>パーソナリティを表現する方法は，多くのパーソナリティ理論で重要になっている関心ごとである</p>\n<p>このサーベイでは，user modelingの方法として，二つに分類される</p>\n<ul>\n<li>identity-based</li>\n<li>knowledge-based</li>\n</ul>\n<p><strong>Identity-based user modeling</strong></p>\n<p>もっともシンプルな方法で，identityを静的な属性として与える</p>\n<p>identity-basedの特徴量は，信頼性があり，情報抽出するための追加のステップを必要とせずに直接的に扱うことができる</p>\n<p>identity-basedの特徴量のソースは主に，registrationで収集したメタデータである</p>\n<p>persona factsとidentity featuresはパーソナライズされた応答の生成に効果があるため，unstructured dataとstructured dataの双方を使う</p>\n<p>identity-basedをニューラルネットに入れるときは，embedding layerを用いて，連続値のdense vectorにする</p>\n<p><strong>Knowledge-based user modeling</strong></p>\n<p>structured dataとpredefined rulesを用いる</p>\n<p>identity-basedと比べると，これはユーザのメタデータの制限がない</p>\n<p>structuredとunstructured information data sourceを両方使用できる</p>\n<p>Personalized reasoningというタスク</p>\n<p>knowledge baseから事実を取り出すことを目的にしている</p>\n<h3>Personalized response generation</h3>\n<ul>\n<li>generative methods</li>\n<li>retrieval-based methods (ranking methods)</li>\n</ul>\n<p>PDSのメインの目標は，適した応答だけでなく，ユーザのじゅう雨よう（重要？）な知識に基づいた応答を生成すること</p>\n<p>ここでは二つのサブトピックの紹介があった</p>\n<ul>\n<li>personality-aware model</li>\n<li>personality-infused model</li>\n</ul>\n<p><strong>Personality-aware model</strong></p>\n<p>ユーザのパーソナリティ，もしくは会話のパーティに適応した応答を生成する</p>\n<p>その応答には，ユーザの嗜好が含まれるということである</p>\n<p>ユーザのプロファイルや会話履歴は，話者の記憶の中で異なる役割をはたす→メモリ(MMNの話など)</p>\n<p>システムの中で多くのユーザの参加する大規模な環境においては，それぞれのユーザのタイプに十分なデータを持つのが難しくなりうる</p>\n<p>→ユーザの知識を収集したり，転移することは可能</p>\n<p>以降はtransfer learningの話がなされていた．RLも同様に使えるとのこと</p>\n<p><strong>Personality-infused agent dialogue systems</strong></p>\n<p>会話をスムーズで，柔軟で自然に行うために，システムにpersonalityを与える</p>\n<p>3つのコンポーネントからなる</p>\n<ul>\n<li>Profiler Detector</li>\n<li>Bidirectional Decoder</li>\n<li>Position Detector</li>\n</ul>\n<ol>\n<li>\n<p>Profile Detector\nどのprofileのvalueが生成された応答の中で言及されるべきかを選ぶ</p>\n<p>MLPを使う</p>\n</li>\n<li>\n<p>Bidirectional Decoder\nprofile valueが言及される中で応答を生成する目的のデコーダ</p>\n</li>\n<li>\n<p>Position Detector\ndecoding positionのスタート位置を予測する</p>\n<p>ここで使うコンポーネントはbidirectional decoderで監視するように設計される</p>\n</li>\n</ol>\n<p>Position Detectorは，training dataをかえる性能があるらしい</p>\n<p>pre-specificなエージェントのprofileに沿った応答生成ができるモデルを提供してくれる</p>\n<p>persona representationの後，以下の提案があった</p>\n<ol>\n<li>\n<p>Persona Aware Attention\nそれぞれのdecoding positionに対するAttention weightsを生成する</p>\n</li>\n<li>\n<p>Persona Aware Bias\nデコーダのoutput layerの分散表現を差し込むことで生成分布を評価する</p>\n</li>\n</ol>\n<p>Attentive Memory Network; AMNの提案</p>\n<p>おそらく個人だけでなく，所属するグループの影響を加味するためのモデルだと思う</p>\n<p>コンポーネント二つ</p>\n<ol>\n<li>Attentive Encoders</li>\n<li>Knowledge-Store Memory Module</li>\n</ol>\n<h3>Knowledge-based dialogue system</h3>\n<p>current dialogue, personal background, external knowledge sourceからきた知識から探したり，コミュニケーションをとるプロセスを経る</p>\n<p>→ knowledge graphなど</p>\n<p>external knowledgeは重要な役割をはたすことができる</p>\n<p>このシステムはたいてい二つの追加のコンポーネントを持つ</p>\n<ol>\n<li>knowledge encoder</li>\n<li>knowledge-aware decoder</li>\n</ol>\n<p>これらによりcontextとexternal knowledgeの両方で応答に条件付けできる</p>\n<p><strong>Knowledge encoding</strong></p>\n<ol>\n<li>\n<p>Structured knowledge\nlanguage understandingで重要な役割</p>\n<p>扱うモデルの変遷</p>\n</li>\n</ol>\n<p>BoW→Sequence→Data cell→Recursive graph</p>\n<pre><code class=\"hljs\">人の前処理やルールベースなどでフィルターをかけるステップが必要\n</code></pre>\n<ol start=\"2\">\n<li>\n<p>Unstructured knowledge\n制約が少ないため，扱えるデータの量が多い</p>\n<p>分散表現に変換できるので，end-to-endのモデル</p>\n</li>\n</ol>\n<p><strong>Knowledge-aware decoding</strong></p>\n<p>historical knowledgeとしてknowledge source→contextなどとinputを一緒に入力にかける</p>\n<p>inputはembeddingされたもの</p>\n<p>応答生成における2種類の知識ソース：</p>\n<ul>\n<li>対話の履歴から得られるもの</li>\n<li>事前予知的知識</li>\n</ul>\n<ol>\n<li>\n<p>Knowledge attention\nknowledge encoderの出力であるknowledge embeddingを使って，応答の生成に条件付けをする</p>\n<p>文脈とknowledge embeddingのセットが与えられたら，関連する知識を読み取るか再認識する必要があり，それが応答性性の条件付けに使われる．</p>\n</li>\n<li>\n<p>Copy\nattention mechanismをベースにしている</p>\n<p>attentionを入力から単語を選び，コピーするためのポインターに使う</p>\n<p>seq2seqをコピー機構で拡張することで，検索ベースの手法より優れた性能を発揮する事が示された．</p>\n<p>単語は決められた単語の分布から取るか，knowledge baseからの単語をコピーすることで生成される</p>\n<p>高階層のmemory architectureの学習の提案をしている人もいる</p>\n</li>\n</ol>\n<h2>Future direction</h2>\n<p>empathetic dialogue systemに残る研究課題：</p>\n<p>personalization, knowledge, and emotion の要素の組み合わせによる包括的な共感システムの構築なんかはあまり行われていなかった．</p>\n<ol>\n<li>\n<p>Multi-goal Management</p>\n<ol>\n<li>\n<p>コミュニケーションには多くのobjective（目的）が乗っている\n→複数の目的によって過負荷になる事がある．感情や性格，知識を取り入れることでさらに顕著に．</p>\n</li>\n<li>\n<p>dialogue agentは全ての異なる側面に取り入れるべき\nすべての異なる側面を考慮する必要があるから↓</p>\n</li>\n<li>\n<p>user's inherent states, communicating information, minimizing the communicative effortsなど\nこれらを同時に達成するための最適解をいかに効率的に探索するかが問題となる</p>\n</li>\n</ol>\n</li>\n<li>\n<p>Explicit Affective Policy</p>\n<ol>\n<li>感情は明示的な行動と考えられる</li>\n<li>agentが他の人の感情をミラーリングしたり，共感を示したりする\n並列共感（相手の感情のミラーリング）と反応的共感に対して異なる戦略を取る事ができる．</li>\n</ol>\n</li>\n<li>\n<p>Long-term Empathy Modeling</p>\n<ol>\n<li>対話中での共感はlong-termである</li>\n<li>emotion, personality, knowledgeを静的，動的の双方で評価して，long-termで対応する\n静的で動的：安定的なベースを持ちながら，変化もしやすい．長期的なデータ収集において変化に適応する会話モデルの構築が課題．</li>\n</ol>\n</li>\n<li>\n<p>Dialogue Generation with Target-dependent Emotion</p>\n<ol>\n<li>感情は，話者と会話の参加者にアタッチされた特定の次元であるとして，target-dependent emotionをuser modelingに合わせる\n感情とターゲットの依存関係が省略されてきた．ターゲットに依存する感情をユーザモデリングと組み合わせることが望まれる（感情と人格の2次元の相関　←共同でモデル化する必要性）．</li>\n</ol>\n</li>\n<li>\n<p>Dialogue Generation with Emotion Knowledge</p>\n<ol>\n<li>sentimental, emotionalな知識を使って，感情の状態を認識する</li>\n</ol>\n</li>\n<li>\n<p>Incorporate Cues from Multimodal Input</p>\n<ol>\n<li>複数のモダリティを使って共感を示す</li>\n<li>i.e. audio signals, body gestures</li>\n</ol>\n</li>\n<li>\n<p>Personalized Diversifying Dialogue Generation</p>\n<ol>\n<li>ユーザに合わせて，生成する応答や検索する応答をカスタマイズする</li>\n<li>グループごとに多様性はあるが，同グループ内での多様性はかけるのが問題</li>\n</ol>\n</li>\n<li>\n<p>Deeper Conversation and User modeling</p>\n<ol>\n<li>与えられたユーザからのクエリに対して，統計的にもっともらしい回答を取り出すのがシンプルなメインの目標なのが現在</li>\n<li>将来的には，会話ごとにモデルを作ったり，どのようにユーザの感情が変わるかを理解したり，重要な会話や嗜好を覚えたり，ユーザのニーズや意図を汲み取る以上のことをするようになる(?)</li>\n<li>↑そのためのサブタスク\n<ol>\n<li>sarcasm detection（皮肉検出）</li>\n<li>time expression（時間表現）</li>\n<li>named entity recognition（固有表現）</li>\n<li>anaphora resolution</li>\n<li>microtext normalization</li>\n<li>etc</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2>引用</h2>\n<blockquote>\n<p>@article{MA202050,\ntitle = {A survey on empathetic dialogue systems},\njournal = {Information Fusion},\nvolume = {64},\npages = {50-70},\nyear = {2020},\nissn = {1566-2535},\ndoi = {<a href=\"https://doi.org/10.1016/j.inffus.2020.06.011%7D\">https://doi.org/10.1016/j.inffus.2020.06.011}</a>,\nurl = {<a href=\"https://www.sciencedirect.com/science/article/pii/S1566253520303092%7D\">https://www.sciencedirect.com/science/article/pii/S1566253520303092}</a>,\nauthor = {Yukun Ma and Khanh Linh Nguyen and Frank Z. Xing and Erik Cambria},\nkeywords = {Artificial intelligence, Affective computing, Dialogue systems},\nabstract = {Dialogue systems have achieved growing success in many areas thanks to the rapid advances of machine learning techniques. In the quest for generating more human-like conversations, one of the major challenges is to learn to generate responses in a more empathetic manner. In this review article, we focus on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge. Accordingly, we identify three key features that underpin such systems: emotion-awareness, personality-awareness, and knowledge-accessibility. The main goal of this review is to serve as a comprehensive guide to research and development on empathetic dialogue systems and to suggest future directions in this domain.}\n}</p>\n</blockquote>","Title":"【論文まとめ】A survey on empathetic dialogue systems","Date":"2023-05-22","Category":"論文","Tags":["survey","dialogue system","empathetic dialogue system"],"Authos":"ゆうぼう","Slug":"A-survey-on-empathetic-dialogue-systems","Thumbnail":"/images/thumbnails/A-survey-on-empathetic-dialogue-systems.png","Description":"A survey on empathetic dialogue systemsのまとめ","Published":true}],"tag":"empathetic dialogue system","categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","CSS","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"pages":1,"page":1},"__N_SSG":true}