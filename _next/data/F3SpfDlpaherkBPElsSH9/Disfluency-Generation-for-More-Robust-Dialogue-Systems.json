{"pageProps":{"postData":{"contentHtml":"<p>本記事において使用される図表は，原著論文内の図表を引用しています．</p>\n<p>また，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．</p>\n<h2>論文情報</h2>\n<p>タイトル: Disfluency Generation for More　Robust Dialogue Systems</p>\n<p>研究会: ACL</p>\n<p>年度: 2023</p>\n<p>キーワード: Speech Disfluency, DST, NLG</p>\n<p>URL: <a href=\"https://aclanthology.org/2023.findings-acl.728/\">https://aclanthology.org/2023.findings-acl.728/</a></p>\n<p>DOI: <a href=\"http://dx.doi.org/10.18653/v1/2023.findings-acl.728\">http://dx.doi.org/10.18653/v1/2023.findings-acl.728</a></p>\n<p>コード: <a href=\"https://github.com/4i-ai/BERT_disfluency_cls\">https://github.com/4i-ai/BERT_disfluency_cls</a></p>\n<p>データセット: DailyDialog, MultiWOZ, SIMMC2, Fisher</p>\n<h2>概要</h2>\n<p>非流暢な発話は対話システムの全てのモジュールに影響するエラー連鎖の原因になりうる（NLU, DST, NLG）</p>\n<p>一般的に使われている対話データセットに非流暢な発話がほとんど含まれていないことを分析し（表3），流暢な発話を非流暢な発話にパラフレージングするaugmentation手法を提案</p>\n<p>提案した手法でaugmentationした非流暢な発話を学習に用いることで，DSTとNLGの両方において性能が改善することを示す．</p>\n<p>以下が非流暢性のタイプと非流暢性による対話システムのエラーの例</p>\n<p><img src=\"/images/article/Disfluency-Generation-for-More-Robust-Dialogue-Systems/evtotgu2.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Disfluency-Generation-for-More-Robust-Dialogue-Systems/rhe52mqj.png\" alt=\"\"></p>\n<p>非流暢性の割合を分析した結果</p>\n<p><img src=\"/images/article/Disfluency-Generation-for-More-Robust-Dialogue-Systems/6xrbquop.png\" alt=\"\"></p>\n<h2>提案手法</h2>\n<p><strong>分類器によって流暢だと判定された発話を非流暢な発話にパラフレージング</strong></p>\n<h3>Disfluent Paraphraser</h3>\n<p><strong>LLM (T5) を用いて非流暢性の生成</strong>（非流暢性の修正をLLMで行う先行研究あり）</p>\n<p>（BART, OPT, BLOOM等を使えば，同様の結果もしくはより良い性能が出るかも？）</p>\n<p>LLMに非流暢性のseq2seqな生成タスクを学習させるために，非流暢な発話とそれに対応する流暢な発話のペアが必要</p>\n<p>→ <strong>大規模な学習データが存在しないため，few-shot learningを適用</strong></p>\n<p>ビームサーチで生成すると，元の流暢な発話の構造を保つ保守的なパラフレーズが多い</p>\n<p>→ 元の発話とオーバーラップが少ない多様な発話を生成したい</p>\n<p>→ <span class=\"math math-inline\"><mjx-container class=\"MathJax\" jax=\"SVG\"><svg style=\"vertical-align: -0.566ex;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"19.282ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 8522.7 1000\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><path id=\"MJX-1-TEX-I-1D6FD\" d=\"M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z\"></path><path id=\"MJX-1-TEX-N-3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path><path id=\"MJX-1-TEX-N-30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path><path id=\"MJX-1-TEX-N-2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\"></path><path id=\"MJX-1-TEX-N-32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path><path id=\"MJX-1-TEX-N-28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path><path id=\"MJX-1-TEX-N-2264\" d=\"M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z\"></path><path id=\"MJX-1-TEX-N-31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path id=\"MJX-1-TEX-N-29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></defs><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><use data-c=\"1D6FD\" xlink:href=\"#MJX-1-TEX-I-1D6FD\"></use></g><g data-mml-node=\"mo\" transform=\"translate(843.8,0)\"><use data-c=\"3D\" xlink:href=\"#MJX-1-TEX-N-3D\"></use></g><g data-mml-node=\"mn\" transform=\"translate(1899.6,0)\"><use data-c=\"30\" xlink:href=\"#MJX-1-TEX-N-30\"></use><use data-c=\"2E\" xlink:href=\"#MJX-1-TEX-N-2E\" transform=\"translate(500,0)\"></use><use data-c=\"32\" xlink:href=\"#MJX-1-TEX-N-32\" transform=\"translate(778,0)\"></use></g><g data-mml-node=\"mstyle\" transform=\"translate(3177.6,0)\"><g data-mml-node=\"mspace\"></g></g><g data-mml-node=\"mstyle\" transform=\"translate(3344.6,0)\"><g data-mml-node=\"mspace\"></g></g><g data-mml-node=\"mo\" transform=\"translate(3511.6,0)\"><use data-c=\"28\" xlink:href=\"#MJX-1-TEX-N-28\"></use></g><g data-mml-node=\"mn\" transform=\"translate(3900.6,0)\"><use data-c=\"30\" xlink:href=\"#MJX-1-TEX-N-30\"></use></g><g data-mml-node=\"mo\" transform=\"translate(4678.3,0)\"><use data-c=\"2264\" xlink:href=\"#MJX-1-TEX-N-2264\"></use></g><g data-mml-node=\"mi\" transform=\"translate(5734.1,0)\"><use data-c=\"1D6FD\" xlink:href=\"#MJX-1-TEX-I-1D6FD\"></use></g><g data-mml-node=\"mo\" transform=\"translate(6577.9,0)\"><use data-c=\"2264\" xlink:href=\"#MJX-1-TEX-N-2264\"></use></g><g data-mml-node=\"mn\" transform=\"translate(7633.7,0)\"><use data-c=\"31\" xlink:href=\"#MJX-1-TEX-N-31\"></use></g><g data-mml-node=\"mo\" transform=\"translate(8133.7,0)\"><use data-c=\"29\" xlink:href=\"#MJX-1-TEX-N-29\"></use></g></g></g></svg></mjx-container></span>でtop-pサンプリングすると有用な非流暢な発話が得られた</p>\n<h3>Disfluent Identification</h3>\n<p>Paraphraserが積極的に非流暢な変換を行いすぎると，元の発話と意味が変わってしまう</p>\n<p>分類器を用いて，元の発話をどの程度パラフレージングするかを決める</p>\n<ul>\n<li>disfluentなら，praphraserを用いない</li>\n<li>低い確率でdisfluentなら，少し修正してdisfluentに</li>\n<li>fulentならaggressiveにdisfluentに</li>\n</ul>\n<p>分類器にはBERTを用いる（先行研究 by Yang et al., 2020に従う）</p>\n<h2>新規性</h2>\n<ul>\n<li>公開されている一般的な対話コーパスには非流暢な発話があまり含まれておらず，対話システムのロバスト性に影響していることを分析</li>\n<li>LLMを用いて，流暢な発話を非流暢な発話へパラフレージングするフレームワークを提案</li>\n<li>提案手法により，対話システムのロバスト性を向上</li>\n</ul>\n<h2>実験</h2>\n<p><img src=\"/images/article/Disfluency-Generation-for-More-Robust-Dialogue-Systems/m9bbczfi.png\" alt=\"\"></p>\n<p>Paraphraserと分類器の学習にはFisher Englishコーパスを使用</p>\n<p>SIMMC2でDRTとNLGを評価</p>\n<p><img src=\"/images/article/Disfluency-Generation-for-More-Robust-Dialogue-Systems/r29zg4uu.png\" alt=\"\"></p>\n<p>Original：オリジナルのSIMMC2で10エポック学習されたGPT2</p>\n<p>General Paraphraser：非流暢性の生成で学習されていないスタンダードなT5 paraphraser</p>\n<p>流暢性と非流暢性を混ぜても性能が向上するのは提案手法（Disfluent Paraphraser）のみ（表でいう(c)のスコア）</p>\n<p>また，少なくとも500件は学習データがないと，提案手法ではBLEURTとjoint accuracyが下がる</p>\n<h2>まとめ</h2>\n<p>LLM (T5) を用いた非流暢な発話へのパラフレージングによるaugmentationデータを混ぜることで，対話モデルをよりうまく学習させることができ，非流暢な発話にロバストになることを確認</p>\n<p>DST及びNLGでの性能向上を確認</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h3>Limitations</h3>\n<ul>\n<li>利用可能な公開データセットはほとんどが流暢な発話でアノテーションされており，多様な非流暢性を含むもっと代表的な評価データセットを構築すべき</li>\n</ul>\n<h2>次読みたい論文</h2>\n<h2>引用</h2>\n<blockquote>\n<p>@inproceedings{marie-2023-disfluency,\ntitle = \"Disfluency Generation for More Robust Dialogue Systems\",\nauthor = \"Marie, Benjamin\",\nbooktitle = \"Findings of the Association for Computational Linguistics: ACL 2023\",\nmonth = jul,\nyear = \"2023\",\naddress = \"Toronto, Canada\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"<a href=\"https://aclanthology.org/2023.findings-acl.728\">https://aclanthology.org/2023.findings-acl.728</a>\",\ndoi = \"10.18653/v1/2023.findings-acl.728\",\npages = \"11479--11488\",\nabstract = \"Disfluencies in user utterances can trigger a chain of errors impacting all the modules of a dialogue system: natural language understanding, dialogue state tracking, and response generation. In this work, we first analyze existing dialogue datasets commonly used in research and show that they only contain a marginal number of disfluent utterances. Due to this relative absence of disfluencies in their training data, dialogue systems may then critically fail when exposed to disfluent utterances. Following this observation, we propose to augment existing datasets with disfluent user utterances by paraphrasing fluent utterances into disfluent ones. Relying on a pre-trained language model, our few-shot disfluent paraphraser guided by a disfluency classifier can generate useful disfluent utterances for training better dialogue systems. We report on improvements for both dialogue state tracking and response generation when the dialogue systems are trained on datasets augmented with our disfluent utterances.\",\n}</p>\n</blockquote><style>\nmjx-container[jax=\"SVG\"] {\n  direction: ltr;\n}\n\nmjx-container[jax=\"SVG\"] > svg {\n  overflow: visible;\n  min-height: 1px;\n  min-width: 1px;\n}\n\nmjx-container[jax=\"SVG\"] > svg a {\n  fill: blue;\n  stroke: blue;\n}\n\nmjx-container[jax=\"SVG\"][display=\"true\"] {\n  display: block;\n  text-align: center;\n  margin: 1em 0;\n}\n\nmjx-container[jax=\"SVG\"][display=\"true\"][width=\"full\"] {\n  display: flex;\n}\n\nmjx-container[jax=\"SVG\"][justify=\"left\"] {\n  text-align: left;\n}\n\nmjx-container[jax=\"SVG\"][justify=\"right\"] {\n  text-align: right;\n}\n\ng[data-mml-node=\"merror\"] > g {\n  fill: red;\n  stroke: red;\n}\n\ng[data-mml-node=\"merror\"] > rect[data-background] {\n  fill: yellow;\n  stroke: none;\n}\n\ng[data-mml-node=\"mtable\"] > line[data-line], svg[data-table] > g > line[data-line] {\n  stroke-width: 70px;\n  fill: none;\n}\n\ng[data-mml-node=\"mtable\"] > rect[data-frame], svg[data-table] > g > rect[data-frame] {\n  stroke-width: 70px;\n  fill: none;\n}\n\ng[data-mml-node=\"mtable\"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed {\n  stroke-dasharray: 140;\n}\n\ng[data-mml-node=\"mtable\"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted {\n  stroke-linecap: round;\n  stroke-dasharray: 0,140;\n}\n\ng[data-mml-node=\"mtable\"] > g > svg {\n  overflow: visible;\n}\n\n[jax=\"SVG\"] mjx-tool {\n  display: inline-block;\n  position: relative;\n  width: 0;\n  height: 0;\n}\n\n[jax=\"SVG\"] mjx-tool > mjx-tip {\n  position: absolute;\n  top: 0;\n  left: 0;\n}\n\nmjx-tool > mjx-tip {\n  display: inline-block;\n  padding: .2em;\n  border: 1px solid #888;\n  font-size: 70%;\n  background-color: #F8F8F8;\n  color: black;\n  box-shadow: 2px 2px 5px #AAAAAA;\n}\n\ng[data-mml-node=\"maction\"][data-toggle] {\n  cursor: pointer;\n}\n\nmjx-status {\n  display: block;\n  position: fixed;\n  left: 1em;\n  bottom: 1em;\n  min-width: 25%;\n  padding: .2em .4em;\n  border: 1px solid #888;\n  font-size: 90%;\n  background-color: #F8F8F8;\n  color: black;\n}\n\nforeignObject[data-mjx-xml] {\n  font-family: initial;\n  line-height: normal;\n  overflow: visible;\n}\n\nmjx-container[jax=\"SVG\"] path[data-c], mjx-container[jax=\"SVG\"] use[data-c] {\n  stroke-width: 3;\n}\n</style>","Title":"【論文まとめ】Disfluency Generation for More　Robust Dialogue Systems","Date":"2023-10-15","Category":"論文","Tags":["Speech Disfluency","DST","NLG"],"Authos":"ゆうぼう","Slug":"Disfluency-Generation-for-More-Robust-Dialogue-Systems","Thumbnail":"/images/thumbnails/Disfluency-Generation-for-More-Robust-Dialogue-Systems.png","Description":"Disfluency Generation for More　Robust Dialogue Systemsのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","Contrastive Learning","CSS","Dialogue Structure Learning","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","Merging Models","ML","Model Editing","Model Patching","MT","Multi-Hop Transformer","multi-modal","MySQL","NLG","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","Speech Disfluency","subprocess","Super-Resolution","survey","tensorflow","Tkinter","Transfer Learning","transformer","Weight Interpolation","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","聞き手反応","超解像"]},"__N_SSG":true}