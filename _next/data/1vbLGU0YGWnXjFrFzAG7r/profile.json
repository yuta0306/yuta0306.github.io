{"pageProps":{"aboutData":{"contentHtml":"<h2>Bio</h2>\n<p>I am a graduate student at Tokyo Institute of Technology.<br>\nI would like to research into human-like dialogue systems, and build my career to develop the society where humans and AI cooperate with each other.<br>\nI'm wating for the invitation for internships and collaborative research.<br>\nPlease feel free to contact me!</p>\n<p>(日本語)<br>\n東京工業大学で大学院生をしています．<br>\nhuman-likeな対話システムの研究に従事し，人間とAIの共生社会の構築に人生を捧げたいと考えています．<br>\nインターンシップや共同研究のお誘いをお待ちしております．<br>\n気軽な連絡お待ちしております！</p>\n<h2>Research Interest</h2>\n<ul>\n<li>Dialogue System (対話システム)</li>\n<li>Multi-modal Dialogue System (マルチモーダル対話システム)</li>\n<li>Speech Dialogue System (音声対話システム)</li>\n<li>Speech Disfluency (非流暢性)</li>\n<li>Human Interaction (ヒューマンインタラクション)</li>\n<li>LLM (大規模言語モデル)</li>\n<li>Humor Recognition (ユーモア検出)</li>\n<li>Knowledge-Intensive NLP (知識に基づく自然言語処)</li>\n</ul>\n<h2>Publication</h2>\n<h3>International Conference</h3>\n<ol>\n<li><strong>Yuta Sasaki</strong>, Jianwei Zhang, Yuhki Shiraishi. Commonsense-aware Attentive Modeling for Humor Recognition. <a href=\"https://www.dexa.org/dexa2023\">The 34th International Conference on Database and Expert Systems Applications (DEXA 2023)</a>. [<a href=\"https://link.springer.com/chapter/10.1007/978-3-031-39847-6_3\">paper</a>] [slide (in preparation)]\n<ul>\n<li>Acceptance rate ?% (FYI, 20.4% in DEXA 2019)</li>\n<li>Online presentation</li>\n</ul>\n</li>\n<li>Jianwei Zhang, Takeru Oda, <strong>Yuta Sasaki</strong>, Lin Li. Link Prediction in Dynamic Networks by Combining GIN with LSTM. <a href=\"https://ijckg2023.knowledge-graph.jp/index.html\">The 12th International Joint Conference on Knowledge Graphs (IJCKG 2023)</a>. [<a href=\"https://ijckg2023.knowledge-graph.jp/pages/proc/paper_14.pdf\">paper</a>]</li>\n</ol>\n<h3>Domestic Conference (Japanese)</h3>\n<ol>\n<li><strong>佐々木 裕多</strong>, 張 建偉, 白石 優旗. Commonsense生成モデルを用いたユーモア検出の性能評価. 2021年度情報処理学会東北支部研究会 (山形大学).</li>\n<li>小田 大翔, <strong>佐々木 裕多</strong>, 張 建偉. 動的グラフにおけるGNNを用いたリンク予測. 2022年度情報処理学会東北支部研究会 (岩手大学).</li>\n<li>佐藤 将太, <strong>佐々木 裕多</strong>, 張 建偉. 応答戦略と共感表現を考慮した感情支援対話の応答生成. 2022年度情報処理学会東北支部研究会 (山形大学).</li>\n<li><strong>佐々木 裕多</strong>, 張 建偉, 白石 優旗. Commonsense-aware AttentionとDiscrepancy Resolution Lossを用いたユーモア検出手法の提案. <a href=\"https://event.dbsj.org/deim2023/\">第15回データ工学と情報マネジメントに関するフォーラム (DEIM 2023)</a>. [<a href=\"https://proceedings-of-deim.github.io/DEIM2023/1b-3-2.pdf\">paper</a>]</li>\n<li>谷 聡馬, <strong>佐々木 裕多</strong>, 張 建偉. ニュースコンテンツとソーシャルコンテクストを用いたフェイクニュースの早期自動検出. <a href=\"https://event.dbsj.org/deim2023/\">第15回データ工学と情報マネジメントに関するフォーラム (DEIM 2023)</a>. [<a href=\"https://proceedings-of-deim.github.io/DEIM2023/1a-8-2.pdf\">paper</a>]</li>\n<li><strong>佐々木 裕多</strong>, 張 建偉. 漫才対話の収集及び自動アノテーションのパイプラインの検討. <a href=\"https://www.anlp.jp/proceedings/annual_meeting/2023/\">言語処理学会第29回年次大会 (NLP 2023)</a>. [<a href=\"https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/Q4-14.pdf\">paper</a>]</li>\n<li>片岸 祥帆, 小原 涼馬, <strong>佐々木 裕多</strong>, 荒木 健治. 漫才対話構造の分析手法の検討. NLP若手の会 (YANS) 第18回シンポジウム. [<a href=\"https://drive.google.com/file/d/1YNA8Wh2uIF4WnTgXJsglse9THV90aBZq/view?usp=sharing\">poster</a>]</li>\n<li>東中竜一郎, 高橋哲朗, 稲葉通将, 斉志揚, <strong>佐々木裕多</strong>, 船越孝太郎, 守屋彰二, 佐藤志貴, 港隆史, 境くりま, 船山智, 小室允人, 西川寛之, 牧野遼作, 菊池浩史, 宇佐美まゆみ. 対話システムライブコンペティション6. <a href=\"https://jsai-slud.github.io/sig-slud/99th-sig.html\">第99回人工知能学会 言語・音声理解と対話処理研究会 (第14回対話システムシンポジウム 2023)</a></li>\n</ol>\n<h2>Education</h2>\n<p>2023.4 - <strong>Present</strong><br>\n<strong>Master of Tokyo Institute of Technology, Tokyo, Japan / 東京工業大学</strong><br>\n<em>School of Engineering Department of Information and Communications Engineering / 工学院 情報通信系</em></p>\n<p>2019.4 - 2023.3<br>\n<strong>Bachelor of Iwate University, Iwate, Japan / 岩手大学</strong><br>\n<em>School of Computer, Intelligence and Media Technology, Department of Systems Innovation Engineering, Faculty of Science and Engineering / 理工学部 システム創成工学科 知能メディア・情報コース</em></p>\n<h2>Scholorship</h2>\n<ol>\n<li>岩手大学理工学部修学支援奨学金 (令和3年4月 - 令和4年3月)</li>\n</ol>\n<h2>Job Experience</h2>\n<p>Comming soon...</p>\n<h2>Internship</h2>\n<p>2023.8 - <strong>Present</strong><br>\n<strong>Research Development Internship / R&#x26;Dインターンシップ</strong><br>\n<a href=\"https://research.reazon.jp/\"><em>Reazon Human Interaction Lab</em></a><br>\nマルチモーダル／対話システム／音声認識</p>\n<p>2023.9<br>\n<strong>Machine Learning Engineer Internship / MLエンジニアインターンシップ @ CA Tech JOB</strong><br>\n<em>CyberAgent 極予測LP</em><br>\nトレーナー：石上亮介<br>\nLLMを用いた自動対話評価基盤の構築と検討 [リンク準備中] [リンク準備中]</p>\n<p>2023.11 - <strong>Present</strong><br>\n<strong>インターンシップ</strong><br>\n<a href=\"https://elith.co.jp/\"><em>Elith Inc.</em></a><br>\nLLMなど</p>\n<h2>Other Experiences</h2>\n<ul>\n<li><a href=\"https://sites.google.com/view/dslc6\">対話システムライブコンペティション6オーガナイザ</a></li>\n<li><a href=\"https://icasspeech.connpass.com/event/292978/\">INTERSPEECH2023論文読み会登壇</a></li>\n<li><a href=\"https://dialog-paper.connpass.com/event/297411/\">SIGDIAL2023&#x26;SemDial2023論文読み会運営</a></li>\n</ul>\n<h2>Software</h2>\n<h3><strong>dslclib</strong> [<a href=\"https://github.com/yuta0306/dslclib\">code</a>] [<a href=\"https://yuta0306.github.io/dslclib/\">docs</a>] [<a href=\"https://pypi.org/project/dslclib/\">PyPI</a>]</h3>\n<p>対話システムライブコンペティション6で使用できるPythonライブラリ．ロボットコンペの方でも使えるようになっている．</p>\n<h3><strong>py-arib-parser</strong> [<a href=\"https://github.com/yuta0306/py-arib-parser\">code</a>]</h3>\n<p>ARIB形式の字幕を抽出するため，arib対応ffmpegをインストールするdockerfileと字幕ファイルを読み込むクラスを記述したライブラリ．<br>\n抽出した字幕を，付与されたカラーコードでターミナルに出力することができる．</p>\n<h3><strong>fed_ja</strong> [<a href=\"https://huggingface.co/datasets/yubo0306/fed_ja\">dataset</a>]</h3>\n<p>対話自動評価で用いられるFEDデータセットをGoogle Cloud Translate API v2で日本語に翻訳したデータセット．</p>\n<h2>Certification</h2>\n<ul>\n<li>TOEIC® Listening &#x26; Reading Test: 865 / 990</li>\n<li>Python3 エンジニア認定基礎試験合格者</li>\n<li>Python3 エンジニア認定データ分析試験合格者</li>\n</ul>\n<h2>Skills</h2>\n<h3>Main</h3>\n<ul>\n<li>Python</li>\n<li>JavaScript</li>\n<li>HTML5</li>\n<li>CSS3 / SCSS</li>\n<li>Docker</li>\n</ul>\n<h3>Sub</h3>\n<ul>\n<li>GCP</li>\n<li>TypeScript</li>\n<li>AWS</li>\n<li>C#</li>\n<li>PHP</li>\n<li>ROS</li>\n</ul>\n<h3>Frameworks</h3>\n<ul>\n<li>Flask</li>\n<li>Pytorch / Pytorch Lightning</li>\n<li>Pelican (SSG with Python)</li>\n<li>React / Next.js (These framework are used in this blog)</li>\n</ul>\n<h2>Contact</h2>\n<p>Email: yubo1336[at]lr.pi.titech.ac.jp<br>\nTwitter: <a href=\"https://twitter.com/Sloth65557166\">@Sloth65557166</a><br>\nGitHub: <a href=\"https://github.com/yuta0306\">@yuta0306</a><br>\nconnpass: <a href=\"https://connpass.com/user/yuta0306/\">@yuta0306</a><br>\nKaggle: <a href=\"https://www.kaggle.com/yutasasaki\">@yutasasaki</a><br>\nLinkedIn: <a href=\"https://www.linkedin.com/in/yuta-sasaki-170472226/\">Yuta SASAKI</a><br>\nBlog: <a href=\"https://yuta0306.github.io/\">ゆうぼうの書跡棚</a></p>","title":"About Me"}},"__N_SSG":true}