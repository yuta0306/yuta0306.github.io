{"pageProps":{"postData":{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<p>Transformersã‚’ä½¿ã£ã¦å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’tokenizeã™ã‚‹ã¨ãã«ï¼Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒå¤§ãã‹ã£ãŸã®ã§ï¼Œãƒãƒƒãƒå˜ä½ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸã‹ã£ãŸæ™‚ãŒã‚ã‚Šã¾ã—ãŸï¼</p>\n<p>ã“ã®æ™‚ï¼Œcollate_fnã«å¯¾ã—ã¦è¤‡æ•°ã®å¼•æ•°ã‚’ä¸ãˆãŸã‹ã£ãŸçŠ¶æ³ã®æ™‚ã®å¯¾å‡¦æ³•ã§ã™ï¼(æ—¥æœ¬èªå¤‰ã‹?)</p>\n<h2>ã‚„ã‚ŠãŸã‹ã£ãŸã“ã¨</h2>\n<p>DataLoaderã‚’å®šç¾©ã™ã‚‹ã¨ãã«ï¼Œ<code>collate_fn</code>ã®ã¨ã“ã‚ã§è‡ªä½œcollate_fnã‚’æŒ‡å®šã—ã¦ï¼Œbatchå˜ä½ã§æµã‚Œã¦ãã‚‹ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ï¼</p>\n<p>ã“ã‚ŒãŒã‚„ã‚ŠãŸã„ã“ã¨ã«ãªã‚Šã¾ã™ï¼ã¤ã¾ã‚Šã“ã‚“ãªæ„Ÿã˜</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyDataset</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=custom_collate_fn)  <span class=\"hljs-comment\"># &#x3C;--- ã“ã“ã§è‡ªä½œcollate_fnã‚’æŒ‡å®šã—ã¦åˆ¶å¾¡</span>\n</code></pre>\n<h2>ã‚„ã£ã¦ã†ã¾ãã„ã‹ãªã‹ã£ãŸã“ã¨</h2>\n<p>å…ˆã«ã‚„ã£ã¦ã†ã¾ãã„ã‹ãªã‹ã£ãŸã“ã¨ã‚’å…±æœ‰ã—ã¦ãŠãã¾ã™ï¼</p>\n<p>è‡ªåˆ†ãŒä½¿ã£ã¦ã„ã‚‹ã®ãŒï¼Œ<code>pytorch-lightning</code>ãªã®ã§ãã®ã›ã„ã‚‚ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼ãªã®ã§ï¼Œã‚‚ã—ã‹ã—ãŸã‚‰æ™®é€šã«ç´ ã®Pytorchãªã‚‰ã†ã¾ãã„ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼</p>\n<p>æ•™ãˆã¦ãã ã•ã„ğŸ™</p>\n<h3>lambdaå¼ã§åˆ¶å¾¡ã™ã‚‹ (functools.partialã‚’ä½¿ã†)</h3>\n<p>ã“ã‚“ãªã“ã¨ã‚’ã—ã¾ã—ãŸï¼</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyDataset</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n        <span class=\"hljs-keyword\">return</span> text, label\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">custom_collate_fn</span>(<span class=\"hljs-params\">data, tokenizer, max_length</span>):\n    texts, labels = <span class=\"hljs-built_in\">zip</span>(*data)\n    texts = <span class=\"hljs-built_in\">list</span>(texts)\n    texts = tokenizer.batch_encode_plus(\n        texts,\n        padding=<span class=\"hljs-literal\">True</span>,\n        truncation=<span class=\"hljs-literal\">True</span>,\n        max_length=max_length,\n        return_tensors=<span class=\"hljs-string\">'pt'</span>,\n    )\n    labels = torch.LongTensor(labels)\n    <span class=\"hljs-keyword\">return</span> texts, labels\n\ntokenizer = AutoTokenizer.from_pretrained(...)\nmax_length = <span class=\"hljs-number\">256</span>\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=<span class=\"hljs-keyword\">lambda</span> data: custom_collate_fn(data, tokenizer, max_length))\n</code></pre>\n<p><code>pytorch-lightning</code>ã®ä»•æ§˜ã ã¨ã¯æ€ã†ã®ã§ã™ãŒï¼Œ<code>pickle</code>ã§åœ§ç¸®ã™ã‚‹ã‚‰ã—ããã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã‚¨ãƒ©ãƒ¼ã‚’åã‹ã‚Œã¾ã—ãŸï¼</p>\n<p>ãªãœã ã‚ã†...æœ‰è­˜è€…ã®æ–¹æ•™ãˆã¦ãã ã•ã„...</p>\n<h2>ã€è§£æ±ºç­–ã€‘ classã§å®šç¾©ã™ã‚‹</h2>\n<p>lambdaå¼ã§ãƒ€ãƒ¡ã ã£ãŸã®ã§ï¼Œã‚‚ã†ã‚¯ãƒ©ã‚¹ã®å†…éƒ¨ã«å¿…è¦ãªã‚‚ã®ã‚’ä¿æŒã•ã›ã¦ãŠã“ã†ã¨ã„ã†ã“ã¨ã«ãªã‚Šã¾ã—ãŸï¼(åƒ•ã®ä¸­ã§ã¯)</p>\n<p>æ¬¡ã®ã‚³ãƒ¼ãƒ‰ã®ã‚ˆã†ãªæ„Ÿã˜ã§è§£æ±ºã—ã¾ã—ãŸï¼</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> torch.utils <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyDataset</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, *args, **kwargs</span>):\n        <span class=\"hljs-built_in\">super</span>().__init__()\n        ...\n    \n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        ...\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx: <span class=\"hljs-built_in\">int</span></span>):\n        ...\n        <span class=\"hljs-keyword\">return</span> text, label\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CollateFn</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, tokenizer, max_length: <span class=\"hljs-built_in\">int</span></span>) -> <span class=\"hljs-literal\">None</span>:\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        os.environ[<span class=\"hljs-string\">\"TOKENIZERS_PARALLELISM\"</span>] = <span class=\"hljs-string\">\"true\"</span>  <span class=\"hljs-comment\"># &#x3C;--- å¤šåˆ†ã“ã‚Œã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã—ãªã„ã¨æ€’ã‚‰ã‚Œã¾ã™ (true|false)</span>\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__call__</span>(<span class=\"hljs-params\">self, data</span>):\n        texts, labels = <span class=\"hljs-built_in\">zip</span>(*data)\n        texts = <span class=\"hljs-built_in\">list</span>(texts)\n        texts = self.tokenizer.batch_encode_plus(\n            texts,\n            padding=<span class=\"hljs-literal\">True</span>,\n            truncation=<span class=\"hljs-literal\">True</span>,\n            max_length=self.max_length,\n            return_tensors=<span class=\"hljs-string\">'pt'</span>,\n        )\n        labels = torch.LongTensor(labels)\n        <span class=\"hljs-keyword\">return</span> texts, labels\n\ntokenizer = AutoTokenizer.from_pretrained(...)\nmax_length = <span class=\"hljs-number\">256</span>\ndataloader = DataLoader(dataset=MyDataset(), batch_size=<span class=\"hljs-number\">16</span>, shuffle=<span class=\"hljs-literal\">True</span>,\n            num_workers=os.cpu_count(),\n            collate_fn=CollateFn(tokenizer, max_length))\n</code></pre>\n<h2>ã¾ã¨ã‚</h2>\n<p>ç´ ã®Pytorchã§çµ„ã‚ã°å•é¡Œãªã‹ã£ãŸã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒï¼Œ<code>pytorch-lightning</code>ã‚’ä½¿ã£ã¦ã„ã‚‹æ–¹ã¯åŒã˜çŠ¶æ³ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼</p>\n<p>ãã®æ™‚ã¯ï¼Œãœã²å‚è€ƒã«classã§collate_fnã§å®Ÿè£…ã—ã¦ã¿ã¦è§£æ±ºã®ä¸€åŠ©ã¨ãªã‚ŒãŸã‚‰å¹¸ã„ã§ã™ï¼</p>\n</body>\n</html>\n","Title":"collate_fnã§è¤‡æ•°ã®å¼•æ•°ã‚’å–ã‚ŠãŸã„!!","Date":"2021-12-24","Category":"Python","Tags":["ML","Python","Pytorch"],"Authors":"ã‚†ã†ã¼ã†","Slug":"pytorch-collate_fn-args","Thumbnail":"/images/thumbnails/pytorch-logo.jpg","Description":"Transformersã‚’ä½¿ã£ã¦å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’tokenizeã™ã‚‹ã¨ãã«ï¼Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒå¤§ãã‹ã£ãŸã®ã§ï¼Œãƒãƒƒãƒå˜ä½ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸã‹ã£ãŸæ™‚ãŒã‚ã‚Šã¾ã—ãŸï¼ã“ã®æ™‚ï¼Œcollate_fnã«å¯¾ã—ã¦è¤‡æ•°ã®å¼•æ•°ã‚’ä¸ãˆãŸã‹ã£ãŸçŠ¶æ³ã®æ™‚ã®å¯¾å‡¦æ³•ã§ã™ï¼(æ—¥æœ¬èªå¤‰ã‹ã‚‚)","Published":true},"categories":["è«–æ–‡","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net","conda","CSS","dialogue system","dialogue system,Internet-Augmented","dialogue system,knowledge-base","dialogue system,NLI","dialogue system,persona,Prompt-Tuning","dialogue system,survey,DST","DST","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","humor detection,multi-modal","JavaScript","JSON","Kaggle","laughter,shared laughter","Linux","Mac","make","map","MeCab","ML","MT,transformer,Multi-Hop Transformer","multi-modal","MySQL","NLP","Node","node.js","npm","Pandas","Poetry","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","SISR","subprocess","Super-Resolution","survey","survey,dialogue system","survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP","tensorflow","Tkinter","transformer","transformer,Highway Transformer,Gating Mechanism,Self-Dependency-Units (SDU)","zsh","ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæŒ‡å‘","ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿","ãƒ‡ãƒ¼ã‚¿åˆ†æ","ç‰¹æ®Šãƒ¡ã‚½ãƒƒãƒ‰","è¶…è§£åƒ"]},"__N_SSG":true}