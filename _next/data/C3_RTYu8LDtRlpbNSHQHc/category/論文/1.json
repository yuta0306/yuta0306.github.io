{"pageProps":{"CategoricalPostData":[{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>対話を通じてユーザに行動変容を促す説得対話システムの研究を行うため，マルチモーダル情報を含む説得対話コーパスの収録</p>\n<p>音声と顔画像から得られる特徴量を含む説得対話コーパス</p>\n<p>収集したコーパスと合わせて前後にアンケート</p>\n<p>被験者に対して追跡調査を行い，実際に説得により行動が変容したかも調査</p>\n<h2>提案手法</h2>\n<p>5〜8分の対話を収録</p>\n<p>3つのドメインについて収集：「運動の促し」「インターネット依存の改善」「慈善事業団体への募金の促し」</p>\n<p>Woz対話であることを伏せて，ERICAで開発された新しいシステムと対話をしてもらうという目的と被験者に伝えた</p>\n<p>効果的な説得対話の戦略（論文参照）に基づいてERICAが発話</p>\n<p>また以下の流れで対話</p>\n<ol>\n<li>お互いに挨拶</li>\n<li>会話テーマの提示（ドメイン）</li>\n<li>会話テーマに対する被験者の意識を尋ねる</li>\n<li>相手の反応に応じて説得</li>\n<li>5分経過後，流れに応じて対話終了</li>\n</ol>\n<h2>新規性</h2>\n<p>説得対話における非言語情報の活用を指向し，遠隔操作Androidを用いたWoz対話によるcleanマルチモーダル説得対話コーパスの収集</p>\n<p>先行研究では主に対話中の説得にフォーカスしているが，本論文では追跡調査による実際の行動変容を調査</p>\n<h2>実験</h2>\n<p><strong>収録環境</strong></p>\n<p>説得マイクでステレオ録音／Webカメラで正面から顔を撮影→OpenFaceでAction Unitを抽出／音声は書き起こし→訓練されたアノテーたによって拡張ISO-24617-2対話行為タグに基づく対話行為タグ付与を</p>\n<p><strong>事前アンケート</strong></p>\n<p>性格，意思決定の傾向，説得対象ドメインへの意識，現在の状況など</p>\n<p><strong>事後アンケート</strong></p>\n<p>年齢，性別，学歴，パートナーの有無，政治的見解など</p>\n<p>ERICAへの印象，対話を通じての意識の変化なども用意</p>\n<p><strong>追跡調査</strong></p>\n<p>説得に対して合意した被験者に対して，1週間後にその合意を履行したか追跡調査</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/dff7dc2e-ac34-4c0d-8afd-b67aa4b23d54/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_12.36.33.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181032Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b5242d6f20292003f3291343f480d2a9a974018da79b3fdf1263eddc73552602&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/965310f1-8222-4ee8-95ee-bdac4b6d0543/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_12.36.48.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181035Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=de853bee75b0c6022da54061568c2b716ec0706e7676bc2fece1d06cbb00ff58&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>実際の行動の変容や意識の変容に関わらず，多くの人が対話中に説得へ合意</p>\n<p>→実際に説得が効果的であったかを対話上の振る舞いから判定することは困難</p>\n<p>意識変容から行動変容に映るにはハードルがある</p>\n<p><strong>ロジスティック回帰による説得に有効な要素の分析</strong></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c90376cb-84d8-46c7-ae15-b25ae45cc909/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_12.39.32.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181043Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=ac294c99a83bbd82d4520547829ab4f995ca79f769cc813b81a795096951f231&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fd08dbad-d61d-4c4c-a517-bb399ba5878b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_12.39.59.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181044Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=f64d92176e8b22ddfc8c4d178bd73766ad00a6aa0c0b89530d1fbdd648bbd24e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f039a29b-d9c2-49c6-9a17-1cea74f790f2/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_12.39.47.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181046Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=613877b80accb55d4525bb13caea81b00fd57979bc67d5f038c72badd6560480&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>その他（なぜ通ったか？等）</h2>\n<p>倫理審査が必要らしい</p>\n<p>顔とか映すデータを撮る場合は倫理審査のため，被験者に合意を得る必要がありそう</p>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析","Date":"2023-05-21","Category":"論文","Tags":"dialogue system","Authos":"ゆうぼう","Slug":"遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0f65b1d8-3b8d-4280-9050-d07e6ecf99af/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_12.22.16.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T180954Z&X-Amz-Expires=3600&X-Amz-Signature=dbb31c81f409ca203f601e4c02e7ad5d7b16f314151066284feeecc49e4a9340&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"遠隔操作アンドロイドを用いたマルチモーダル説得対話コーパスの収集と分析のまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>ある文脈において利用可能な知識は一意とは限らず，実際に利用された知識意外にも利用可能な知識は存在する可能性がある</p>\n<p>→　旅行代理店における対話を題材として，基準対話データセットを作成（知識が一意）</p>\n<p>→　基準対話データセットを元にマルチラベル対話データセットを作成（知識が複数対応）</p>\n<p>マルチラベル対話データセットを発話生成モデルの生成に用いると，多様で適切な応答が可能になることが示唆</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5c89f427-8d37-4fc7-8a18-17abc1428558/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_13.04.42.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180924Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=07cdc4b91ced7a9ce9d5bd3af7a85af4d6c94780a488c2e8b7cf42fcb698dda5&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/48a2b666-2dd7-48f5-9828-de0903b767a6/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_13.08.19.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180925Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=e55b0611740be916fc0eece7f9e4e1fa9933fe2d9ed0e01cc582c7046d3f5e41&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><strong>基準対話データセットの構築</strong></p>\n<p>クラウドソーシングを利用して，東京と大阪の観光地441件を対象に，観光地に関する対話おw収集</p>\n<p>知識情報として，基礎情報はじゃらんからスクレイピング，レビュー情報にはGoogle Map APIを用いて取得</p>\n<p>店発話は，知識情報をなるべく用いて発話し，使用できる知識情報源は最大で2つとした</p>\n<p>相槌など知識情報を使用しない発話にはnoneのラベルを付与</p>\n<p><strong>マルチラベルデータセットの構築</strong></p>\n<p>利用していない知識は，「利用できない知識」ではなく「利用していない知識」</p>\n<p>→　基準対話データセットから400件を抽出し，対象の発話において利用可能な知識をアノテーション</p>\n<p>基準対話データセットの分布とマルチラベル対話データセットの分布を比較すると，多くの知識源が利用可能であるとわかる</p>\n<h2>新規性</h2>\n<p>一つの発話に対して複数の知識を対応させたマルチラベル対話データセットを作成</p>\n<h2>実験</h2>\n<p>Laboro製BERTを用いて利用可能な知識情報を選択</p>\n<p>→　TransformerベースのNTT製大規模対話モデルhobbyistを用いて，知識情報を用いた応答生成</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f4f537cb-79a3-4c01-87b5-346171d41cc3/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_13.13.38.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180944Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=c40b6157dd75cee646793743c253dd7fbd5f2009399c721401c0014edfc67565&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>BERTを用いた知識選択</p>\n<p>シングルtestが0.46，マルチtestが0.90</p>\n<p>適切な知識が選択できていれば正解なので，マルチが高くなるのはそれはそう</p>\n<p>マルチラベル対話データセットを使用した応答生成は，全て文脈として正しく，知識を反映した多様かつ適切な生成ができていた</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】知識源との一対多関係を有する対話コーパスによる発話生成","Date":"2023-05-21","Category":"論文","Tags":"dialogue system,knowledge-base","Authos":"ゆうぼう","Slug":"知識源との一対多関係を有する対話コーパスによる発話生成","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d311458d-0126-4027-bb33-27ef23e42db8/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_11.52.48.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T180915Z&X-Amz-Expires=3600&X-Amz-Signature=569edfdc04fd2dc9a2d829f31086e32d08a6ba4af72e43e793c686d3632de7a4&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"知識源との一対多関係を有する対話コーパスによる発話生成のまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>ニューラル文章生成において，文章としては自然だが，内容が事実とは異なる**事実不整合（factual inconsistency）**が問題</p>\n<p>→　BERTを用いて分類タスクをすることで生成文の事実不整合の検出を試みる</p>\n<p>疑似データセットを作成し学習することで，不整合検出におけるドメイン適応の重要性を明らかにした</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1ed54194-49ae-452a-bf7d-f6347059b77d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_11.31.54.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180835Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=3313f664bedc7bbe7770df24928aa928875a8fceda3a3a68226c86a486b594df&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b4af1da4-7869-4522-b00c-01a2ee36936b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_11.32.42.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180836Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=bbc96bd6864d164e79750b72b8df5dcf30bb6d7f70817a46fae2e49769f3ca0a&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>特に数値データに対してロバストなモデルになるよう学習するため，知識に数値が含まれる「料金情報」「アクセス情報」「営業時間情報」の3カテゴリに絞って学習に用いる</p>\n<p>疑似例の作成は数値や日付，駅名等を書き換えることで対応</p>\n<p>料金，アクセス，営業時間情報で書き以下絵対象がお’異なるため，それぞれ小cleanなる改変方法でデータを書き換え</p>\n<h2>新規性</h2>\n<p>旅行ドメインに対して疑似データセットを作成し，それを用いて学習することで，SNLIデータセットを用いた学習に比べて，事実不整合の生成文の検出精度を向上</p>\n<h2>実験</h2>\n<p>データセット</p>\n<p>事実整合性判定学習データセット</p>\n<p>料金，アクセス，営業時間情報について作成した疑似生後売れ，不整合例を集めたデータセット</p>\n<p>ニューラル生成文データセット</p>\n<p>NTT製TransformerのHobbyistを用いて生成した文章を含むデータセット</p>\n<p>Laboro社製BERTをファインチューニング</p>\n<p>ベースラインデータセットとして，日本語SNLIデータセット</p>\n<p>recallが最良のエポックの重みを最良モデルとして評価</p>\n<p>recallが低いモデルは大量の不整合を見逃していることになるため，目的を果たしていないと考えたから</p>\n<h2>まとめ</h2>\n<p>提案手法（疑似例を用いたデータセット）は事実不整合検出に有効である</p>\n<p>正解できなかった不整合例の内訳</p>\n<p>料金7件／アクセス1件／営業時間16件</p>\n<p>→　テンプレートの拡充が必要か？</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】分類モデルBERTによる不整合生成文の検出について","Date":"2023-05-21","Category":"論文","Tags":"dialogue system,NLI","Authos":"ゆうぼう","Slug":"分類モデルBERTによる不整合生成文の検出について","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3dfb04c2-e744-465a-aeed-9cab4ad06729/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_11.31.54.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T180829Z&X-Amz-Expires=3600&X-Amz-Signature=3eb2d8fada149e2992803f25c3b6af6c39cb3b56c227b78ec05b99f4d1fbd5f8&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"分類モデルBERTによる不整合生成文の検出についてのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>文生成時に与えた外部知識と異なる内容の発話文を生成してしまうhallucination errorが課題</p>\n<p>→　hallucination errorを含むデータを疑似的に作成し，BARTやTransformerを用いて事後修正を試みる</p>\n<p>1.6BのTransformerでは52件中29件の事後修正をした</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3bcba150-6a78-45fc-a0dd-97a3e9bad3f1/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_12.22.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180752Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=5d3226c18e48dd146955e5212a9a4fc1ed358a01a53c8391a750534e0971aed0&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>一つの発話文と知識源のペアをテンプレートとして複数のデータを疑似的に作成することで，各知識とカテゴリごとに40000件の発話ぶんと知識源のペアを作成</p>\n<p>→　「営業時間」「アクセス」「料金」に関するエンティティを書き換えることで疑似的なhallcination errorを含んだ文を作成</p>\n<p>ニューラル生成モデルは事実と無関係な文章を生成する場合がある</p>\n<p>→　エンティティの書き換えだけではなく，無関係な発話を含んだデータも作成</p>\n<h2>新規性</h2>\n<p>hallucination errorを含むデータを疑似的に作成することで，ニューラルモデルによる事後修正の試み</p>\n<h2>実験</h2>\n<p>NTT製japanese-dialog-transormers（1.6B）</p>\n<p>黒橋研製日本語BART（0.12B）</p>\n<p>hallucination error修正学習データセットには，無関係な発話を含む（add_unrelated）とそれを含まない（baseline）データセットを二種類用意</p>\n<p>※知識源とHEを[SEP]でつなげるが，普通はBARTは対応していないのでfairseq上ではFusion-in-DecoderをBARTに実装する必要があるらしい</p>\n<p>評価指標</p>\n<p>Faithfulness／BLEU-4 score</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/223a1fa3-9e14-4b32-b4e6-5f1f6acc6fa1/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_12.29.56.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180811Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=5b60d9a3d7e8fabff49e4d4ecef11cfd7d8a58824af9f3b3dbd58d1379797163&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/90a39955-a692-49de-90ab-e275d0be4108/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_12.30.09.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180813Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=25e62e7377d2ceff9df3916c19fc1211f9c7a47de970fe37c73e4c9c56df7c65&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>BLEU-4は「数値が異なる」みたいな単純なhallucination errorは正しく評価できていないのでは？</p>\n<p>BARTとTransformerの大きな精度差はおそらくパラメータ数と事前学習時のデータセットの差なのでは？</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/dad75b6b-e4c4-4958-8398-39670f07754d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_12.32.27.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180817Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=3c83e6b99e2c2f53d465e5a1a543ae074b0888859bf538bbf9ff8ea5fb6c7063&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>知識源に出現するエンティティの順序とモデルの主直に出現するエンティティの順序が同じ</p>\n<p>→　エンティティが出現する順序に注目して書き換えを行っている可能性</p>\n<p>正しくエンティティの関係を理解できていない？</p>\n<p>add_relatedでは発話ぶんにある一文を削除する傾向が見られた</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<p>今後の展望</p>\n<p>HE修正学習データセットの基となるデータの収集</p>\n<p>書き換えルールなど作成方法の拡張の必要性</p>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】Transformerによるhallucination errorの事後修正","Date":"2023-05-21","Category":"論文","Tags":"dialogue system","Authos":"ゆうぼう","Slug":"Transformerによるhallucination-errorの事後修正","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/98a96bf0-24b9-4c30-96f1-71fdf80f43e0/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-24_12.22.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T180746Z&X-Amz-Expires=3600&X-Amz-Signature=bbf7c6af01e3fef28b498a7a1b8804dd2fae7a5bc6a65e9056cfe436b825b7a5&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Transformerによるhallucination errorの事後修正のまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<p>Data State Tracking (以下DST) on Task-Oriented Dialogue Systemに焦点を当てたsurvey</p>\n<h2>Abstract</h2>\n<p>触れること</p>\n<ul>\n<li>タスク</li>\n<li>データセット</li>\n<li>evaluation metrics</li>\n<li>アプローチ</li>\n</ul>\n<p>本論文では，二つのDSTモデルをしっかり区別する．</p>\n<ul>\n<li>static ontology DST models</li>\n<li>固定された対話状況集合を予測する</li>\n<li>dynamic ontology DST models</li>\n<li>オントロジーが変化した時でも対話状況を予測する</li>\n</ul>\n<p>Definition of ontology</p>\n<p>a set of concepts and categories in a subject area or domain that shows their properties and the relations between them.</p>\n<p>単一ドメインでも複数ドメインでもトラックすることや新しいドメインにスケーリングすることのモデルの性能について議論する</p>\n<p>Terms: knowledge transfer, zero-shot learning</p>\n<p>カバーしている年代は2013~2020</p>\n<h2>Introduction</h2>\n<p>Task-oriented dialogue system:</p>\n<p>ユーザーがタスクを成し遂げるようにするシステム</p>\n<p>チケット予約，レストラン予約，カスタマーサポートなど</p>\n<p>ユーザの要求を正確にトラッキングする性能は，一貫していて効果的な対話を可能にする</p>\n<p>対話状況をslot-valueで表現するDSTコンポーネントを使った情報をトラッキングする</p>\n<p>↑この精度がとても重要で，下流のコンポーネントがこの状況を利用して，次のactionを決定する</p>\n<p>DSTタスクは，実際Natural Language Understanding (以下NLU)のタスクを統合している</p>\n<p>ただし，単なるslot filling taskよりも複雑になっている</p>\n<p>DST</p>\n<p>現在のturnまで，対話レベルでslot-valueを予測</p>\n<p>Slot Filling</p>\n<p>特定のturnのみ考慮してslot-valueを予測すれば良い</p>\n<p>モデルとしては以下が提案されている</p>\n<p>RNN-based models</p>\n<p>Attention-based models</p>\n<p>Transformer-based models</p>\n<p>ここ最近では，単一ドメインではなく，マルチドメインやflexibleにドメインの移行をするモデリングの研究が盛んらしい</p>\n<h2>Dialogue State Tracking</h2>\n<p>そもそもDSTとは</p>\n<h3>Dialogue State</h3>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">S_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>: dialogue state</p>\n<p>→turn <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span> までにおける対話履歴のsummary</p>\n<p>次の行動を決定するための全ての十分な情報を含んでいる</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span>   : turn</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mi>l</mi><mi>o</mi><mi>t</mi><mo separator=\"true\">,</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(slot, value)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">e</span><span class=\"mclose\">)</span></span></span></span></span>: このペアで，ユーザの目的を捉える</p>\n<p>slotはOntology <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span> の中で事前に定義されていて (ドメイン依存であるが)，</p>\n<p>valueはユーザによって与えられた各スロット <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi></mrow><annotation encoding=\"application/x-tex\">s</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">s</span></span></span></span></span> で決められる</p>\n<p>レストランの例で言えば</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub><mo>=</mo><mo stretchy=\"false\">{</mo><mo stretchy=\"false\">(</mo><mi>F</mi><mi>O</mi><mi>O</mi><mi>D</mi><mo separator=\"true\">,</mo><mi>I</mi><mi>T</mi><mi>A</mi><mi>L</mi><mi>I</mi><mi>A</mi><mi>N</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mo stretchy=\"false\">(</mo><mi>A</mi><mi>R</mi><mi>E</mi><mi>A</mi><mo separator=\"true\">,</mo><mi>C</mi><mi>E</mi><mi>N</mi><mi>T</mi><mi>R</mi><mi>E</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">s_t = \\{(FOOD, ITALIAN), (AREA, CENTRE)\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">FOO</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">RE</span><span class=\"mord mathnormal\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">CENTRE</span><span class=\"mclose\">)}</span></span></span></span></span>のようになる</p>\n<p>slotのタイプは二つ</p>\n<ol>\n<li>informable</li>\n</ol>\n<p>対話から得られる→FOODやAREA</p>\n<ol start=\"2\">\n<li>requestable</li>\n</ol>\n<p>システムが与える→ADRRESSやPHONE</p>\n<h3>Dialogue State Tracker</h3>\n<ol>\n<li>turn-level prediction</li>\n</ol>\n<p>各ターンで与えられるslot-valueを予測</p>\n<ol start=\"2\">\n<li>dialogue-level prediction</li>\n</ol>\n<p>各ターンでの完全な対話状況を予測</p>\n<h3>Turn-level prediction</h3>\n<p>直近のturn <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span> からslot-valueを予測する</p>\n<p>rule-basedの場合は，そのルールに従って，<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2083em;\"><span></span></span></span></span></span></span></span></span></span></span>に統合して<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>を得る</p>\n<p>turn <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span> を優先したり，</p>\n<p>確率を利用して統合したり</p>\n<p>learning to updateの場合は，turn-levelの予測を入力として，対話状況を予測する方法を学習する</p>\n<h3>Dialogue level prediction</h3>\n<p>各turn <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span> において，完全な対話履歴を入力として，完全な対話状況 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> を予測する</p>\n<p>直前の対話状況 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2083em;\"><span></span></span></span></span></span></span></span></span></span></span> を考慮しないため，<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2083em;\"><span></span></span></span></span></span></span></span></span></span></span>と<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>に一貫性がないこともある</p>\n<h2>Datasets</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a3d38be7-a154-45ca-9eb7-dc64ccd44191/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2021-10-23_12.28.45.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191350Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a0753cedb6d13a8522c86c5501bb53e636fbf1530fc65d0188a455107b863138&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>Dialog State Tracking Challenge (DSTC)</li>\n<li>DSTC2 and DSTC3</li>\n<li>WoZ2.0</li>\n<li>MultiWoZ</li>\n<li>Schema-Guided Dataset (SGD)</li>\n<li>TreeDST</li>\n<li>Machine-to-Machine (M2M)</li>\n</ul>\n<h2>Evaluation Metrics</h2>\n<ul>\n<li>Average Goal Accuracy</li>\n<li>Joint Goal Accuracy</li>\n<li>Requested  Slots F1</li>\n<li>Time Complexity</li>\n</ul>\n<h2>Static Ontology DST Models</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/98ee8408-1d36-4b00-9e5c-86a78778e553/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2021-10-24_10.52.45.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191403Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=7aec3e44279dc3e4c2b405c3bea9d80256b83994ec6d78e4e449a55ed9cffbb0&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>slot-valueは事前に定義されている</p>\n<p>→</p>\n<p>output layerは</p>\n<ul>\n<li>feed-forward layer</li>\n<li>slotとvalueが固定なので，それらはembeddingされているため可能</li>\n<li>softmax</li>\n<li>全てのslot-valueのペアの確率を求める</li>\n<li>sigmoid</li>\n<li>それぞれのslot-valueの確率を求める</li>\n</ul>\n<h3>Delexicalization</h3>\n<p>imbalanced training data for slot-valuesに対処する効果的なアプローチ</p>\n<p>入力のslot valuesをラベルの名前に置き換える</p>\n<p>I want Chinese food.</p>\n<p>→ I want F.VALUE F.SLOT.</p>\n<h3>Data-driven DST</h3>\n<p>delexicalizationは確かに効果的だが，手作業でのfeature engineeringが必要になる</p>\n<p>→ data-drivenな手法が提案された</p>\n<h3>Parameter sharing</h3>\n<p>昔のモデルはslotごとにエンコーダが分かれていた</p>\n<p>→そのため全てのslotに対してパラメータを共有する手法が提案された</p>\n<p>StateNet？</p>\n<h3>RNN and latency in DST</h3>\n<p>予測時間が問題だったため，それに対する対策の提案</p>\n<h3>Encoder based on pre-trained LM</h3>\n<p>BERTなどを使うことで，捕捉できるslot valueが増えた</p>\n<h2>Dynamic Ontology DST Models</h2>\n<p>オントロジーが事前定義されていなくてもslot-valueをトラッキングする必要がある</p>\n<p>アプローチは2種</p>\n<ol>\n<li>ユーザの入力からslot-valueをコピー</li>\n<li>outputにslot-valueを生成</li>\n</ol>\n<p>下図は2種のアプローチを合わせたアーキテクチャ</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d86f101-492b-4c69-a759-25fad9a9c727/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2021-10-24_10.57.18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191430Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=8519f4dbe0ed85eb214206cbb7520c505ed89de7a5775d418de499598145124a&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>static ontology vs dynamic ontology</p>\n<p>staticだとvalueが有限だが，</p>\n<p>dynamicだとoutputの語彙数がとても大きくなる</p>\n<h3>Copy and pointer networks</h3>\n</body>\n</html>\n","Title":"【論文まとめ】Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","survey","DST"],"Authos":"ゆうぼう","Slug":"Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6a13b44c-3197-4abe-af23-58fa95611f92/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.46.56.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T191251Z&X-Amz-Expires=3600&X-Amz-Signature=9b2a7e4b89e04c3c187d51566173e10786404ee4411472534e615545cdb6633e&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Surveyのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<p>Data State Tracking (以下DST) on Task-Oriented Dialogue Systemに焦点を当てたsurvey</p>\n<h2>Abstract</h2>\n<p>触れること</p>\n<ul>\n<li>タスク</li>\n<li>データセット</li>\n<li>evaluation metrics</li>\n<li>アプローチ</li>\n</ul>\n<p>本論文では，二つのDSTモデルをしっかり区別する．</p>\n<ul>\n<li>static ontology DST models</li>\n<li>固定された対話状況集合を予測する</li>\n<li>dynamic ontology DST models</li>\n<li>オントロジーが変化した時でも対話状況を予測する</li>\n</ul>\n<p>Definition of ontology</p>\n<p>a set of concepts and categories in a subject area or domain that shows their properties and the relations between them.</p>\n<p>単一ドメインでも複数ドメインでもトラックすることや新しいドメインにスケーリングすることのモデルの性能について議論する</p>\n<p>Terms: knowledge transfer, zero-shot learning</p>\n<p>カバーしている年代は2013~2020</p>\n<h2>Introduction</h2>\n<p>Task-oriented dialogue system:</p>\n<p>ユーザーがタスクを成し遂げるようにするシステム</p>\n<p>チケット予約，レストラン予約，カスタマーサポートなど</p>\n<p>ユーザの要求を正確にトラッキングする性能は，一貫していて効果的な対話を可能にする</p>\n<p>対話状況をslot-valueで表現するDSTコンポーネントを使った情報をトラッキングする</p>\n<p>↑この精度がとても重要で，下流のコンポーネントがこの状況を利用して，次のactionを決定する</p>\n<p>DSTタスクは，実際Natural Language Understanding (以下NLU)のタスクを統合している</p>\n<p>ただし，単なるslot filling taskよりも複雑になっている</p>\n<p>DST</p>\n<p>現在のturnまで，対話レベルでslot-valueを予測</p>\n<p>Slot Filling</p>\n<p>特定のturnのみ考慮してslot-valueを予測すれば良い</p>\n<p>モデルとしては以下が提案されている</p>\n<p>RNN-based models</p>\n<p>Attention-based models</p>\n<p>Transformer-based models</p>\n<p>ここ最近では，単一ドメインではなく，マルチドメインやflexibleにドメインの移行をするモデリングの研究が盛んらしい</p>\n<h2>Dialogue State Tracking</h2>\n<p>そもそもDSTとは</p>\n<h3>Dialogue State</h3>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">S_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>: dialogue state</p>\n<p>→turn <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span> までにおける対話履歴のsummary</p>\n<p>次の行動を決定するための全ての十分な情報を含んでいる</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span>   : turn</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>s</mi><mi>l</mi><mi>o</mi><mi>t</mi><mo separator=\"true\">,</mo><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(slot, value)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">t</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">e</span><span class=\"mclose\">)</span></span></span></span></span>: このペアで，ユーザの目的を捉える</p>\n<p>slotはOntology <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi></mrow><annotation encoding=\"application/x-tex\">O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span> の中で事前に定義されていて (ドメイン依存であるが)，</p>\n<p>valueはユーザによって与えられた各スロット <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi></mrow><annotation encoding=\"application/x-tex\">s</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">s</span></span></span></span></span> で決められる</p>\n<p>レストランの例で言えば</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub><mo>=</mo><mo stretchy=\"false\">{</mo><mo stretchy=\"false\">(</mo><mi>F</mi><mi>O</mi><mi>O</mi><mi>D</mi><mo separator=\"true\">,</mo><mi>I</mi><mi>T</mi><mi>A</mi><mi>L</mi><mi>I</mi><mi>A</mi><mi>N</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mo stretchy=\"false\">(</mo><mi>A</mi><mi>R</mi><mi>E</mi><mi>A</mi><mo separator=\"true\">,</mo><mi>C</mi><mi>E</mi><mi>N</mi><mi>T</mi><mi>R</mi><mi>E</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">s_t = \\{(FOOD, ITALIAN), (AREA, CENTRE)\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">FOO</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">RE</span><span class=\"mord mathnormal\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">CENTRE</span><span class=\"mclose\">)}</span></span></span></span></span>のようになる</p>\n<p>slotのタイプは二つ</p>\n<ol>\n<li>informable</li>\n</ol>\n<p>対話から得られる→FOODやAREA</p>\n<ol start=\"2\">\n<li>requestable</li>\n</ol>\n<p>システムが与える→ADRRESSやPHONE</p>\n<h3>Dialogue State Tracker</h3>\n<ol>\n<li>turn-level prediction</li>\n</ol>\n<p>各ターンで与えられるslot-valueを予測</p>\n<ol start=\"2\">\n<li>dialogue-level prediction</li>\n</ol>\n<p>各ターンでの完全な対話状況を予測</p>\n<h3>Turn-level prediction</h3>\n<p>直近のturn <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span> からslot-valueを予測する</p>\n<p>rule-basedの場合は，そのルールに従って，<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2083em;\"><span></span></span></span></span></span></span></span></span></span></span>に統合して<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>を得る</p>\n<p>turn <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span> を優先したり，</p>\n<p>確率を利用して統合したり</p>\n<p>learning to updateの場合は，turn-levelの予測を入力として，対話状況を予測する方法を学習する</p>\n<h3>Dialogue level prediction</h3>\n<p>各turn <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6151em;\"></span><span class=\"mord mathnormal\">t</span></span></span></span></span> において，完全な対話履歴を入力として，完全な対話状況 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> を予測する</p>\n<p>直前の対話状況 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2083em;\"><span></span></span></span></span></span></span></span></span></span></span> を考慮しないため，<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">s_{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6389em;vertical-align:-0.2083em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2083em;\"><span></span></span></span></span></span></span></span></span></span></span>と<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>に一貫性がないこともある</p>\n<h2>Datasets</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a3d38be7-a154-45ca-9eb7-dc64ccd44191/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2021-10-23_12.28.45.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182159Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=be99eaffa376611036e3852a993c51417d9054fc0b4c4be95800e3134f000e4e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>Dialog State Tracking Challenge (DSTC)</li>\n<li>DSTC2 and DSTC3</li>\n<li>WoZ2.0</li>\n<li>MultiWoZ</li>\n<li>Schema-Guided Dataset (SGD)</li>\n<li>TreeDST</li>\n<li>Machine-to-Machine (M2M)</li>\n</ul>\n<h2>Evaluation Metrics</h2>\n<ul>\n<li>Average Goal Accuracy</li>\n<li>Joint Goal Accuracy</li>\n<li>Requested  Slots F1</li>\n<li>Time Complexity</li>\n</ul>\n<h2>Static Ontology DST Models</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/98ee8408-1d36-4b00-9e5c-86a78778e553/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2021-10-24_10.52.45.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182211Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2bb62448f566678805c24acd66257c26107c4ea7751669c254cfe7b3dda92772&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>slot-valueは事前に定義されている</p>\n<p>→</p>\n<p>output layerは</p>\n<ul>\n<li>feed-forward layer</li>\n<li>slotとvalueが固定なので，それらはembeddingされているため可能</li>\n<li>softmax</li>\n<li>全てのslot-valueのペアの確率を求める</li>\n<li>sigmoid</li>\n<li>それぞれのslot-valueの確率を求める</li>\n</ul>\n<h3>Delexicalization</h3>\n<p>imbalanced training data for slot-valuesに対処する効果的なアプローチ</p>\n<p>入力のslot valuesをラベルの名前に置き換える</p>\n<p>I want Chinese food.</p>\n<p>→ I want F.VALUE F.SLOT.</p>\n<h3>Data-driven DST</h3>\n<p>delexicalizationは確かに効果的だが，手作業でのfeature engineeringが必要になる</p>\n<p>→ data-drivenな手法が提案された</p>\n<h3>Parameter sharing</h3>\n<p>昔のモデルはslotごとにエンコーダが分かれていた</p>\n<p>→そのため全てのslotに対してパラメータを共有する手法が提案された</p>\n<p>StateNet？</p>\n<h3>RNN and latency in DST</h3>\n<p>予測時間が問題だったため，それに対する対策の提案</p>\n<h3>Encoder based on pre-trained LM</h3>\n<p>BERTなどを使うことで，捕捉できるslot valueが増えた</p>\n<h2>Dynamic Ontology DST Models</h2>\n<p>オントロジーが事前定義されていなくてもslot-valueをトラッキングする必要がある</p>\n<p>アプローチは2種</p>\n<ol>\n<li>ユーザの入力からslot-valueをコピー</li>\n<li>outputにslot-valueを生成</li>\n</ol>\n<p>下図は2種のアプローチを合わせたアーキテクチャ</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d86f101-492b-4c69-a759-25fad9a9c727/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2021-10-24_10.57.18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182238Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a7930e45f7f862a03d3af11a21c6394584c56203546ecd6458f51c3888f48268&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>static ontology vs dynamic ontology</p>\n<p>staticだとvalueが有限だが，</p>\n<p>dynamicだとoutputの語彙数がとても大きくなる</p>\n<h3>Copy and pointer networks</h3>\n</body>\n</html>\n","Title":"【論文まとめ】Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey","Date":"2023-05-21","Category":"論文","Tags":"dialogue system,survey,DST","Authos":"ゆうぼう","Slug":"Recent-Neural-Methods-on-Dialogue-State-Tracking-for-Task-Oriented-Dialogue-Systems-A-Survey","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6a13b44c-3197-4abe-af23-58fa95611f92/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.46.56.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T182049Z&X-Amz-Expires=3600&X-Amz-Signature=2b0d0e3c914b0fdbd1d6d8962774ef2c2250c83acfcf5074b114e8b8f0b2cc52&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Surveyのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/aa30067f-f9eb-4cf6-96d4-1d2afabc0781/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.44.29.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191435Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b8508065b6462781cb38c6579b0bde193d64ccaf9ad7d3ede35d996ea5263e71&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>概要</h2>\n<p>対話システムに関するサーベイ論文</p>\n<p>対話システムはNLPタスクの一種</p>\n<p>研究の価値が高いNLPタスクを多く含むため，対話システムは複雑と言える．</p>\n<p>ここ最近で良い成果をあげているもののほとんどがDL</p>\n<p>メインは，モデルタイプとシステムタイプについて述べられる．</p>\n<p>システムタイプ</p>\n<p>タスク指向型</p>\n<p>オープンドメイン型</p>\n<h3>Keywords</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/75a43002-c16e-4129-8551-46bda6ea0706/_2021-06-04_16.00.31.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191443Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=e94848920c48927eb31baafa662959c72edeb77de55e14ebdfadbf65cce698d5&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h3>サーベイの主張の流れ</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/105a5fb4-3669-4648-95f1-dd44cc94066c/_2021-06-04_16.32.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191444Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=45f4c0ebf02dd94cdd27e15ed57ba41154005f619051ff6879bdf2f0bb49aba2&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>まとめ</h2>\n<h3>Introduction</h3>\n<p>対話システムはNLPにおいてホットな話題であり，産業においても需要が非常に高い．</p>\n<p>タスク指向型とオープンドメイン型の対話システムが存在する．</p>\n<p>昔ながらのタスク指向型は，Natural Language Understanding, Dialogue State Tracking, Policy Learning, Natural Language Generationの4つからなっていた</p>\n<p>⇒</p>\n<p>最近のSoTAモデルでは，E2Eのタスク指向型の対話システムが多い．</p>\n<p>オープンドメイン型</p>\n<ul>\n<li>generative systems</li>\n<li>seq2seqなモデル</li>\n<li>ユーザのメッセージや対話履歴を返答系列にマッピングする(Trainingデータに存在しないであろうものも含む)</li>\n<li>柔軟でコンテクストを読んだ返答をするが，時々主張が一貫しない返答や鈍感で面白くない返答を返す．</li>\n<li>retrieval-based systems (検索)</li>\n<li>返答の集合の中から，すでに存在する適した返答を探す．</li>\n<li>表面上では良い返答をする．ただし，返答集合は有限集合なので，対話上のコンテクストに対しては関係性があまりみられないこともある．</li>\n<li>ensemble systems</li>\n<li>上記二つを含む</li>\n<li>Generatie systemsは検索システムをよくするために使われる．</li>\n<li>検索システムはより適した返答を選ぶために使われる．</li>\n</ul>\n<p>古典的な対話システムとして，finite state-basedとstatistical learningとmachine learning-basedが挙げられる．</p>\n<ul>\n<li>Finite State-based</li>\n<li>対話の流れはあらかじめ決められている</li>\n<li>決まったシナリオの中でしか対応ができない．</li>\n<li>Statistical Learning-based</li>\n<li>Finite State-basedよりは柔軟である．あらかじめ対応が決められていないから．</li>\n<li>machine learning-based</li>\n<li>Deep learningが主流？</li>\n</ul>\n<p>NLPの中には対話システムに近い領域がある．</p>\n<ul>\n<li>Q &#x26; A</li>\n<li>reading comprehension</li>\n<li>dialogue disentanglement</li>\n<li>visual dialogue</li>\n<li>visual Q &#x26; A</li>\n<li>dialogue reasoning</li>\n<li>conversational semantic parsing</li>\n<li>dialogue relation extraction</li>\n<li>dialogue sentiment analysis</li>\n<li>hate speech detection</li>\n<li>MISC detection (???)</li>\n</ul>\n<h3>Neural Models in Dialogue Sustems</h3>\n<ul>\n<li>CNN</li>\n<li>ここ数年NLPの分野での応用も多いらしい</li>\n<li>フレーズや文章，パラグラフには意味づけをするのに有用でCNNがヒラルキーなモデルになる</li>\n<li>CNNは一条に乏しいため，最近のSoTAにおいては，テキストをencoderにかけたのちにCNNを用いてヒエラルキーな特徴抽出を行っている．</li>\n<li>欠点として入力系列の長さは固定長のため以下の使用例</li>\n<li>encoderの出力をCNNでベクトル化</li>\n<li>contextと返答の候補を行列にして，CNNで近さを図ることによって，妥当な候補を選び出す</li>\n<li>基本的にCNNとencoderはセットか？</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/58dce446-317f-44de-b28a-5a87a56cf515/_2021-06-05_11.23.05.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191513Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=6bc537e3550005580ca06e4553ffbc41739129a596031519d065049660f60b3d&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>RNN and Vanilla seq2seq</li>\n<li>系列として扱えるのが利点と考えるべき</li>\n<li>HMMや古典的な系列モデルだと，推論時のアルゴリズムの複雑さや考えるべき状態空間の増大に合わせて行列サイズが大きくなりすぎて，大きな状態空間を必要とするデータには対応しがたい．</li>\n<li>マルコフモデルは限られた条件下においては強力なモデルになりうる．</li>\n<li>RNNは最近では提案されないが，NLPタスクにおいては未だ現役として活躍することもある</li>\n<li>Jordan-Type &#x26; Elman-Type RNN</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/cae115c2-6e35-4005-bd63-95db89df98be/_2021-06-05_11.33.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191518Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=5016541f4000e9dc2982438cb1d375b85bfdf6c36b8884980dd35f0321c94dd1&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>Jordan-Type RNN</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6d08e0be-96d8-4fe0-9ecd-52244da2d741/_2021-06-05_11.34.24.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191518Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=c9028511d8da8446968f8928b0988507076985f4b947ba1bdcba881ddb5423a1&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>最新の隠れ層の状態は，Input_tとOutput_t-1による</p>\n</li>\n<li>\n<p>Elman-Type RNN</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/19f38d19-5587-4770-9cec-a3fd1c555c86/_2021-06-05_11.34.33.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191522Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=332978963e25ffcd7ee50b205920623a673ef592ec2feb11d50f68051be8e327&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>最新の隠れ層の状態は，Input_tとHidden_t-1による</p>\n</li>\n<li>\n<p>いずれにしてもシンプルなRNNは勾配消失か勾配爆発が大抵おこる</p>\n</li>\n<li>\n<p>LSTM</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/982bc260-69ec-4d59-af83-58c60d57e8af/_2021-06-05_11.42.38.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191524Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=7859285f979dd84eb8e7eb5904d20209af06b3fb7c5f8cbeaaa8967911768ce4&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>Gates</p>\n</li>\n<li>\n<p>入力ゲート</p>\n</li>\n<li>\n<p>忘却ゲート</p>\n</li>\n<li>\n<p>出力ゲート</p>\n</li>\n<li>\n<p>GRU; Gated Recurrent Unit</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0a43b79f-ba25-46c0-83b4-d98279ca5a56/_2021-06-05_11.45.48.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191530Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=256bdae3362ad3063d285e188c319101a7b9dd2a6d14f68541533ec6d1250443&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>Gates</p>\n</li>\n<li>\n<p>更新ゲート</p>\n</li>\n<li>\n<p>リセットゲート</p>\n</li>\n<li>\n<p>パラメータが少ないため，</p>\n</li>\n<li>\n<p>早い</p>\n</li>\n<li>\n<p>汎化性がみられる</p>\n</li>\n<li>\n<p>ただし，</p>\n</li>\n<li>\n<p>大きなデータセットには対応しきれないこともある</p>\n</li>\n<li>\n<p>Bi-directional RNN</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f8fd9965-97c5-4172-b042-a0ac1a2c134a/_2021-06-05_11.53.33.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191536Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=5126a5902914816e6fc7a099c2abe2df815b4b8127ea08af5023e1297ce056e4&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>双方向を考慮したRNN</p>\n</li>\n<li>\n<p>seq2seq; Encoder-Decoder model</p>\n</li>\n<li>\n<p>初めは機械翻訳のために提案された手法</p>\n</li>\n<li>\n<p>Encoderにより入力系列をベクトル化，その隠れ状態をDecodeして生成することを目指す</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6a1b161f-2991-4ded-9a60-fe9525addd7b/_2021-06-05_12.00.02.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191539Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=08f0be3a381e90615ae3b44ad4c81c089e67c7575ebe78e567cdd401be15f423&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>Encode時</p>\n</li>\n<li>\n<p>t時刻のinputとt-1時刻のhiddenによって，t時刻のhiddenが決まる</p>\n</li>\n<li>\n<p>Decode時</p>\n</li>\n<li>\n<p>t時刻のhiddenとt-1時刻のoutputによって，t時刻のoutputをデコードする</p>\n</li>\n<li>\n<p>入力系列と出力系列の長さが固定長である必要はない．</p>\n</li>\n<li>\n<p>その代わり，適応させる系列長と出力される系列長は同じになることは保証されない</p>\n</li>\n<li>\n<p>Hierarchical Recurrent Encoder-Decoder; HRED</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/11de7452-73f5-44f0-986b-a3ba68d48cf1/_2021-06-06_12.46.26.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191550Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=6d745c8c7b571815758f6daa6e51af025a1d5215d405e66ba2e0cd2b914d9006&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>コンテクストを理解するためのseq2seqモデル</p>\n</li>\n<li>\n<p>クエリの履歴を理解する？</p>\n</li>\n<li>\n<p>トークンレベルとターンレベルで学習する</p>\n</li>\n<li>\n<p>Memory Networks</p>\n</li>\n<li>\n<p>Attention and Transformer</p>\n</li>\n<li>\n<p>Attention</p>\n</li>\n<li>\n<p>Transformer</p>\n</li>\n<li>\n<p>Muti-head Attention</p>\n</li>\n<li>\n<p>Pointer Net and CopyNet</p>\n</li>\n<li>\n<p>Pointer Net</p>\n</li>\n<li>\n<p>CopyNet</p>\n</li>\n<li>\n<p>Deep RL and GANs</p>\n</li>\n<li>\n<p>Deep Q-Networks</p>\n</li>\n<li>\n<p>REINFORCE</p>\n</li>\n<li>\n<p>GANs</p>\n</li>\n<li>\n<p>Knowledge Graph Augmented Neural Networks</p>\n</li>\n</ul>\n<p>2章は途中から読むのやめた．使用されるネットワークよりも課題感の方が知りたい．</p>\n<h3>タスク指向型対話システム</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d87782bb-ab38-4695-bb98-d8c12a227d1c/_2021-06-06_14.41.55.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191603Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=cfca9b9ac288c978071a2092c25b56926f566fe92a42f2ed46dc74b1e2338a79&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>ドメインの決まったタスクにおいて特定の問題を解決する．</p>\n<ul>\n<li>Natural Language Understanding</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2b964a3d-97f7-4eb0-9bc8-1e83f0458cfb/_2021-06-06_14.47.29.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191605Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=82e7b07a9646b6cda018a2e55aeb1bab6d2b8a313a09e3aa38a4e2c976bad695&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>3つのタスクを持つ</p>\n</li>\n<li>\n<p>ドメイン分類</p>\n</li>\n<li>\n<p>意図の理解</p>\n</li>\n<li>\n<p>スロット埋め</p>\n</li>\n<li>\n<p>IOB; Inside Outside Beginning</p>\n</li>\n<li>\n<p>NER; Named Entity Recognition</p>\n</li>\n<li>\n<p>intent detectionにおいては，Task-Oriented Dialogue BERTがSoTA?</p>\n</li>\n<li>\n<p>Domain classification &#x26; intent detectionは同カテゴリタスク</p>\n</li>\n<li>\n<p>slot filling task = semantic tagging</p>\n</li>\n<li>\n<p>NLUタスクを解く際に，音声データをそのままInputとして与える研究事例も出ているらしい</p>\n</li>\n<li>\n<p>エラーが少なくロバストなモデルになったらしい？</p>\n</li>\n<li>\n<p>Natural Language UnderstandingとNatural Language Generationは逆のプロセスをふむ</p>\n</li>\n<li>\n<p>同時にタスクを学習結果が得られるというアプローチも</p>\n</li>\n<li>\n<p>Dialogue State Tracking</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d8c577f9-1dd9-45a4-a0af-a0801e202e93/_2021-06-07_22.53.27.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191625Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=eba3e594849eab0d81f62035cef9842260ce999557864ccbd1177cc94cdd12c8&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>ユーザの目的と対話履歴を追跡する</p>\n</li>\n<li>\n<p>NLUとDSTのタスクは近い関係にある．</p>\n</li>\n<li>\n<p>NLUは単語にtagを割り振っていくイメージ</p>\n</li>\n<li>\n<p>DSTはtagのplaceholderを会話の内容から埋めていくイメージ</p>\n</li>\n<li>\n<p>Dialogue Stateには3つの要素からなる</p>\n</li>\n<li>\n<p>Goal constraint corresponding with informable slots</p>\n</li>\n<li>\n<p>特別なvalueの制約で，ユーザによって言及されるか特別な値をとる</p>\n</li>\n<li>\n<p>DontcareやNoneが特別な値にあたる</p>\n</li>\n<li>\n<p>Requested slots</p>\n</li>\n<li>\n<p>Search method of current turn</p>\n</li>\n<li>\n<p>古典的な手法でいくと，</p>\n</li>\n<li>\n<p>ルールベースはエラーが多く，ドメイン適応が大変</p>\n</li>\n<li>\n<p>統計的手法はノイジーな状態や曖昧性に弱い</p>\n</li>\n<li>\n<p>ニューラルネットな手法</p>\n</li>\n<li>\n<p>slot-valueのペアを事前定義して学習</p>\n</li>\n<li>\n<p>valueが大きくなると複雑性が増す</p>\n</li>\n<li>\n<p>slot-valueのペアを読むだけでよく，2値分類タスクとして解ける</p>\n</li>\n<li>\n<p>モデルの複雑性は避けられるが，反応速度が遅くなる可能性がある．</p>\n</li>\n<li>\n<p>slot-valueのペアを定義せずに，対話の中から直接選ぶ</p>\n</li>\n<li>\n<p>Policy Learning</p>\n</li>\n<li>\n<p>DSTモジュールの出力結果からどう行動をとるか</p>\n</li>\n<li>\n<p>教師あり学習or 強化学習</p>\n</li>\n<li>\n<p>教師ありだとアノテショーンデータセットを作るのがとても大変</p>\n</li>\n<li>\n<p>Natural Language Generation; NLG</p>\n</li>\n<li>\n<p>タスク指向型対話システムにおける最終層のモジュール</p>\n</li>\n<li>\n<p>最終的な自然言語表現を生成するシステム</p>\n</li>\n<li>\n<p>4つのコンポーネントからなる</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/02db3490-606b-40f7-9829-086aaf7a96fd/Screenshot_from_2021-06-08_09-06-59.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191641Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=daf8946897d3a4043baec8b97119fb810a5cac803a24f98f20f806f9e91c3fb8&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>Content Determination</p>\n</li>\n<li>\n<p>Sentence Planning</p>\n</li>\n<li>\n<p>Surface Realization</p>\n</li>\n<li>\n<p>Lexicalization, Referring expression, aggregation</p>\n</li>\n<li>\n<p>RNNに基づいた統計言語モデルにおいて，意味的制約や文法構造による返答生成を行うなど</p>\n</li>\n<li>\n<p>コンテクストを理解した返答を生成することは重要である</p>\n</li>\n<li>\n<p>タスク指向型においては，返答の多様性というよりも信頼性のほうが重要視されがち</p>\n</li>\n<li>\n<p>意味解析をビームサーチを使うことで，意味の正しさを改善する手法も提案された</p>\n</li>\n<li>\n<p>E2E Methods</p>\n</li>\n<li>\n<p>end-to-endのパイプラインを組むことで高いパフォーマンスを発揮することがあるが，</p>\n</li>\n<li>\n<p>多くのモジュールを組み込むため，バックプロパゲーションで誤差が伝播しないこともある．</p>\n</li>\n<li>\n<p>すべてのモジュールが，返答の精度を向上するために，対等に重要であるとは限らない．</p>\n</li>\n<li>\n<p>違うドメインに差し替えるとき，オントロジーを事前学習させる必要があるため，困難が生じることもある</p>\n</li>\n<li>\n<p>やり方は大きく分けて2つ</p>\n</li>\n<li>\n<p>すべてのモジュールを展開して誤差逆伝播させる？</p>\n</li>\n<li>\n<p>知識ベースの検索システムと返答生成の双方を用いてパイプラインを組む</p>\n</li>\n<li>\n<p>タスク指向型においては，外部の知識源が必要なことが多い</p>\n</li>\n</ul>\n<h3>オープンドメイン型対話システム</h3>\n<ul>\n<li>雑談対話システム，或いはタスク思考型ではない対話システムのこと</li>\n<li>SoTAを示しているオープンドメインは大抵ニューラルネットで解決している</li>\n<li>完全なるデータドリブンなものが多い</li>\n<li>オープンドメイン型対話システムは，大まか3つに分けられる</li>\n<li>生成システム</li>\n<li>検索ベースシステム</li>\n<li>アンサンブルシステム</li>\n</ul>\n<p>３つの話が以下</p>\n<ul>\n<li>生成システム</li>\n<li>訓練コーパスに出てこないような返答に対して，ユーザのメッセージや対話履歴をマッピングするために，seq2seqなモデルを適用する</li>\n<li>検索システム</li>\n<li>決まった返答集合の中からすでに存在する返答を探そうとする</li>\n<li>アンサンブルシステム</li>\n<li>生成手法と検索手法を合わせる．</li>\n<li>生成された返答と検索された返答とを比べる．</li>\n<li>生成も，検索された返答を洗練するために用いられる．</li>\n</ul>\n<p>特徴として，</p>\n<p>生成モデルは</p>\n<p>柔軟でコンテクストを読んだ返答をできるが，ときには理解に欠けていたり，怠けた返答を見せることがある</p>\n<p>検索ベースのモデルは</p>\n<p>人の返答の集合から実際の返答を選ぶため，返答の集合は有限集合であり，コンテクストと相関がないことがある．</p>\n<p>ただし，表面上のレベルでは，首尾一貫した返答することも多い</p>\n<p>以下は，オープンドメイン型対話システムにおける，難しさとホットなトピックをまとめる</p>\n<ul>\n<li>Context Awareness</li>\n<li>対話コンテクストは会話のトピックを決定したり，ユーザの目標を決定したりと重要</li>\n<li>コンテクストを解釈した対話エージェントは，現メッセージだけではなく，対話履歴からももとにして返答する</li>\n<li>生成モデルも検索ベースも，どちらも対話コンテクストモデリングに依存する</li>\n<li>いくつかのモデルではAttentionが使用されているらしい</li>\n<li>構造化されたAttentionを用いることでコンテクストを読み取れる？</li>\n<li>対話をリライトする問題があるらしい</li>\n<li>複数のメッセージから単一のメッセージに変換する目標</li>\n<li>ここではコンテクストを理解させることが重要</li>\n<li>Response Coherence</li>\n<li>首尾一貫した返答は，良い生成器としての一つのクオリティ</li>\n<li>対話の中で，論理的で首尾一貫しているか？という指標</li>\n<li>生成モデルにおいてホットなトピックとなっている（検索ベースはすでに人の返答をりようするのでもともと一貫性はあるという主張）</li>\n<li>一貫性のない文の順序を見つけるタスクを解くことで，返答の一貫性を改善した事例もあり</li>\n<li>Response Diversity</li>\n<li>人が多用するような表現は訓練コーパスにも多く含まれ，それらばかりを返答してしまうことが問題となりうる</li>\n<li>かつては条件付き確率において，尤度関数を解くことで尤もらしい返答をもとめていた．</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/80c38282-ca52-417c-bed3-bb37c143e388/Screenshot_from_2021-06-09_14-58-59.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191718Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=d551c743533af1f087c6d32bd8306373a7eb7c35e46d654b1a63a6a329176a2d&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>この手法では，返答の精度の安全性と適切さはトレードオフになっていた？</li>\n<li>ビームサーチを提案されたことも</li>\n<li></li>\n<li>Speaker Consistency and Personality-based Response</li>\n<li>システムは，訓練コーパスからサンプリングされた分布に対して学習</li>\n<li>対話者の趣味といった一貫性のないものに対する返答は．．．</li>\n<li>対話者の役割を理解し，その個人に合わせた返答が必要になる</li>\n<li>1ステージではなく，3ステージで個人的な嗜好に対応した事例がある</li>\n<li></li>\n<li>Empathetic Response</li>\n<li>同情する対話システムは，ユーザの感情の変化や感情に伴った適切な返答をする</li>\n<li>雑談チャットについて，このトピックは重要</li>\n<li>CortanaやAlexaなどの製品にもモジュールが含まれている</li>\n<li>CoBERTのモデルなど</li>\n<li>感情対話システムのデータセットはとぼしいが，新たなデータセットとベンチマークが提供されたらしい</li>\n<li></li>\n<li>Conversation Topics</li>\n<li>トピックや目的は，会話に参加した人と会話を続けるための重要な役割を果たす</li>\n<li>トピックを理解させることが重要</li>\n<li></li>\n<li>Knowledge-Grounded System</li>\n<li>人は，会話のコンテクストと経験や記憶といったものとを関連付けて，返答をする（機会には難しい）</li>\n<li>生成モデルは，単なる機械翻訳よりも複雑</li>\n<li>より自由度が高く，制約が曖昧なため</li>\n<li>故に，雑談チャットは，外部から得られる常識と結びつけて，seq2seqなモデルによって生成する</li>\n<li>メモリーネットワークなどで，知識をグラウンディングする手法</li>\n<li>知識グラフは外部の情報をソースにするものもある．</li>\n<li>graph attentionを用いて，常識をグラフベースで学習する手法も</li>\n<li>主な考え方は，外部の知識グラフを使って，会話の論理の流れをモデリングする指標の一部として扱う</li>\n<li>Interactive Training</li>\n<li>別名；human-in-loop training</li>\n<li>アノテーションされたデータセットは限られている</li>\n<li>すべての状況をカバーすることは不可能</li>\n<li>ユーザとの対話の中で，システムを改善する</li>\n<li>強化学習における逐次学習を提案</li>\n<li>対話相手と話して，その相手からフィードバックを得る</li>\n<li>教師あり学習をした後，Interactive Trainingによってファインチューニングする</li>\n<li></li>\n<li>Visual Dialogue</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/024f212d-df8b-4569-a3f2-fe899fa0b606/Screenshot_from_2021-06-09_16-35-24.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191745Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=dbd8d7a1049d776a7d59cf1f8c30c0cec9d59a9bc0444e5e8202effaa77d26d2&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>Visual Q &#x26; Aなど</li>\n<li>画像あり対話システムのほか，映像あり対話システムも面白いトピックだが難題でもある</li>\n<li>特徴量抽出の複雑さも増す</li>\n<li>visual dialogueのアノテーションは重労働であり，データセットに乏しいので，現在はデータの不十分さに悩まされている</li>\n<li></li>\n</ul>\n<h3>評価のアプローチ</h3>\n<p>評価の仕方も重要なパートとなっている</p>\n</body>\n</html>\n","Title":"【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey","Date":"2023-05-21","Category":"論文","Tags":["survey","dialogue system"],"Authos":"ゆうぼう","Slug":"Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b6eb260b-8c7f-4cb6-877b-7844cd677787/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.44.29.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T191435Z&X-Amz-Expires=3600&X-Amz-Signature=a82d605c98b6b29a684818a69c5b5e0d32b8b80ae0b5428bfd5c2eeedaae014e&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Surveyのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/aa30067f-f9eb-4cf6-96d4-1d2afabc0781/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.44.29.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182246Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=7cfa5ccd280b4d86cbeb36260517c11653586aa725457d32830bb7e4c9873470&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>概要</h2>\n<p>対話システムに関するサーベイ論文</p>\n<p>対話システムはNLPタスクの一種</p>\n<p>研究の価値が高いNLPタスクを多く含むため，対話システムは複雑と言える．</p>\n<p>ここ最近で良い成果をあげているもののほとんどがDL</p>\n<p>メインは，モデルタイプとシステムタイプについて述べられる．</p>\n<p>システムタイプ</p>\n<p>タスク指向型</p>\n<p>オープンドメイン型</p>\n<h3>Keywords</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/75a43002-c16e-4129-8551-46bda6ea0706/_2021-06-04_16.00.31.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182256Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b3305959cc681102e8d027a66aceecdf9bdc7be556eff50dc8ff76970f7135ad&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h3>サーベイの主張の流れ</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/105a5fb4-3669-4648-95f1-dd44cc94066c/_2021-06-04_16.32.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182301Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2965cafe1b6130fe1862f6b5736daf7ffe4c0aa530732e9ca4c4227eeb14a7f1&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>まとめ</h2>\n<h3>Introduction</h3>\n<p>対話システムはNLPにおいてホットな話題であり，産業においても需要が非常に高い．</p>\n<p>タスク指向型とオープンドメイン型の対話システムが存在する．</p>\n<p>昔ながらのタスク指向型は，Natural Language Understanding, Dialogue State Tracking, Policy Learning, Natural Language Generationの4つからなっていた</p>\n<p>⇒</p>\n<p>最近のSoTAモデルでは，E2Eのタスク指向型の対話システムが多い．</p>\n<p>オープンドメイン型</p>\n<ul>\n<li>generative systems</li>\n<li>seq2seqなモデル</li>\n<li>ユーザのメッセージや対話履歴を返答系列にマッピングする(Trainingデータに存在しないであろうものも含む)</li>\n<li>柔軟でコンテクストを読んだ返答をするが，時々主張が一貫しない返答や鈍感で面白くない返答を返す．</li>\n<li>retrieval-based systems (検索)</li>\n<li>返答の集合の中から，すでに存在する適した返答を探す．</li>\n<li>表面上では良い返答をする．ただし，返答集合は有限集合なので，対話上のコンテクストに対しては関係性があまりみられないこともある．</li>\n<li>ensemble systems</li>\n<li>上記二つを含む</li>\n<li>Generatie systemsは検索システムをよくするために使われる．</li>\n<li>検索システムはより適した返答を選ぶために使われる．</li>\n</ul>\n<p>古典的な対話システムとして，finite state-basedとstatistical learningとmachine learning-basedが挙げられる．</p>\n<ul>\n<li>Finite State-based</li>\n<li>対話の流れはあらかじめ決められている</li>\n<li>決まったシナリオの中でしか対応ができない．</li>\n<li>Statistical Learning-based</li>\n<li>Finite State-basedよりは柔軟である．あらかじめ対応が決められていないから．</li>\n<li>machine learning-based</li>\n<li>Deep learningが主流？</li>\n</ul>\n<p>NLPの中には対話システムに近い領域がある．</p>\n<ul>\n<li>Q &#x26; A</li>\n<li>reading comprehension</li>\n<li>dialogue disentanglement</li>\n<li>visual dialogue</li>\n<li>visual Q &#x26; A</li>\n<li>dialogue reasoning</li>\n<li>conversational semantic parsing</li>\n<li>dialogue relation extraction</li>\n<li>dialogue sentiment analysis</li>\n<li>hate speech detection</li>\n<li>MISC detection (???)</li>\n</ul>\n<h3>Neural Models in Dialogue Sustems</h3>\n<ul>\n<li>CNN</li>\n<li>ここ数年NLPの分野での応用も多いらしい</li>\n<li>フレーズや文章，パラグラフには意味づけをするのに有用でCNNがヒラルキーなモデルになる</li>\n<li>CNNは一条に乏しいため，最近のSoTAにおいては，テキストをencoderにかけたのちにCNNを用いてヒエラルキーな特徴抽出を行っている．</li>\n<li>欠点として入力系列の長さは固定長のため以下の使用例</li>\n<li>encoderの出力をCNNでベクトル化</li>\n<li>contextと返答の候補を行列にして，CNNで近さを図ることによって，妥当な候補を選び出す</li>\n<li>基本的にCNNとencoderはセットか？</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/58dce446-317f-44de-b28a-5a87a56cf515/_2021-06-05_11.23.05.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182353Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=f7247f748421b5e32e1e063676affc2497fd239429c4390442cf414e2c267447&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>RNN and Vanilla seq2seq</li>\n<li>系列として扱えるのが利点と考えるべき</li>\n<li>HMMや古典的な系列モデルだと，推論時のアルゴリズムの複雑さや考えるべき状態空間の増大に合わせて行列サイズが大きくなりすぎて，大きな状態空間を必要とするデータには対応しがたい．</li>\n<li>マルコフモデルは限られた条件下においては強力なモデルになりうる．</li>\n<li>RNNは最近では提案されないが，NLPタスクにおいては未だ現役として活躍することもある</li>\n<li>Jordan-Type &#x26; Elman-Type RNN</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/cae115c2-6e35-4005-bd63-95db89df98be/_2021-06-05_11.33.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182401Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=94e55034b5d8706a2daf534ed82d377d175ed2fc38fb5c9931cc9592e496a513&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>Jordan-Type RNN</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6d08e0be-96d8-4fe0-9ecd-52244da2d741/_2021-06-05_11.34.24.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182403Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=455bd2b58fa62e6afb8910dbd1a973a6bbea6be4554b617d5b195e74b0e3e409&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>最新の隠れ層の状態は，Input_tとOutput_t-1による</p>\n</li>\n<li>\n<p>Elman-Type RNN</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/19f38d19-5587-4770-9cec-a3fd1c555c86/_2021-06-05_11.34.33.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182406Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=62602f1d34c76e36464bfefa0b27f54720de130dc14877eb671c76c204510bee&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>最新の隠れ層の状態は，Input_tとHidden_t-1による</p>\n</li>\n<li>\n<p>いずれにしてもシンプルなRNNは勾配消失か勾配爆発が大抵おこる</p>\n</li>\n<li>\n<p>LSTM</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/982bc260-69ec-4d59-af83-58c60d57e8af/_2021-06-05_11.42.38.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182409Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=8d9e3ffcc008514085376acee0f638c28808cfd6de0c710d7b3cd8c8f6d3894f&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>Gates</p>\n</li>\n<li>\n<p>入力ゲート</p>\n</li>\n<li>\n<p>忘却ゲート</p>\n</li>\n<li>\n<p>出力ゲート</p>\n</li>\n<li>\n<p>GRU; Gated Recurrent Unit</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0a43b79f-ba25-46c0-83b4-d98279ca5a56/_2021-06-05_11.45.48.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182417Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b35f12cd17bb65d7d75955b74f3e36e2d6a744f25a53207e1328ff9662adc6b8&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>Gates</p>\n</li>\n<li>\n<p>更新ゲート</p>\n</li>\n<li>\n<p>リセットゲート</p>\n</li>\n<li>\n<p>パラメータが少ないため，</p>\n</li>\n<li>\n<p>早い</p>\n</li>\n<li>\n<p>汎化性がみられる</p>\n</li>\n<li>\n<p>ただし，</p>\n</li>\n<li>\n<p>大きなデータセットには対応しきれないこともある</p>\n</li>\n<li>\n<p>Bi-directional RNN</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f8fd9965-97c5-4172-b042-a0ac1a2c134a/_2021-06-05_11.53.33.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182424Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=7057989f26331721a206c218ab237bb45faddd62dacdacaac8a22a25094eb19a&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>双方向を考慮したRNN</p>\n</li>\n<li>\n<p>seq2seq; Encoder-Decoder model</p>\n</li>\n<li>\n<p>初めは機械翻訳のために提案された手法</p>\n</li>\n<li>\n<p>Encoderにより入力系列をベクトル化，その隠れ状態をDecodeして生成することを目指す</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6a1b161f-2991-4ded-9a60-fe9525addd7b/_2021-06-05_12.00.02.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182429Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=f3bb91d84517ccc4e66d3c3c20dd9ed1d427d33316e462b0bc040e7601264319&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>Encode時</p>\n</li>\n<li>\n<p>t時刻のinputとt-1時刻のhiddenによって，t時刻のhiddenが決まる</p>\n</li>\n<li>\n<p>Decode時</p>\n</li>\n<li>\n<p>t時刻のhiddenとt-1時刻のoutputによって，t時刻のoutputをデコードする</p>\n</li>\n<li>\n<p>入力系列と出力系列の長さが固定長である必要はない．</p>\n</li>\n<li>\n<p>その代わり，適応させる系列長と出力される系列長は同じになることは保証されない</p>\n</li>\n<li>\n<p>Hierarchical Recurrent Encoder-Decoder; HRED</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/11de7452-73f5-44f0-986b-a3ba68d48cf1/_2021-06-06_12.46.26.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182441Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a1fd63b17e73624687fe6c8eed1fc67b061ec8fa8aba43747a7bcd1a9a3c3ab1&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>コンテクストを理解するためのseq2seqモデル</p>\n</li>\n<li>\n<p>クエリの履歴を理解する？</p>\n</li>\n<li>\n<p>トークンレベルとターンレベルで学習する</p>\n</li>\n<li>\n<p>Memory Networks</p>\n</li>\n<li>\n<p>Attention and Transformer</p>\n</li>\n<li>\n<p>Attention</p>\n</li>\n<li>\n<p>Transformer</p>\n</li>\n<li>\n<p>Muti-head Attention</p>\n</li>\n<li>\n<p>Pointer Net and CopyNet</p>\n</li>\n<li>\n<p>Pointer Net</p>\n</li>\n<li>\n<p>CopyNet</p>\n</li>\n<li>\n<p>Deep RL and GANs</p>\n</li>\n<li>\n<p>Deep Q-Networks</p>\n</li>\n<li>\n<p>REINFORCE</p>\n</li>\n<li>\n<p>GANs</p>\n</li>\n<li>\n<p>Knowledge Graph Augmented Neural Networks</p>\n</li>\n</ul>\n<p>2章は途中から読むのやめた．使用されるネットワークよりも課題感の方が知りたい．</p>\n<h3>タスク指向型対話システム</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d87782bb-ab38-4695-bb98-d8c12a227d1c/_2021-06-06_14.41.55.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182508Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=4f3bcb06143762ceb21a47e5511d276caaf5d3643311a9701531c427d5d0f45c&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>ドメインの決まったタスクにおいて特定の問題を解決する．</p>\n<ul>\n<li>Natural Language Understanding</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2b964a3d-97f7-4eb0-9bc8-1e83f0458cfb/_2021-06-06_14.47.29.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182513Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=0e5806ac31bf2f9fd619c2b1c397aa3118a85239d68c372d3b00f8f763a80233&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>3つのタスクを持つ</p>\n</li>\n<li>\n<p>ドメイン分類</p>\n</li>\n<li>\n<p>意図の理解</p>\n</li>\n<li>\n<p>スロット埋め</p>\n</li>\n<li>\n<p>IOB; Inside Outside Beginning</p>\n</li>\n<li>\n<p>NER; Named Entity Recognition</p>\n</li>\n<li>\n<p>intent detectionにおいては，Task-Oriented Dialogue BERTがSoTA?</p>\n</li>\n<li>\n<p>Domain classification &#x26; intent detectionは同カテゴリタスク</p>\n</li>\n<li>\n<p>slot filling task = semantic tagging</p>\n</li>\n<li>\n<p>NLUタスクを解く際に，音声データをそのままInputとして与える研究事例も出ているらしい</p>\n</li>\n<li>\n<p>エラーが少なくロバストなモデルになったらしい？</p>\n</li>\n<li>\n<p>Natural Language UnderstandingとNatural Language Generationは逆のプロセスをふむ</p>\n</li>\n<li>\n<p>同時にタスクを学習結果が得られるというアプローチも</p>\n</li>\n<li>\n<p>Dialogue State Tracking</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d8c577f9-1dd9-45a4-a0af-a0801e202e93/_2021-06-07_22.53.27.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182526Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=7eb74a0587b20a8544ba51c90acd3aadead1eb1ab21d6810f113784f3c208fbd&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>ユーザの目的と対話履歴を追跡する</p>\n</li>\n<li>\n<p>NLUとDSTのタスクは近い関係にある．</p>\n</li>\n<li>\n<p>NLUは単語にtagを割り振っていくイメージ</p>\n</li>\n<li>\n<p>DSTはtagのplaceholderを会話の内容から埋めていくイメージ</p>\n</li>\n<li>\n<p>Dialogue Stateには3つの要素からなる</p>\n</li>\n<li>\n<p>Goal constraint corresponding with informable slots</p>\n</li>\n<li>\n<p>特別なvalueの制約で，ユーザによって言及されるか特別な値をとる</p>\n</li>\n<li>\n<p>DontcareやNoneが特別な値にあたる</p>\n</li>\n<li>\n<p>Requested slots</p>\n</li>\n<li>\n<p>Search method of current turn</p>\n</li>\n<li>\n<p>古典的な手法でいくと，</p>\n</li>\n<li>\n<p>ルールベースはエラーが多く，ドメイン適応が大変</p>\n</li>\n<li>\n<p>統計的手法はノイジーな状態や曖昧性に弱い</p>\n</li>\n<li>\n<p>ニューラルネットな手法</p>\n</li>\n<li>\n<p>slot-valueのペアを事前定義して学習</p>\n</li>\n<li>\n<p>valueが大きくなると複雑性が増す</p>\n</li>\n<li>\n<p>slot-valueのペアを読むだけでよく，2値分類タスクとして解ける</p>\n</li>\n<li>\n<p>モデルの複雑性は避けられるが，反応速度が遅くなる可能性がある．</p>\n</li>\n<li>\n<p>slot-valueのペアを定義せずに，対話の中から直接選ぶ</p>\n</li>\n<li>\n<p>Policy Learning</p>\n</li>\n<li>\n<p>DSTモジュールの出力結果からどう行動をとるか</p>\n</li>\n<li>\n<p>教師あり学習or 強化学習</p>\n</li>\n<li>\n<p>教師ありだとアノテショーンデータセットを作るのがとても大変</p>\n</li>\n<li>\n<p>Natural Language Generation; NLG</p>\n</li>\n<li>\n<p>タスク指向型対話システムにおける最終層のモジュール</p>\n</li>\n<li>\n<p>最終的な自然言語表現を生成するシステム</p>\n</li>\n<li>\n<p>4つのコンポーネントからなる</p>\n</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/02db3490-606b-40f7-9829-086aaf7a96fd/Screenshot_from_2021-06-08_09-06-59.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182554Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=844042ae8ee41b5fd519f5bd488f9ad44c7c308d07c8160e6fc185d11c590ed8&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>\n<p>Content Determination</p>\n</li>\n<li>\n<p>Sentence Planning</p>\n</li>\n<li>\n<p>Surface Realization</p>\n</li>\n<li>\n<p>Lexicalization, Referring expression, aggregation</p>\n</li>\n<li>\n<p>RNNに基づいた統計言語モデルにおいて，意味的制約や文法構造による返答生成を行うなど</p>\n</li>\n<li>\n<p>コンテクストを理解した返答を生成することは重要である</p>\n</li>\n<li>\n<p>タスク指向型においては，返答の多様性というよりも信頼性のほうが重要視されがち</p>\n</li>\n<li>\n<p>意味解析をビームサーチを使うことで，意味の正しさを改善する手法も提案された</p>\n</li>\n<li>\n<p>E2E Methods</p>\n</li>\n<li>\n<p>end-to-endのパイプラインを組むことで高いパフォーマンスを発揮することがあるが，</p>\n</li>\n<li>\n<p>多くのモジュールを組み込むため，バックプロパゲーションで誤差が伝播しないこともある．</p>\n</li>\n<li>\n<p>すべてのモジュールが，返答の精度を向上するために，対等に重要であるとは限らない．</p>\n</li>\n<li>\n<p>違うドメインに差し替えるとき，オントロジーを事前学習させる必要があるため，困難が生じることもある</p>\n</li>\n<li>\n<p>やり方は大きく分けて2つ</p>\n</li>\n<li>\n<p>すべてのモジュールを展開して誤差逆伝播させる？</p>\n</li>\n<li>\n<p>知識ベースの検索システムと返答生成の双方を用いてパイプラインを組む</p>\n</li>\n<li>\n<p>タスク指向型においては，外部の知識源が必要なことが多い</p>\n</li>\n</ul>\n<h3>オープンドメイン型対話システム</h3>\n<ul>\n<li>雑談対話システム，或いはタスク思考型ではない対話システムのこと</li>\n<li>SoTAを示しているオープンドメインは大抵ニューラルネットで解決している</li>\n<li>完全なるデータドリブンなものが多い</li>\n<li>オープンドメイン型対話システムは，大まか3つに分けられる</li>\n<li>生成システム</li>\n<li>検索ベースシステム</li>\n<li>アンサンブルシステム</li>\n</ul>\n<p>３つの話が以下</p>\n<ul>\n<li>生成システム</li>\n<li>訓練コーパスに出てこないような返答に対して，ユーザのメッセージや対話履歴をマッピングするために，seq2seqなモデルを適用する</li>\n<li>検索システム</li>\n<li>決まった返答集合の中からすでに存在する返答を探そうとする</li>\n<li>アンサンブルシステム</li>\n<li>生成手法と検索手法を合わせる．</li>\n<li>生成された返答と検索された返答とを比べる．</li>\n<li>生成も，検索された返答を洗練するために用いられる．</li>\n</ul>\n<p>特徴として，</p>\n<p>生成モデルは</p>\n<p>柔軟でコンテクストを読んだ返答をできるが，ときには理解に欠けていたり，怠けた返答を見せることがある</p>\n<p>検索ベースのモデルは</p>\n<p>人の返答の集合から実際の返答を選ぶため，返答の集合は有限集合であり，コンテクストと相関がないことがある．</p>\n<p>ただし，表面上のレベルでは，首尾一貫した返答することも多い</p>\n<p>以下は，オープンドメイン型対話システムにおける，難しさとホットなトピックをまとめる</p>\n<ul>\n<li>Context Awareness</li>\n<li>対話コンテクストは会話のトピックを決定したり，ユーザの目標を決定したりと重要</li>\n<li>コンテクストを解釈した対話エージェントは，現メッセージだけではなく，対話履歴からももとにして返答する</li>\n<li>生成モデルも検索ベースも，どちらも対話コンテクストモデリングに依存する</li>\n<li>いくつかのモデルではAttentionが使用されているらしい</li>\n<li>構造化されたAttentionを用いることでコンテクストを読み取れる？</li>\n<li>対話をリライトする問題があるらしい</li>\n<li>複数のメッセージから単一のメッセージに変換する目標</li>\n<li>ここではコンテクストを理解させることが重要</li>\n<li>Response Coherence</li>\n<li>首尾一貫した返答は，良い生成器としての一つのクオリティ</li>\n<li>対話の中で，論理的で首尾一貫しているか？という指標</li>\n<li>生成モデルにおいてホットなトピックとなっている（検索ベースはすでに人の返答をりようするのでもともと一貫性はあるという主張）</li>\n<li>一貫性のない文の順序を見つけるタスクを解くことで，返答の一貫性を改善した事例もあり</li>\n<li>Response Diversity</li>\n<li>人が多用するような表現は訓練コーパスにも多く含まれ，それらばかりを返答してしまうことが問題となりうる</li>\n<li>かつては条件付き確率において，尤度関数を解くことで尤もらしい返答をもとめていた．</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/80c38282-ca52-417c-bed3-bb37c143e388/Screenshot_from_2021-06-09_14-58-59.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182656Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a703b05e266c9d9ccd1f603ef60f64496d030d622fb03cf9dc2ff6ecbae87b88&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>この手法では，返答の精度の安全性と適切さはトレードオフになっていた？</li>\n<li>ビームサーチを提案されたことも</li>\n<li></li>\n<li>Speaker Consistency and Personality-based Response</li>\n<li>システムは，訓練コーパスからサンプリングされた分布に対して学習</li>\n<li>対話者の趣味といった一貫性のないものに対する返答は．．．</li>\n<li>対話者の役割を理解し，その個人に合わせた返答が必要になる</li>\n<li>1ステージではなく，3ステージで個人的な嗜好に対応した事例がある</li>\n<li></li>\n<li>Empathetic Response</li>\n<li>同情する対話システムは，ユーザの感情の変化や感情に伴った適切な返答をする</li>\n<li>雑談チャットについて，このトピックは重要</li>\n<li>CortanaやAlexaなどの製品にもモジュールが含まれている</li>\n<li>CoBERTのモデルなど</li>\n<li>感情対話システムのデータセットはとぼしいが，新たなデータセットとベンチマークが提供されたらしい</li>\n<li></li>\n<li>Conversation Topics</li>\n<li>トピックや目的は，会話に参加した人と会話を続けるための重要な役割を果たす</li>\n<li>トピックを理解させることが重要</li>\n<li></li>\n<li>Knowledge-Grounded System</li>\n<li>人は，会話のコンテクストと経験や記憶といったものとを関連付けて，返答をする（機会には難しい）</li>\n<li>生成モデルは，単なる機械翻訳よりも複雑</li>\n<li>より自由度が高く，制約が曖昧なため</li>\n<li>故に，雑談チャットは，外部から得られる常識と結びつけて，seq2seqなモデルによって生成する</li>\n<li>メモリーネットワークなどで，知識をグラウンディングする手法</li>\n<li>知識グラフは外部の情報をソースにするものもある．</li>\n<li>graph attentionを用いて，常識をグラフベースで学習する手法も</li>\n<li>主な考え方は，外部の知識グラフを使って，会話の論理の流れをモデリングする指標の一部として扱う</li>\n<li>Interactive Training</li>\n<li>別名；human-in-loop training</li>\n<li>アノテーションされたデータセットは限られている</li>\n<li>すべての状況をカバーすることは不可能</li>\n<li>ユーザとの対話の中で，システムを改善する</li>\n<li>強化学習における逐次学習を提案</li>\n<li>対話相手と話して，その相手からフィードバックを得る</li>\n<li>教師あり学習をした後，Interactive Trainingによってファインチューニングする</li>\n<li></li>\n<li>Visual Dialogue</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/024f212d-df8b-4569-a3f2-fe899fa0b606/Screenshot_from_2021-06-09_16-35-24.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182732Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=71cf387985ea5733c7a0086c95d95c0290055e0d110a351ac24801aed290767a&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>Visual Q &#x26; Aなど</li>\n<li>画像あり対話システムのほか，映像あり対話システムも面白いトピックだが難題でもある</li>\n<li>特徴量抽出の複雑さも増す</li>\n<li>visual dialogueのアノテーションは重労働であり，データセットに乏しいので，現在はデータの不十分さに悩まされている</li>\n<li></li>\n</ul>\n<h3>評価のアプローチ</h3>\n<p>評価の仕方も重要なパートとなっている</p>\n</body>\n</html>\n","Title":"【論文まとめ】Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey","Date":"2023-05-21","Category":"論文","Tags":"survey,dialogue system","Authos":"ゆうぼう","Slug":"Recent-Advances-in-Deep-Learning-Based-Dialogue-Systems-A-Systematic-Survey","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b6eb260b-8c7f-4cb6-877b-7844cd677787/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.44.29.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T182245Z&X-Amz-Expires=3600&X-Amz-Signature=f6e89f39c9b418b4e2739829b4e0f51e33f3a393bf7a3b2e11fb2d03f2343cc5&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Surveyのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>与えられたキャラクター設定（ペルソナ）を考慮した応答生成をする雑談対話システムの構築</p>\n<p>一貫した発話をしない対話システムは魅力的ではない</p>\n<p>→　一貫性を持たせるためペルソナに着目</p>\n<p>Prompt-Tuningを行うことで，Fine-Tuningに比べて学習時間と計算資源を削減しつつ，より自然で個性を持ったシステムの構築</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5204ea56-cdd0-4764-9119-4e01ccbdd8e9/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_10.33.59.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181058Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=9000cf45f4c2f5bc1893ecbe2b371c404cf14bd2d6185517226cf873ae642995&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>ペルソナ情報を埋め込むトークン（Persona Info Token）用のEmbedding層を追加したTransformerモデルを提案</p>\n<p>この新たに追加したEmbedding層のパラメータを更新する</p>\n<h2>新規性</h2>\n<p>事前学習済みモデルのパラメータを更新しないPrompt-Tuningによって学習</p>\n<p>→　学習に要する時間と計算資源の削減が可能</p>\n<p>数百個の対話ペアからなる小規模なデータセットであっても，個性を持ったシステムの構築が可能</p>\n<h2>実験</h2>\n<p>データセット：Persona-Chat／DailyDialog</p>\n<p>1往復の2初話ずつに分割→これを対話ペア</p>\n<p>使用するペルソナ：Persona-chatにおける対話ペア数の多い上位3種類のペルソナのみ</p>\n<p>ペルソナとは無関係な対話ペアとしてDailyDialogを使用</p>\n<p>→　TopicがRelationshipの対話ペアを使用</p>\n<p>中でも発話と応答の両方の長さが50文字以下の対話ペアを一定の比率で学習用データセットに混ぜる</p>\n<p>→　なぜ？：短い発話やペルソナと無関係な一般的な発話おデータセットに取り込む</p>\n<p>ペルソナ文を与える際，長さ&#x3C;200の時は，200になるまでペルソナぶんを繰り返し並べる</p>\n<p>生成の戦略にはGreedy searchを採用</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/64a67a7e-011f-4829-86fc-534126a929d4/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_10.41.44.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181118Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=414ca00d2b367d75c01e95e7d3ad1350b2f8ff68726e58ebf74e1e5acbd53018&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/04a389d8-4c52-4b93-8330-dc464f804940/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_10.42.02.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181119Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=f920535862f71043abb8de9459991598219daa8a0285d8f5aeec99fa4ca6f888&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1fd80b4c-baff-4875-a6e0-b27a3c507e72/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_10.42.24.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181123Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b1a7ecd128436d08db90ed6703a0b820633c28d840f5b4c09add36e8b1609652&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b3b0d288-dd48-4dfd-8ccb-48dc133197c3/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_10.42.42.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181135Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=0c264e7f7a5f808279d8d71f1f7ef93dc0ebb954e182912cf98dd9f27c435bb4&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>自動評価時：distinct-{1, 2}</p>\n<p>GPT-J-6BをPrompt-Tuningしたモデルが最も多様性のある生成</p>\n<p>Fine-Tuningの時は入力にペルソナを孵化しない方が良い性能</p>\n<p>人手評価時</p>\n<p>全ての項目においてGPT-J-6BをPrompt-Tuningしたモデルの評価が高い</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<p>LINEとの共同研究</p>\n<p>AI-Bridging cloudを用いてA100（40GB）を使用した実験</p>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】Prompt-Tuning による個性を持った対話システムの構築","Date":"2023-05-21","Category":"論文","Tags":"dialogue system,persona,Prompt-Tuning","Authos":"ゆうぼう","Slug":"Prompt-Tuning-による個性を持った対話システムの構築","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/281f5c65-6042-478c-80e0-855ec035a28e/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-07-23_10.33.59.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T181052Z&X-Amz-Expires=3600&X-Amz-Signature=42d5012d0a794690f0bfbe583b0ba3e2d5a8874792c495151041c28896a46666&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Prompt-Tuning による個性を持った対話システムの構築のまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>提案手法</h2>\n<p>会話ロボットがshared laughterを自動生成することを目的にする</p>\n<h3>Shared Laughter Model</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1de6b6b2-a98a-439b-8da8-6e45f425c73f/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-17_13.54.22.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181156Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=ee71ea0d8549ff03902e0f000622282a9587a336e7e01a2b6b424b82abaface1&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>ユーザの最初の笑いを検知して，システムが笑うモデル</p>\n<p>3種類のモジュールが存在する</p>\n<ol>\n<li>ユーザの最初の笑いを検出</li>\n<li>shared laughterを生成するかどうかを決定</li>\n<li>どのタイプの笑いをするべきか決定</li>\n</ol>\n<h3>Data Collection and Analysis</h3>\n<p>収集方法：ERICA</p>\n<p>teleoperateしたのは女性</p>\n<p>対象：61人の男性</p>\n<p>シナリオ：speed dating</p>\n<p>好きな趣味，好きなこと，嫌いなことに関してカジュアルなチャット</p>\n<p>アノテーション：</p>\n<p>2種類のタイプに笑いを分けた</p>\n<ol>\n<li>isolated laugh</li>\n<li>笑い単体で起こる笑い</li>\n<li>speech laugh</li>\n<li>話しながら起こる笑い</li>\n</ol>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1e798f36-17f0-4b8d-8851-201cf2bd1675/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-17_14.04.32.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181218Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=f1ff80a67323119d7e1eeda42732af60fa8343a8bcd1f17fee9f47f9944c159d&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6305e57d-f4fe-4d66-8301-8baf00db5dfd/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-17_14.04.55.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181224Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=8cbd1774c651115a437a339316c3ec158566cbb741aca762afd62a29f3331322&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>集まったデータの中で，1206件のinitial laughが確認</p>\n<p>698件がself laughで508件がshared laugh</p>\n<h3>Model Creation</h3>\n<p>特徴量2種類：</p>\n<p><strong>Audio-based features</strong></p>\n<p>40のacoustic メルフィルタバンクの平均と標準偏差</p>\n<p><strong>Prosodic features</strong></p>\n<p>全IPUにまたがるピッチとパワーの値を使った合計で14つの以下の指標</p>\n<p>平均／中央値／標準偏差／最大値／最小値／範囲</p>\n<p><strong>モデル</strong>：</p>\n<p>LR／SVM</p>\n<p>データサンプルが小さかったからか，deep learningの手法は弱かった</p>\n<h2>新規性</h2>\n<p>ユーザに合わせて毎回笑いを生成するのではなく，適切なタイミングでshared laughterを自動生成することをロボットに持たせたいという目的をもった研究</p>\n<h2>評価方法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5699d970-a1cb-46cb-a3a6-0065c3e74a1b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-17_14.20.05.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181242Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=1918c0beb7e1d75b0d6107c0fd1f73753ba3a0f09217288ee13a27d0110a555b&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>オフラインとオンラインの二つのタイプで評価</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a4425ec8-151c-4f54-9fba-c360f40bb34c/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-17_14.21.05.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181249Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=4a9d420209c5699b821be6c4653d99524ec8cc0af4e18abb23076c4044030470&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7c04f66f-6a92-40af-ae4e-3aafb9a1b1c2/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-17_14.21.17.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181252Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a59522ac850da45239af8dd7a9142be0d95b9cfa3d3aa0c751bd3b49d7d74d71&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>特徴量としてlaughter typeを加えることでrecallが改善する傾向</p>\n<p>負に歪んだピッチの分布の時は笑いがシェアされがちで笑いが長く続きがち</p>\n<p>laughter detectionとlaugh type classificationのエラーによってパフォーマンスが落ちることは明らかだが，それでもベースラインをoutperform</p>\n<p>最もよかったonline modelはacousticとprosodicの特徴量を両方使ったもの</p>\n<h2>何がすごかった？</h2>\n<p>prosodicの分析からわかったことが，initial laughのacousiticsはresponse laughを呼び起こすいくつかの特徴があること</p>\n<p>まだ改善の余地はあるものの，acousticとprosodicの特徴量の両方を使うことはパフォーマンスの改善に役立った</p>\n<p>shared laughterのタイミングについてはかけた研究である</p>\n<p>今後の課題である</p>\n<h2>次に読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】Prediction of Shared Laughter for Human-Robot Dialogue","Date":"2023-05-21","Category":"論文","Tags":"laughter,shared laughter","Authos":"ゆうぼう","Slug":"Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8794a1f3-9e28-4e3c-9890-2421fac523e5/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-17_11.13.42.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T181149Z&X-Amz-Expires=3600&X-Amz-Signature=1395e08283b7e1496d920bd07f6aca8727756340e2f1e0b88cfd3c85e62e88c2&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Prediction of Shared Laughter for Human-Robot Dialogueのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>マルチモダールなユーモアデータセット(<strong>MHD; Multimodal Humor Dataset</strong>)（The Big Bang Theoryを使用）を構築</p>\n<p>海外のSitcoms (Situation comedies) では笑い声がドラマ内に含まれている</p>\n<p>→ sitcomsは定期的に作成されていて，この笑い声を自動で追加するタスクがクリティカルなタスク</p>\n<p>→ <strong>笑い声の自動挿入のタスクを自動化することが狙い</strong></p>\n<p>構築されたデータセットを用いて，マルチモーダルを利用したAttentionベースのモデルを構</p>\n<p>→SoTA &#x26; データセット分析</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e9dbc394-bcf4-4316-8d7d-26b3a8df346a/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_9.54.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191045Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=875fcef8e4c34d0244652019e2b3b6e83e11f873d4b7fdd4f6d41626a426947d&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f4ba132d-d530-41ca-8574-543ce3f59b7b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_9.53.14.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191049Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=30e66c37ab34dc93b2d82b9f35ca0987d5c57b5fc45ea877041f0344b2aa6548&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/90a64f3d-7b08-4725-abe3-c1a208d7ef88/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_9.54.31.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191049Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=56532addba0d167bc67f748d52ce045a1e6fba89d117ea47209aa29bbe6e78e2&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h3>データセットのこと</h3>\n<p>対話のチャンクに対してlaughter tracksを使用してラベルを付与</p>\n<p>笑い声をアノテーションすることがは間接的に人手でのアノテーションと同じになるという過程</p>\n<p>→ 笑い声の起こる直前の発話の集合をユーモアとしてラベル付け</p>\n<p>Attributes</p>\n<ol>\n<li>Scene</li>\n<li>Speaker</li>\n<li>Recipients</li>\n<li>Participants</li>\n<li>Dialogue Turns</li>\n<li>Dialogue Start/End time</li>\n<li>Humor Start/End time</li>\n</ol>\n<p>対話のチャンクに複数のlaughter tracksがある場合，最後のみ適用</p>\n<p>データ分析の結果はFig 3.を参照のこと</p>\n<h3>モデルのこと</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2362b493-1c85-4602-ba74-d181ad8ced3d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_10.01.01.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191059Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=68e23c4842088e321a7cc6ad05f2acdee6532c032005ca8cb42788bd72189555&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>新規性</h2>\n<ul>\n<li>手動でアノテーションされたマルチモーダルな大規模ユーモアデータセットを構築</li>\n<li>これまでのSoTA手法を実験しつつ，multimodal self attention based modelを提案</li>\n<li>提案手法の汎化性能を検証</li>\n</ul>\n<h2>実験</h2>\n<p>5 turns / dialogueとする</p>\n<p>humor : non-humor = 1 : 2としてサンプリング</p>\n<p>humorのラベルが85%と高く，かなり不均衡のため</p>\n<p>実験モデル</p>\n<p>{Attention, Fusion, Sequential} with {only Text, only Video, both of them}</p>\n<p>評価指標：</p>\n<p>Accuracy, ROC, F1</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/28252124-9d19-4422-a8a3-b60fc13c8c83/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_10.08.22.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191109Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=ec270447a882b5eab596d1efdba311a8ff756fa2cc5c5b10b00f9468be752803&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5652a72f-b61e-4e35-9a75-8acc0515616b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_10.05.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191110Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=0fe8d621ae3114e7a98d82e7b35357d0d6c1459d988c0f55a9dbb12ec249d6f9&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/97772d42-0cc9-4b9e-bdbe-e76c5fcc5514/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_10.05.24.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191111Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=8f39111d3b8e6aa30d6582ef9fa29f12fa86d6386f52b359bd80f29d69e1dafe&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>提案手法のMSAMが強い</p>\n<p>表情や動作のようなvisual特徴量がユーモアの合図になっていることがある</p>\n<p>→ visual特徴量を使うことが有効である</p>\n<p>@Table 6.より，dialogueのターン数を長くするとよりcontextualにできるが，長くしすぎても精度が落ちている</p>\n<p>→ dialogue 5, 6がピークになっている→ ゆえにturn数を5として本研究は進められている</p>\n<h3>Discussion</h3>\n<ul>\n<li>良いモデルはテキストと視覚的な特徴量の重みづけの仕方を正しく考慮しなければならない</li>\n<li>失敗例への対策</li>\n<li>よりlong tailなユーモアにロバストにならなければいけない</li>\n<li>例）Sheldonは滅多にブランケットを羽織らない→羽織った時面白くなる</li>\n<li>知識ベースの弱さへの改善</li>\n<li>sitcomsは皮肉での笑いが多い（知識がないと伝わらないことがある</li>\n</ul>\n<h2>その他（なぜ通ったか？等）</h2>\n<h2>次読みたい論文</h2>\n<p>Here is a summary of the paper based on the web search results:</p>\n<h2>Title: Multimodal Humor Dataset: Predicting Laughter tracks for Sitcoms</h2>\n<p>URL: <a href=\"https://ieeexplore.ieee.org/document/9423266\">https://ieeexplore.ieee.org/document/9423266</a>\nConference or Journal: 2021 IEEE Winter Conference on Applications of Computer Vision (WACV)\nPublished at: 14 June 2021\nKeywords: multimodal humor, laughter prediction, sitcoms, Big Bang Theory, self-attention\nCited by: 0 (as of 27 April 2023)</p>\n<p>The paper aims to automate the task of adding laughter tracks to sitcoms by annotating an existing sitcom (Big Bang Theory) and evaluating various state-of-the-art baselines. The paper also proposes a novel multimodal self-attention based model that outperforms other models.</p>\n<p>The paper introduces a new dataset and task of predicting laughter tracks for sitcoms, which is a challenging semantic and practical problem. The paper also proposes a novel multimodal self-attention based model that leverages both text and video modalities.</p>\n<p>The proposed method consists of three main components: a multimodal encoder, a self-attention layer, and a binary classifier. The multimodal encoder encodes the text and video features separately using LSTM and CNN respectively, and then concatenates them. The self-attention layer computes the attention weights for each modality and each time step, and then applies them to the encoded features. The binary classifier takes the attended features as input and outputs a probability of laughter for each time step.</p>\n<p>The paper conducts experiments on the Big Bang Theory dataset, which contains 10 episodes from season 1 with manual annotations of laughter tracks. The paper compares the proposed method with several baselines, including LSTM, BERT, CNN-LSTM, and CNN-BERT. The paper uses accuracy, precision, recall, F1-score, and ROC-AUC as evaluation metrics.</p>\n<p>The paper reports that the proposed method achieves the best performance on all metrics, followed by CNN-LSTM and CNN-BERT. The paper also shows that using both text and video modalities improves the performance over using only one modality. The paper further analyzes the attention weights and finds that they are able to capture some humorous cues in the text and video.</p>\n<p>The paper concludes that predicting laughter tracks for sitcoms is a novel and interesting task that requires multimodal understanding of humor. The paper also concludes that the proposed multimodal self-attention based model is effective and interpretable for this task.</p>\n<p>Some possible papers to read next are:</p>\n<ul>\n<li>Humor Recognition using Deep Learning by Weller et al., 2019</li>\n<li>A Multimodal Dataset for Authoring and Editing Jokes by Chakrabarty et al., 2020</li>\n<li>Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems by Le et al., 2019</li>\n</ul>\n<p>ソース: Bing との会話 2023/4/27(1) Multimodal Humor Dataset: Predicting Laughter tracks for .... <a href=\"https://ieeexplore.ieee.org/document/9423266\">https://ieeexplore.ieee.org/document/9423266</a> アクセス日時 2023/4/27.\n(2) Multimodal humor dataset: Predicting laughter tracks for sitcoms. <a href=\"https://researchportal.bath.ac.uk/en/publications/multimodal-humor-dataset-predicting-laughter-tracks-for-sitcoms\">https://researchportal.bath.ac.uk/en/publications/multimodal-humor-dataset-predicting-laughter-tracks-for-sitcoms</a> アクセス日時 2023/4/27.\n(3) Multimodal Humor Dataset: Predicting Laughter Tracks for .... <a href=\"https://openaccess.thecvf.com/content/WACV2021/html/Patro_Multimodal_Humor_Dataset_Predicting_Laughter_Tracks_for_Sitcoms_WACV_2021_paper.html\">https://openaccess.thecvf.com/content/WACV2021/html/Patro_Multimodal_Humor_Dataset_Predicting_Laughter_Tracks_for_Sitcoms_WACV_2021_paper.html</a> アクセス日時 2023/4/27.\n(4) Multimodal Humor Dataset: Predicting Laughter tracks for .... <a href=\"https://www.semanticscholar.org/paper/Multimodal-Humor-Dataset%3A-Predicting-Laughter-for-Patro-Lunayach/a8cd2a93dc7f798e0c5280f2e7bc3fdc66bc4c22\">https://www.semanticscholar.org/paper/Multimodal-Humor-Dataset%3A-Predicting-Laughter-for-Patro-Lunayach/a8cd2a93dc7f798e0c5280f2e7bc3fdc66bc4c22</a> アクセス日時 2023/4/27.</p>\n</body>\n</html>\n","Title":"【論文まとめ】Multimodal Humor Dataset: Predicting Laughter tracks for Sitcoms","Date":"2023-05-21","Category":"論文","Tags":["humor detection","multi-modal"],"Authos":"ゆうぼう","Slug":"Multimodal-Humor-Dataset-Predicting-Laughter-tracks-for-Sitcoms","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9d8a6445-fdde-46c8-b0b9-72b1f53e4491/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-08_21.44.00.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T191039Z&X-Amz-Expires=3600&X-Amz-Signature=4f4bc4025bf9505ee1318bdbd65422ff21071f8b17540644c4abcf65009097a0&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Multimodal Humor Dataset: Predicting Laughter tracks for Sitcomsのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>マルチモダールなユーモアデータセット(<strong>MHD; Multimodal Humor Dataset</strong>)（The Big Bang Theoryを使用）を構築</p>\n<p>海外のSitcoms (Situation comedies) では笑い声がドラマ内に含まれている</p>\n<p>→ sitcomsは定期的に作成されていて，この笑い声を自動で追加するタスクがクリティカルなタスク</p>\n<p>→ <strong>笑い声の自動挿入のタスクを自動化することが狙い</strong></p>\n<p>構築されたデータセットを用いて，マルチモーダルを利用したAttentionベースのモデルを構</p>\n<p>→SoTA &#x26; データセット分析</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e9dbc394-bcf4-4316-8d7d-26b3a8df346a/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_9.54.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180341Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=5b27ee778b4b52d926cc58b26a85b63ef0e845ca327755aed28fb3059d42d555&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f4ba132d-d530-41ca-8574-543ce3f59b7b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_9.53.14.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180344Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=9e5f87561ac85c1eda997f5e70d3637833b25116e77abd2a6af1f01e4400a41c&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/90a64f3d-7b08-4725-abe3-c1a208d7ef88/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_9.54.31.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180348Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2af88be8e09237c755126c35e5078a9639502857fb07a760c48c50037aa5448d&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h3>データセットのこと</h3>\n<p>対話のチャンクに対してlaughter tracksを使用してラベルを付与</p>\n<p>笑い声をアノテーションすることがは間接的に人手でのアノテーションと同じになるという過程</p>\n<p>→ 笑い声の起こる直前の発話の集合をユーモアとしてラベル付け</p>\n<p>Attributes</p>\n<ol>\n<li>Scene</li>\n<li>Speaker</li>\n<li>Recipients</li>\n<li>Participants</li>\n<li>Dialogue Turns</li>\n<li>Dialogue Start/End time</li>\n<li>Humor Start/End time</li>\n</ol>\n<p>対話のチャンクに複数のlaughter tracksがある場合，最後のみ適用</p>\n<p>データ分析の結果はFig 3.を参照のこと</p>\n<h3>モデルのこと</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2362b493-1c85-4602-ba74-d181ad8ced3d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_10.01.01.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180414Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=4b9c37202b1c79aa7b8c8fd0daf1a02543384956e8839ea12043668fb8886f60&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>新規性</h2>\n<ul>\n<li>手動でアノテーションされたマルチモーダルな大規模ユーモアデータセットを構築</li>\n<li>これまでのSoTA手法を実験しつつ，multimodal self attention based modelを提案</li>\n<li>提案手法の汎化性能を検証</li>\n</ul>\n<h2>実験</h2>\n<p>5 turns / dialogueとする</p>\n<p>humor : non-humor = 1 : 2としてサンプリング</p>\n<p>humorのラベルが85%と高く，かなり不均衡のため</p>\n<p>実験モデル</p>\n<p>{Attention, Fusion, Sequential} with {only Text, only Video, both of them}</p>\n<p>評価指標：</p>\n<p>Accuracy, ROC, F1</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/28252124-9d19-4422-a8a3-b60fc13c8c83/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_10.08.22.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180430Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=13d483e8c4cbfb256f50730b13afc36c6da8e156ebac43d3fd7feb7ac6ceadde&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5652a72f-b61e-4e35-9a75-8acc0515616b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_10.05.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180432Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=1265762aa3394b65c75eddd17c718fd880950065f9214246790590ceae6008ce&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/97772d42-0cc9-4b9e-bdbe-e76c5fcc5514/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-09_10.05.24.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180433Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=c5470ae7c6d1c7389fa4ff5c3a966286463bf12e37511a2ab1e73d215e2c8f01&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>提案手法のMSAMが強い</p>\n<p>表情や動作のようなvisual特徴量がユーモアの合図になっていることがある</p>\n<p>→ visual特徴量を使うことが有効である</p>\n<p>@Table 6.より，dialogueのターン数を長くするとよりcontextualにできるが，長くしすぎても精度が落ちている</p>\n<p>→ dialogue 5, 6がピークになっている→ ゆえにturn数を5として本研究は進められている</p>\n<h3>Discussion</h3>\n<ul>\n<li>良いモデルはテキストと視覚的な特徴量の重みづけの仕方を正しく考慮しなければならない</li>\n<li>失敗例への対策</li>\n<li>よりlong tailなユーモアにロバストにならなければいけない</li>\n<li>例）Sheldonは滅多にブランケットを羽織らない→羽織った時面白くなる</li>\n<li>知識ベースの弱さへの改善</li>\n<li>sitcomsは皮肉での笑いが多い（知識がないと伝わらないことがある</li>\n</ul>\n<h2>その他（なぜ通ったか？等）</h2>\n<h2>次読みたい論文</h2>\n<p>Here is a summary of the paper based on the web search results:</p>\n<h2>Title: Multimodal Humor Dataset: Predicting Laughter tracks for Sitcoms</h2>\n<p>URL: <a href=\"https://ieeexplore.ieee.org/document/9423266\">https://ieeexplore.ieee.org/document/9423266</a>\nConference or Journal: 2021 IEEE Winter Conference on Applications of Computer Vision (WACV)\nPublished at: 14 June 2021\nKeywords: multimodal humor, laughter prediction, sitcoms, Big Bang Theory, self-attention\nCited by: 0 (as of 27 April 2023)</p>\n<p>The paper aims to automate the task of adding laughter tracks to sitcoms by annotating an existing sitcom (Big Bang Theory) and evaluating various state-of-the-art baselines. The paper also proposes a novel multimodal self-attention based model that outperforms other models.</p>\n<p>The paper introduces a new dataset and task of predicting laughter tracks for sitcoms, which is a challenging semantic and practical problem. The paper also proposes a novel multimodal self-attention based model that leverages both text and video modalities.</p>\n<p>The proposed method consists of three main components: a multimodal encoder, a self-attention layer, and a binary classifier. The multimodal encoder encodes the text and video features separately using LSTM and CNN respectively, and then concatenates them. The self-attention layer computes the attention weights for each modality and each time step, and then applies them to the encoded features. The binary classifier takes the attended features as input and outputs a probability of laughter for each time step.</p>\n<p>The paper conducts experiments on the Big Bang Theory dataset, which contains 10 episodes from season 1 with manual annotations of laughter tracks. The paper compares the proposed method with several baselines, including LSTM, BERT, CNN-LSTM, and CNN-BERT. The paper uses accuracy, precision, recall, F1-score, and ROC-AUC as evaluation metrics.</p>\n<p>The paper reports that the proposed method achieves the best performance on all metrics, followed by CNN-LSTM and CNN-BERT. The paper also shows that using both text and video modalities improves the performance over using only one modality. The paper further analyzes the attention weights and finds that they are able to capture some humorous cues in the text and video.</p>\n<p>The paper concludes that predicting laughter tracks for sitcoms is a novel and interesting task that requires multimodal understanding of humor. The paper also concludes that the proposed multimodal self-attention based model is effective and interpretable for this task.</p>\n<p>Some possible papers to read next are:</p>\n<ul>\n<li>Humor Recognition using Deep Learning by Weller et al., 2019</li>\n<li>A Multimodal Dataset for Authoring and Editing Jokes by Chakrabarty et al., 2020</li>\n<li>Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems by Le et al., 2019</li>\n</ul>\n<p>ソース: Bing との会話 2023/4/27(1) Multimodal Humor Dataset: Predicting Laughter tracks for .... <a href=\"https://ieeexplore.ieee.org/document/9423266\">https://ieeexplore.ieee.org/document/9423266</a> アクセス日時 2023/4/27.\n(2) Multimodal humor dataset: Predicting laughter tracks for sitcoms. <a href=\"https://researchportal.bath.ac.uk/en/publications/multimodal-humor-dataset-predicting-laughter-tracks-for-sitcoms\">https://researchportal.bath.ac.uk/en/publications/multimodal-humor-dataset-predicting-laughter-tracks-for-sitcoms</a> アクセス日時 2023/4/27.\n(3) Multimodal Humor Dataset: Predicting Laughter Tracks for .... <a href=\"https://openaccess.thecvf.com/content/WACV2021/html/Patro_Multimodal_Humor_Dataset_Predicting_Laughter_Tracks_for_Sitcoms_WACV_2021_paper.html\">https://openaccess.thecvf.com/content/WACV2021/html/Patro_Multimodal_Humor_Dataset_Predicting_Laughter_Tracks_for_Sitcoms_WACV_2021_paper.html</a> アクセス日時 2023/4/27.\n(4) Multimodal Humor Dataset: Predicting Laughter tracks for .... <a href=\"https://www.semanticscholar.org/paper/Multimodal-Humor-Dataset%3A-Predicting-Laughter-for-Patro-Lunayach/a8cd2a93dc7f798e0c5280f2e7bc3fdc66bc4c22\">https://www.semanticscholar.org/paper/Multimodal-Humor-Dataset%3A-Predicting-Laughter-for-Patro-Lunayach/a8cd2a93dc7f798e0c5280f2e7bc3fdc66bc4c22</a> アクセス日時 2023/4/27.</p>\n</body>\n</html>\n","Title":"【論文まとめ】Multimodal Humor Dataset: Predicting Laughter tracks for Sitcoms","Date":"2023-05-21","Category":"論文","Tags":"humor detection,multi-modal","Authos":"ゆうぼう","Slug":"Multimodal-Humor-Dataset-Predicting-Laughter-tracks-for-Sitcoms","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9d8a6445-fdde-46c8-b0b9-72b1f53e4491/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-10-08_21.44.00.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T180328Z&X-Amz-Expires=3600&X-Amz-Signature=47425b16d3accc25b1ca817eec4d5bf1148e6cf566a7737adf14227c8da0f921&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Multimodal Humor Dataset: Predicting Laughter tracks for Sitcomsのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>Document-level neural machine translationにおいて，Multi-Hopなアーキテクチャを導入することにより，従来手法と比べて精度の高い文脈を考慮した機械翻訳を実現</p>\n<p>翻訳者のように，頭の中に翻訳のドラフトを作り，文脈に合わせて適切に修正する流れ（human-like draft-editing）を明示的にモデリング</p>\n<p>大きな事前学習済みモデルを使うことなく，使用に足る機械翻訳モデルを実現</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c2619e4c-99b6-4874-8d32-2f7a07bb54a3/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-23_13.58.23.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180650Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=4a9ebbe96f6c5752e6fc236e0119656f4b12b60887449c2c7aa040705e510b1b&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>アーキテクチャ周りのこと</p>\n<h3>Sentence Encoder</h3>\n<p>source-sideとtarget-sideでそれぞれPretrained Encoderがあり，source contextとtarget draftの分散表現をそれぞれ得る</p>\n<h3>Multi-Hop Encoder</h3>\n<p>source-contextにおいて文章ごとのreasoningをして，現在の文章の分散表現を得る</p>\n<h3>Multi-Hop Decoder</h3>\n<p>target-side draftから情報を取得して，翻訳の確率分布を得る</p>\n<p>そのほかアーキテクチャの工夫</p>\n<h3>Contet Gating</h3>\n<p>contextual informationを過剰にutilizeしすぎないように，context gating machanismを採用</p>\n<p>contextと現在の文章間の重みを動的にコントロールする</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi><mo>=</mo><mi>σ</mi><mo stretchy=\"false\">(</mo><msub><mi>W</mi><mi>a</mi></msub><msubsup><mi>A</mi><mi>s</mi><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo>+</mo><msub><mi>W</mi><mi>b</mi></msub><msubsup><mi>B</mi><mrow><mi>s</mi><mo>−</mo><mi>i</mi></mrow><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\alpha = \\sigma(W_a A_s^{(n)} + W_b B_{s-i}^{(n)})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2948em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">a</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.5834em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1166em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.38em;vertical-align:-0.3352em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0448em;\"><span style=\"top:-2.4231em;margin-left:-0.0502em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\">i</span></span></span></span><span style=\"top:-3.2198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3352em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> where sigma is logistic sigmoid function</p>\n<h2>新規性</h2>\n<p>Docment-level NMTにおける従来手法の問題点</p>\n<ol>\n<li>文章間のreasoningの特徴づけを明示的に行うことなく，単純にcontextの分散表現を導入</li>\n<li>推論時にはアクセスできないのに，訓練時には追加入力としてのtarget contextにground-truthなデータを入力</li>\n</ol>\n<p>↑　訓練時と推論時において状況が異なる</p>\n<p>Document-level NMTにおいてMulti-Hop reasoningをモデリングしたMulti-Hop Transformerの提案と提案モデルによるDocument-level NMTの大きな性能改善</p>\n<p>target contextにground-truthで訓練すると推論時にはアクセスできないため，他の翻訳モデルの翻訳結果を使用することで，訓練時と推論時の状況を同じにした</p>\n<h2>実験</h2>\n<p>Baseline</p>\n<p>Transformer</p>\n<p>CA-Transformer</p>\n<p>CA-HAN</p>\n<p>CADec</p>\n<p>計算量のオーバーヘッドを改善するためSentence Encoderはそれぞれのsideでパラメータを共有</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e9aa2659-c723-4d78-b619-a2fca604a864/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-23_14.26.30.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180722Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=3c66aee5b1251f84f761a12c1b07c5f26d1114707c08ad8eb206be319a3d6204&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>large-scaleな事前学習済み言語モデルを使用することなく，SoTA翻訳クオリティを達成</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/648e061a-037a-47b0-9ccd-cb5e34f0584a/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-23_14.28.39.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180725Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=d8e366424556a63c360223cb870221afa415f0600f1de00904ef774da473a490&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>contextを付与するためのAttentionの構造は，ConcatやHierarchicalよりもMulti-HopなAttentionが効果があり</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7b8e8b86-406c-4fca-ac8d-f024c3d62def/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-23_14.30.06.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180728Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=02d6ca507eda285f489eb36d05990ce6b4189bcdd66b43c4cf724d22483fd766&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>contextを考慮する幅のwindow sizeは大きくするほど効果が上がるわけではなく．3が最も良かった</p>\n<p>4以上にすると悪化傾向らしく，本研究ではwindow size = 3 を採用</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/38aeab8f-9c30-446e-b0a5-c01920ef5946/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-23_14.36.58.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180731Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=27f587002275197d83d43ed3fcc6ac2f71ea54f41e42d6d313e5619a7b726883&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>contextにおいてreasoningするときの方向は，一般的な読み順の通りleft-to-rightで順方向にreasoningさせた方が結果は良かった</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/4f9ed4db-e0ac-48b0-9f5d-44af8ae2d2c5/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-23_14.38.40.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180733Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=5819e87b937d230adb78032278ea562724af2a498fd6ffff524e7b434f34dd8b&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>訓練時と推論時にtarget draftに与える文章が異なる問題への対処に関する実験結果</p>\n<p>Referenceはground-truthをtarget draftとして与えて訓練，Draftはpre-trained MT systemが生成した翻訳結果をtarget draftとして与えて訓練したモデル</p>\n<p>Draftの方が結果がよく，pre-trained MT systemの生成結果をtarget draftとする方法によって訓練時と推論時のギャップの橋渡しになることを示唆する結果</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h2>次読みたい論文</h2>\n<p><a href=\"/5955ca444629476ebf23e66629a2413f\">Context-Aware Self-Attention Networks</a></p>\n</body>\n</html>\n","Title":"【論文まとめ】Multi-Hop Transformer for Document-Level Machine Translation","Date":"2023-05-21","Category":"論文","Tags":"MT,transformer,Multi-Hop Transformer","Authos":"ゆうぼう","Slug":"Multi-Hop-Transformer-for-Document-Level-Machine-Translation","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/31894441-2dc1-4741-aa95-3d3a1d9b6411/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-23_13.58.23.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T180640Z&X-Amz-Expires=3600&X-Amz-Signature=f3b170858b4feaeb830ff35992d79604941439a760b4f7426fe311b73b9298f5&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Multi-Hop Transformer for Document-Level Machine Translationのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>検索クエリを生成し，Bing検索の結果をもとに応答生成を行うことで，大規模言語モデルの抱えるhallucinationの問題を軽減しつつ，up-to-the-minute relavent informationを導入した生成を可能にする．</p>\n<p>インターネットによるaugmentationを行わないモデルやFAISSベースのモデルよりも，search-queryのモデルは優れた会話能力を達成した．</p>\n<h2>提案手法</h2>\n<p>提案手法 (Search Engine-Augmented Generation) の流れ</p>\n<ol>\n<li>コンテクストから検索クエリを生成</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span>個のドキュメントを取得</li>\n<li>FiD (Fusion in Decoder)モデルによって，個々のドキュメントをエンコードし，対話コンテクストと結合して，応答を生成</li>\n</ol>\n<p>インターネットへのアクセスの手法</p>\n<ol>\n<li><strong>FAISS: distributed approximate nearest-neighbor databaseにストアすることでページをキャッシュ</strong></li>\n<li>これがベースライン的な手法</li>\n<li>Common CrawlのデータをFAISSストアして検索をかける</li>\n<li>ベースライン手法</li>\n<li>RAG (Retrieval Augmented Generation)</li>\n<li>FiD (Fusion in Decoder)</li>\n<li>FiD-RAG</li>\n<li>FAISS + Search Query-based Retrieval</li>\n<li><strong>インターネットに直接アクセスしてページを取得</strong></li>\n<li>FAISS-basedの手法の課題を解決するため</li>\n<li>リアルタイムなウェブ情報に更新するのが難しい</li>\n<li>ローカルのFAISSにストアできるウェブページの数には限界がある</li>\n<li>インターネット検索エンジンがチューニングしているハイクオリティなページのランキングの利点を活かせない</li>\n</ol>\n<h2>新規性</h2>\n<ul>\n<li>インターネットにアクセスすることで，常に数え切れないほどの最新の情報にアクセスし，それを取り入れた応答生成を可能にする</li>\n<li>knowledge regulationなどを行うことで，dynamic state of the worldに対応する</li>\n<li>大規模言語モデルは，知識をweightsの中で記憶してしまうため，hallucinationが起きやすい→これを正則化によってよりうまく情報をcopyするように学習させる</li>\n<li>長い目で見れば機械学習の手法は実世界とのインタラクションが求められるが，まず自然な第一ステップとしてインターネットへのアクセスをモデル化してみた．</li>\n</ul>\n<h2>実験</h2>\n<p>Wizard of the Internet (WizInt)という新たなタスクで評価</p>\n<p>T5, BART-large, BlenderBotをファインチューニング</p>\n<p>Retrieval-augmented methodは5つのドキュメント (<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">N = 5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">5</span></span></span></span></span>) を使用</p>\n<p>デコーダ</p>\n<p>ビームサーチ with ビームサイズ = 3</p>\n<p>最小sequence length = 20</p>\n<p>beam blocking ngram = 3</p>\n<p>評価指標</p>\n<p>PPL</p>\n<p>F1</p>\n<p>gold responseとのオーバーラップを評価</p>\n<p>Knowledge F1 (KF1)</p>\n<p>モデルの応答と人間がデータ収集時に使った知識のオーバーラップを評価</p>\n<p>→ F1とKF1はトレードオフ</p>\n<p>KF1が高く，F1が低いと知識には富んでいるが，会話能力は低</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/046eaf2d-d2ad-4c64-88ff-1da3652d09db/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_10.56.43.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180245Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=5bc0838e45dcfd8e8bd5eaccc3119950721a181ddda4d06ec738e7c3365f5031&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>Table 3からBART-largeを全てのモデルのPLMベースとして採用</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1ca77f8a-f779-4b89-848d-c91da6c62f4a/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.01.48.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180251Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=9ff218f5ee589b534be2eb715c0f7f63df861d554e66d55106b4c556781442fd&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/27573c8b-3d99-43f9-94ab-7587b26b32cc/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.05.44.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180251Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b964e89f1e9d2ae8e64e0d7d742d7020fc7ef4ff29b833797ce37314e5799441&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>対話生成のプロセスにインターネットの情報を与えると，人との対話においてより事実との不整合の少ない情報を生成することができる</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h3>Datasetの概要</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2eb1422e-7ff7-4cc5-8196-bde757915ce2/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.09.02.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180259Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=710c789b847b28780b36828dceb94a0c5e64477a947408b006326fd9d96fa982&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d5ea08a4-45cf-49ef-91e7-377133215991/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.13.05.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180259Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=c399c60223e5461c49e6402da18bbd25141af21f76ecef9ac70feb5bb99e2712&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f4dc75e0-c5fc-4c72-87a2-038fa4da489d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.09.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180301Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=be8accd7244e0323058c7cae973662a3e4e6aeed3ea7cbe2166c7cd14b85b449&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>Wizard vs apprentice (Figure 3がペルソナ設定のインターフェース)</p>\n<p>Wizardは対話しながらネット検索ができる</p>\n<p>→検索された結果をアノテーションし，適切な検索結果が得られなければもう一度検索でき，検索結果を無視することも可能</p>\n<p>Apprenticeはペルソナを選び，そのもとでチャット</p>\n<p>ペルソナはPersona-ChatとTopical-Chatデータセットに含まれるペルソナから選択</p>\n<h3>データ収集インターフェース</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0085580b-3278-476e-9ec5-c2ffb77d7b29/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.14.35.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180312Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=cecc9811d038c323c2fe77514541206c99c29f182089e0ff4f7ff1c05af76ae4&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h3>対話例</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f4ea4c49-8c2d-461e-90f8-e088f140236f/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.15.44.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180317Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=76f2ea0ce416603f36d781351eb7ef96112d254becc9fc794f003d7a505d656d&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a7cbe08f-b519-4f38-9fd3-c04ac200ca59/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.16.36.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180318Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=6b2ceb55e526c639addff82e913b3131ffa72b15726b9e4466b940d897fd4d63&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/34dfeedc-b77c-4a35-b702-75063a8bc508/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.17.07.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180320Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=98cefeb4eb76d733e0f66f1ee4b6da121400d4424e577568f4f62b89a1f4604c&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f32d2168-6cc4-4d1a-9144-28b7b9f08403/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.16.06.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180322Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=3303ed5f702bd5f37007ea86bd77140491402ebe7cdd5c95864ea40e0fb5c497&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/297251c8-e380-41bb-bd63-e7d5cb7a3a85/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-12-01_11.16.52.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180323Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b96877406775d10be4cac4190bb15461878b6252b5145dad83309750f2de7c68&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】Internet-Augmented Dialogue Generation","Date":"2023-05-21","Category":"論文","Tags":"dialogue system,Internet-Augmented","Authos":"ゆうぼう","Slug":"Internet-Augmented-Dialogue-Generation","Description":"Internet-Augmented Dialogue Generationのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>LSTM-styleなSDUを提案</p>\n<p>ゲートとしてSDUをTransformer内部に適用することにより，ハイパラをチューニングすることなく，Transformerの浅い層において，内在的な意味の重要性を捉え，より早い収束を可能に</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ee071883-293d-4802-ab74-1f3298ab1ad1/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_12.58.57.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191153Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=56857eedf60df4ea04d3bc9c4d0311694c4892da6e5bc79c590f087d7ad81884&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h3>Self-Dependency Units (SDU)</h3>\n<p>sigmoid gatesを導入する</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Ψ</mi></mrow><annotation encoding=\"application/x-tex\">\\Psi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\">Ψ</span></span></span></span></span>はゲートとして作用し，logistic sigmoidもしくはtanhで実現</p>\n<p>筆者らの認識</p>\n<p>tanhはupdate gateとして作用し，重要度の幅を-1 to 1に制限</p>\n<p>sigmoidはLSTMのinput gateと似ていて，feature-wise levelでどれくらいの情報を残すか決定</p>\n<h3>Pseudo-highway Connection</h3>\n<p>residual connectionされたgating-modified encodingsでMulti Head Dot Product Attention (MHDPA)の分散表現を豊かにするため，新たな計算グラフの枝を追加し，SDUとIdentityとMHDPAをpost LNを使用してresidual connectionする</p>\n<h2>新規性</h2>\n<p>本来，人にとって，読み物をよりよく理解するためには，global contextだけではなく，ここの単語の意味も必要</p>\n<p>→ Self-gatingなアプローチを提案</p>\n<ol>\n<li>Transformerにおける浅い層において，trainingとvalidationでハイパラチューニングすることなく，より高速な収束を達成</li>\n<li>Transformerでの低レイヤーにおいて，local-range encodingにフォーカスした層を実現</li>\n<li>Self-gating mechanismは，R-TransformerやTransformer-XLのコンポーネントとしてRNN-likeなメカニズムを補完</li>\n</ol>\n<h2>実験</h2>\n<p>SDUを導入し，PTBデータセットにおけるSDUの効果を検証</p>\n<p>sigmoidとtanhを実験</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/983f88c3-b4c6-4017-89a5-c11814060ffe/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.21.41.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191211Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=de0e4f48e3c4f1d48d1dadbd40d52c622b05b036744da4589057b0d22e30bd47&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bf1a2c53-9065-4c50-bc7a-7cb9aae77dd8/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.22.04.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191214Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=84a6f8b7d973f492edbb74709165b166737f008cb07f7b78e9208422d30c89c6&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/43698a9d-abf7-4007-b343-7b9dc2a4e588/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.22.25.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191216Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=345b1f51e95dda0f94b67019eec9c8fc5fdd9fc5d9da0f480b40d3203ac8e0d0&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6cd06f60-3432-42c1-b90a-e8cafdb254a5/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.22.43.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191216Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=af5d8bef1ae3d9a568076e15252732529fe4bbf1a45a3a975ab1bbef710c0693&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a5b222bb-5fc4-4ad6-9c08-e7cde9bc7b8d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.23.01.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191218Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=d3c09f27b5cc59fd01d48a33b359797bd046846268698b26e57080c92db1506e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2e0b4670-6891-40f4-859b-a6b50feaeb9b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.23.12.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191219Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=63c50b1a03f24106c25485cc75f027ef404905b57a04601d32e4668dea527030&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c48f4870-1a31-45e3-984e-d9622e262bad/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.23.37.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191221Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=e98d80059f48aac80db3ee397019789a30c6ce4a648d55621f98b986a098a62f&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d6970bfd-1cd0-40f2-ac05-d9d46e1db8aa/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.23.48.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T191221Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a7cbdd817494c7351b47605e6667a834a90a05828362583a078dc5e427a09093&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>sigmoidによるSDUが安定しているが，データとタスクによってはtanhの方がoutperformすることがある</p>\n<p>いずれのactivationを使っても収束は早い</p>\n<p>enwik8による大規模データでの追実験において，提案手法が浅いレイヤーには寄与することが確かめられた</p>\n<p>SDUで計算量が増えるが，そこまで差はなかった</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】Highway Transformer: Self-Gating Enhanced Self-Attentive Networks","Date":"2023-05-21","Category":"論文","Tags":["transformer","Highway Transformer","Gating Mechanism","Self-Dependency-Units (SDU)"],"Authos":"ゆうぼう","Slug":"Highway-Transformer-Self-Gating-Enhanced-Self-Attentive-Networks","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c1d2b55a-8e61-4918-8a5e-bee7f61e9f4d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_12.58.57.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T191150Z&X-Amz-Expires=3600&X-Amz-Signature=ad0c4bc565d9eed51eaa62e5e5895293759b83f5343d860c78f899a00f878afc&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Highway Transformer: Self-Gating Enhanced Self-Attentive Networksのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>LSTM-styleなSDUを提案</p>\n<p>ゲートとしてSDUをTransformer内部に適用することにより，ハイパラをチューニングすることなく，Transformerの浅い層において，内在的な意味の重要性を捉え，より早い収束を可能に</p>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ee071883-293d-4802-ab74-1f3298ab1ad1/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_12.58.57.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180540Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=90235e0c189715ed2ad9e053ac0ded46a7529072523ceb561856d73c171cbc63&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h3>Self-Dependency Units (SDU)</h3>\n<p>sigmoid gatesを導入する</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">Ψ</mi></mrow><annotation encoding=\"application/x-tex\">\\Psi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\">Ψ</span></span></span></span></span>はゲートとして作用し，logistic sigmoidもしくはtanhで実現</p>\n<p>筆者らの認識</p>\n<p>tanhはupdate gateとして作用し，重要度の幅を-1 to 1に制限</p>\n<p>sigmoidはLSTMのinput gateと似ていて，feature-wise levelでどれくらいの情報を残すか決定</p>\n<h3>Pseudo-highway Connection</h3>\n<p>residual connectionされたgating-modified encodingsでMulti Head Dot Product Attention (MHDPA)の分散表現を豊かにするため，新たな計算グラフの枝を追加し，SDUとIdentityとMHDPAをpost LNを使用してresidual connectionする</p>\n<h2>新規性</h2>\n<p>本来，人にとって，読み物をよりよく理解するためには，global contextだけではなく，ここの単語の意味も必要</p>\n<p>→ Self-gatingなアプローチを提案</p>\n<ol>\n<li>Transformerにおける浅い層において，trainingとvalidationでハイパラチューニングすることなく，より高速な収束を達成</li>\n<li>Transformerでの低レイヤーにおいて，local-range encodingにフォーカスした層を実現</li>\n<li>Self-gating mechanismは，R-TransformerやTransformer-XLのコンポーネントとしてRNN-likeなメカニズムを補完</li>\n</ol>\n<h2>実験</h2>\n<p>SDUを導入し，PTBデータセットにおけるSDUの効果を検証</p>\n<p>sigmoidとtanhを実験</p>\n<h2>まとめ</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/983f88c3-b4c6-4017-89a5-c11814060ffe/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.21.41.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180603Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=dc4b94706aaae77f3e190ab3103d101fb2152f6216dcfdef0d162302fe053706&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bf1a2c53-9065-4c50-bc7a-7cb9aae77dd8/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.22.04.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180607Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=8deccd38d03139667d4e160812d04d855e16f2c37db8428d5434b33bbbfd46f4&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/43698a9d-abf7-4007-b343-7b9dc2a4e588/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.22.25.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180609Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=99f3e053d8e49ec68bef5d06de3bbd3f71e880cd411b9f6561244597055b24a1&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6cd06f60-3432-42c1-b90a-e8cafdb254a5/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.22.43.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180612Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=546157c3dbc57dbdfebfd19724491ba4026390d3b968e6bf79cbed0cdc8fdec4&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a5b222bb-5fc4-4ad6-9c08-e7cde9bc7b8d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.23.01.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180614Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=ce5717a7823c4d6531b7dfa3ca8cf71fd84bc9cafa5e0613c111b5c5380bda2a&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2e0b4670-6891-40f4-859b-a6b50feaeb9b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.23.12.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180620Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=50441be8be1fbd4908b07ebc956da7e7343e0db5ec91e01a264d275a9c4a4394&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c48f4870-1a31-45e3-984e-d9622e262bad/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.23.37.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180625Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=34e626fb90de9065c1df255c4293c825cd190bb783589c4d1bd6e1a4f96eb6a0&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d6970bfd-1cd0-40f2-ac05-d9d46e1db8aa/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_13.23.48.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T180628Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b60865c113b62ddaae3f5496c4f83f6248f60a34763b8df0f9a6aef50aba250d&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>sigmoidによるSDUが安定しているが，データとタスクによってはtanhの方がoutperformすることがある</p>\n<p>いずれのactivationを使っても収束は早い</p>\n<p>enwik8による大規模データでの追実験において，提案手法が浅いレイヤーには寄与することが確かめられた</p>\n<p>SDUで計算量が増えるが，そこまで差はなかった</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】Highway Transformer: Self-Gating Enhanced Self-Attentive Networks","Date":"2023-05-21","Category":"論文","Tags":"transformer,Highway Transformer,Gating Mechanism,Self-Dependency-Units (SDU)","Authos":"ゆうぼう","Slug":"Highway-Transformer-Self-Gating-Enhanced-Self-Attentive-Networks","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c1d2b55a-8e61-4918-8a5e-bee7f61e9f4d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-08-26_12.58.57.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T180536Z&X-Amz-Expires=3600&X-Amz-Signature=3a2649aaae274fbabf93cde0b58588663b3b7e6a951c5a628fb5bbca202a7140&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"Highway Transformer: Self-Gating Enhanced Self-Attentive Networksのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ce8ac11c-bb77-4047-aca2-b3bf53b16368/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.30.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181309Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=0301994b6faf8a478cc24bfc525e20d3f2287e7b133168e2065e9bdb19f52839&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>上の流れで学習して，メンタル状態を外部知識のEmbeddingを利用しながら捉える</p>\n<ol>\n<li>Data Preprocessing</li>\n</ol>\n<ul>\n<li>nltk sentence tokenizerを使ってpostを文区切にする</li>\n<li>→文ごとのmental stateを捉えるため</li>\n</ul>\n<ol start=\"2\">\n<li>Context-aware post (CAP) encoder</li>\n</ol>\n<p>RoBERTaをdomain-specificなデータで学習した<strong>MentalRoBERTa</strong>なるものがあるのでそれを使って，context-awareなエンコーダとして使用する</p>\n<ol start=\"3\">\n<li>Mental satte knowledge infusion</li>\n</ol>\n<p>mental stateの知識を捉えるため，ATOMICで学習されたGPTベースのCOMETを使用する</p>\n<p>理由：</p>\n<p>↑mental stateとmental health conditionの関係を捉えるために，ConceptNetではなくATOMICで学習されたものを使った</p>\n<ul>\n<li>ConceptNet：一般的な言語の概念を含む</li>\n<li>ATOMIC：human interactionを捉えたcommonsenseを含む</li>\n</ul>\n<ol>\n<li>Feature extraction</li>\n</ol>\n<p>以下の5つのaspectを使用した</p>\n<ul>\n<li>intent of S</li>\n<li>effect on S</li>\n<li>reaction of S</li>\n<li>effect on others</li>\n<li>reaction of others</li>\n</ul>\n<p><strong>面白ポイント：COMETのlm_headを削除し，Transformerの内部のみをEncoderとして扱う</strong></p>\n<p>直接的にpost representationをモデルに統合できて，mental-related variablesを適応することが期待できる</p>\n<p>CAP embeddingsによるtoken-level representationは，max poolingによってsentence-level representationとされる</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mover accent=\"true\"><mi>H</mi><mo>^</mo></mover><mi>j</mi><mi>i</mi></msubsup><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi mathvariant=\"normal\">_</mi><mi>p</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>H</mi><mo stretchy=\"false\">[</mo><msubsup><mi>P</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow><mi>i</mi></msubsup><mo>:</mo><msubsup><mi>P</mi><mi>j</mi><mi>i</mi></msubsup><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{H}_j^i = max\\_pooling(H[P_{j-1}^i : P_j^i])</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.3415em;vertical-align:-0.3948em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9468em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span></span><span style=\"top:-3.2523em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.0813em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2194em;vertical-align:-0.3948em;\"></span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">x</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">oo</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">in</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2194em;vertical-align:-0.3948em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mclose\">])</span></span></span></span></span></p>\n<ol start=\"2\">\n<li>Knowledge-aware mentalisation</li>\n</ol>\n<p>5つの独立したGRUを使用して，mentalのaspect毎に学習するスタイル</p>\n<p>これでpost-level representationになる</p>\n<p>その後GRUによるmental aspectごとのpost-level representationとmax poolingされたsentence-level representationをAttentionすることで統合する</p>\n<ol start=\"4\">\n<li>Supervised contrasive learning</li>\n</ol>\n<p>より文章のsemantic meaningに注意して学習するために，contrasive learningを使用した</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6aba2985-13d9-4484-bb9e-da2def220431/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.31.30.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181343Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2d72674319f5c0334a18317851132b44a572c8b43f9f10e79c978732d88bad93&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b6fa8c7b-2c69-4574-b317-258cc41aafc8/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.32.16.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181344Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a43e2c440e21ed2ee9f0d2e5b7093248861ea9dd0368df834bdc6d01c8eb1816&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>新規性</h2>\n<ul>\n<li>mental state knolwedgeを使うことでスピーカー（実験ではpostした人）のmental stateを明示的にモデル化する</li>\n<li>model state knowledgeを理解し，使うモデルの能力を強くするため，knowledge-aware dot-product attentionに基づくmentalisation moduleを導入</li>\n</ul>\n<h2>評価方法</h2>\n<p>baseline</p>\n<ul>\n<li>CNN</li>\n<li>GRU</li>\n<li>BiLSTM_Attn</li>\n<li>LR+Features (Logistic Regression)</li>\n<li>EMO_INF</li>\n<li>BERT</li>\n<li>RoBERTa</li>\n<li>MentalRoBERTa</li>\n</ul>\n<p>Precision / Recall / F1を比較</p>\n<h2>何がすごかった？</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9ae321b3-ac70-408f-8142-e261bac6ede1/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_10.16.17.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181403Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=4ab133115e59b20cb0a4e0d1797a72b51b5078476ef52c15550f4d76b9b1ad0f&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d095eb4-866b-499f-91ff-c36cd97e8669/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_10.16.36.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181407Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=916dcadc9833d97c90f75269bd90c412934b7a911f634cdf11eba3aae13dcc4c&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>label情報を完全に利用するためのsupervised contrasive learningを使用することでclass-specificな特徴量を捉える必要性を議論</li>\n<li>SOTAモデル on three stress and depression detection datasets</li>\n</ul>\n<h2>次に読みたい論文</h2>\n<p>CEM: Commonsense-aware Empathetic Response Generation</p>\n</body>\n</html>\n","Title":"【論文まとめ】A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media","Date":"2023-05-21","Category":"論文","Tags":"COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net","Authos":"ゆうぼう","Slug":"A-mental-state-Knowledge–aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bcd9cf65-a266-4729-a855-f08f28d9578e/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.30.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T181306Z&X-Amz-Expires=3600&X-Amz-Signature=bee4522c1b4c4915939a2f749e0fcab83ac7b62fd4b39ee8fe1038470174fba8&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social mediaのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<p>まとめること</p>\n<ol>\n<li>Knowledge-Intensive NLPの概要</li>\n<li>Knowledge Sources</li>\n<li>Encyclopedic Knowledge</li>\n<li>Commonsense Knowledge</li>\n<li>最近のKnowledge Sourcesの特徴</li>\n<li>Knowledge-Intensive NLP Task</li>\n<li>Knowledge-Intensive NLP Taskの概要</li>\n<li>Knowledge-Intensive NLP Taskの特徴</li>\n<li>Knowledge Fusion Methodsについて</li>\n<li>Pre-Fusion Methods</li>\n<li>Post-Fusion Methods</li>\n<li>Hybrid-Fusion Methods</li>\n<li>代表的なモデルの紹介</li>\n<li>Challengingなことと今後の方向性</li>\n<li>Unified PLMKEs Across Tasks and Domains</li>\n<li>Reliability of Knowledge Sources</li>\n<li>Reasoning Module Design</li>\n</ol>\n<h2>概要</h2>\n<p>事前学習済みモデルにより，モデルのcapacityは増加傾向にあるが，encyclopedicやcommonsenseを用いた，knowledgeableなNLPモデルの需要の高まりが生じている</p>\n<p>**PLMKEs (Pre-trained Language Model-based Knowledge-Enhanced models)**についてまとめたsurvey論文</p>\n<p>linguistic or factual knowledgeは暗示的にモデルのパラメータに保存される</p>\n<p>→事前学習済みのNLPモデルがより汎用的な能力を持つことを一部ではあるが説明できる</p>\n<p>今のpre-trained LMは，明示的なencyclopedicやcommonsenseのレバレッジ能力に欠けている</p>\n<p>PLMKEsは，関連する外部知識を取り出すモジュールと知識を混ぜるモジュールがある</p>\n<p>PLMKEsに関連した重要な3つの要素がある</p>\n<ol>\n<li>Knowledge Sources</li>\n<li>Knowledge-Intensive NLP Tasks</li>\n<li>Knowledge Fusion Methods</li>\n</ol>\n<h2>Knowledge Sources</h2>\n<h3>Encyclopedic knowledge</h3>\n<p>エンティティに関する属性とエンティティ間の関係性をもった知識</p>\n<p>Entity: person → Attributes: age → Relations: educated at</p>\n<p>Wikipediaは大量のencyclopedicな知識を持っている</p>\n<p>人物の経歴やイベントの背景などを含んでいる</p>\n<p>一般的にはtripletsで構成されていることが多い</p>\n<p>e.g. &#x3C;Tom Hanks, occupation, actor></p>\n<p>Wikidataのような知識データがPLMKEsに広く使用されている</p>\n<h3>Commonsense Knowledge</h3>\n<p>日常生活のなかでの状況に関する知識</p>\n<p>イベントとその影響を記す</p>\n<p>e.g. mop up the floor if we split food over it / study hard to win scholarship / goat has four legs</p>\n<p>commonsenseの特徴</p>\n<p>多くの人の間で共有されている知識であり，コミュニケーションの中で暗示的に想定されている知識である</p>\n<p>commonsenseもtripletsで表現される</p>\n<p>最近のPLMKEsでは，ConceptNetとATOMICが外部知識として使用されることが多い</p>\n<h3>Knowledge Sourcesの特徴</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/30b21e96-66e9-4c93-b612-2a5ec35b43c9/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_16.42.16.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181930Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a08e0cc46127ef5b006be5eca7349c3b4f203325cb4dd1c39cb9757131c24c8e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>large-scaleでdiverse</p>\n<p>現在のソースはより正確で安定的に作られている</p>\n<p>アノテーションのプロセスは部分的に自動化されていて，非エキスパートにもaccessibleになっている</p>\n<p>知識データがカバーするドメインは多様</p>\n<p>オープンドメインのものもあれば，specificなドメインのものも</p>\n<p>Wikipedia, DBPedia, Freebaseなどはオープンドメイン</p>\n<p>UMLSやAMinerなどはbiomedicineやscienceの特定ドメイン</p>\n<p>domain-specificなアプリケーションをブーストできる知識</p>\n<p>commonsenseに関しては</p>\n<p>ConceptNetやTransOMCSは複数のドメインのcommonsenseをカバー</p>\n<p>ATOMICやASERはある特定のタイプのcommonsenseにフォーカスした知識ソース</p>\n<h2>Knowledge-Intensive NLP Task</h2>\n<h3>概要</h3>\n<p>Knowledge-intensive NLP taskは必要とする知識ソースの種類で2つに分けられ，さらに詳細に分けることができる</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ab23c756-9f8e-4f3c-a76c-cdd674276022/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.02.12.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181947Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b76560af21a3c08235665cc245c16fb63334660f36a2530535b06fa485395991&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>encyclopedic knowledge-intensive NLP task</li>\n</ul>\n<p>encyclopedicの知識ソースを利用する</p>\n<ul>\n<li>open-domain QA</li>\n<li>fact verification</li>\n<li>entity linking</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/28ba511c-8fa2-4031-9624-7a7460f25913/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.02.31.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181952Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b0c31adc0b4a7f7ea85b0fe08456ba8559910988866d93f039288cbd4421f3a6&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>commonsense knowledge-intensive NLP task</li>\n</ul>\n<p>commonsenseの知識ソースを利用する</p>\n<p>commonsenseの多様性のために，タスクのタイプ自体も多様化している</p>\n<p>モデルが正確に日常のシナリオを理解し，応答するか否かのテストにフォーカスしたタスク</p>\n<ul>\n<li>General Commonsense</li>\n<li>Social Commonsense</li>\n<li>Physical Commonsense</li>\n<li>Temporal Commonsense</li>\n</ul>\n<h3>Knowledge-Intensive Taskの特徴</h3>\n<p>実際は，モデルにとってだけではなく，人間にとってもいかなる知識の参照なしに問題に答えるのは難しい．（バラクオバマの誕生日はいつ？など</p>\n<p>しかも，外部知識が必要なのにinputとして必要な外部知識が渡されないため，とてもチャレンジングなタスクになっている</p>\n<p>そもそも必要な外部知識にグラウンディングするモジュールをPLMKEsの設計に加えることを考慮するようになっている</p>\n<h2>Knowledge Fusion Methods</h2>\n<p>モデルが知識を統合するステージは二箇所あり，</p>\n<ul>\n<li>Pre-fusion; pre-training</li>\n<li>Post-fusion; fine-tuning</li>\n</ul>\n<p>の二通りが考えられる（もしくはその両方のステージ</p>\n<h3>Pre-Fusion Methods</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ddeea37a-3062-47f7-b3ac-15057b8a1349/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.11.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182017Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=914d261462ed9d88bc35c4edfa5d080b2ffe29c48a555d3ffe8d9407c9fc70a8&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>pre-trainingのステージで知識を統合する手法</p>\n<p>モデルに知識を入力するため，構造化された知識データを非構造化データのテキストコーパスへと処理→モデルに入力</p>\n<p>テキストデータとして知識を入力するため，大きくモデルのアーキテクチャを変更する必要はない</p>\n<p>ただし，知識グラフのような構造化データを非構造化データへ変えることは難しいこともある</p>\n<p>簡単な対処法はエンティティと関係性を結合するか，流暢な文章をconditional text generation modelに生成させるか</p>\n<p>Zhang et al. 2019 | Agarwal et al. 2021 を参照（必要になれば読む</p>\n<h3>Post-Fusion Methods</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a978299c-4851-41c8-a702-a3aafb0f9323/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.37.53.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182027Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=e4e8f6a6703612a8f1118eb67304d93279f45d48fff78fd6f0b2c2d8b2b5a063&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>まず，関連知識をキャプチャする</p>\n<p>次に取得した関連知識をGNNなどのエンコーダでembeddingを得る</p>\n<ul>\n<li>それを追加特徴量としてpre-trained LMに与える（図でいうA）</li>\n<li>直接pre-trained LMに入力する（図でいうB）</li>\n</ul>\n<h3>Hybrid-Fusion Methods</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b696904a-be2b-4bd8-9d93-ca87a47ecc5e/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_19.38.22.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182031Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=8c309aba75c92d449b843fead794f87d2bd0340923faeef77c381a33ab5eb82e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>pre-trainingとfine-tuningの両方のステージで知識を統合する</p>\n<p>追加の学習されるretrieverによりaugmentされたpre-trained modelは，fine-tuningのステージでより効果的にretrieverからの知識を活用できる</p>\n<p>retrieval-augmented pre-trainingでhybrid-fusionが広く使われている</p>\n<h3>代表的なモデル</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ce1f044a-ba15-4c30-8d61-eab525800d9d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_19.39.00.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182039Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2bfc9853f1a4e6bff019baa7c3effe98a1c01a806e603f05131576021c53bf3e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/81d13c12-2379-4709-bc00-97fd4185fd4b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-31_12.00.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182039Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=3f15cc31ed578332b99f8185529710bceec9e12123b9b990b31a909b1da89850&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>Table4/5はSOTAモデルを示す</p>\n<p>encyclopedic knowledge-intensive taskにおいては，BOOLQをのぞき，全てpost-fusionを採用</p>\n<p>commonsense knowledge-intensive taskにおいては，CommonsenseQAをのぞき，全てpre-fusionを採用</p>\n<p>pre-fusionとpost-fusionの違いは何？</p>\n<p>pre-fusionは，知識を事前学習のパラメータに暗示的に保存数る</p>\n<p>最終的にどの知識がパラメータに保存するのかを決定するのは難しい</p>\n<p>知識の引き出しや利用の難しさが増す</p>\n</body>\n</html>\n","Title":"【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","Date":"2023-05-21","Category":"論文","Tags":"survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP","Authos":"ゆうぼう","Slug":"A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/72a3a885-7a2d-4363-ba6b-3371efd274e7/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.49.18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T181845Z&X-Amz-Expires=3600&X-Amz-Signature=4f2395f9c9ae855d53990b80015353bf52b3381b31b93d31fe5fd92cdd60b7a5&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ","Published":true}],"category":"論文","categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net","conda","CSS","dialogue system","dialogue system,Internet-Augmented","dialogue system,knowledge-base","dialogue system,NLI","dialogue system,persona,Prompt-Tuning","dialogue system,survey,DST","DST","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","humor detection,multi-modal","JavaScript","JSON","Kaggle","laughter,shared laughter","Linux","Mac","make","map","MeCab","ML","MT,transformer,Multi-Hop Transformer","multi-modal","MySQL","NLP","Node","node.js","npm","Pandas","Poetry","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","SISR","subprocess","Super-Resolution","survey","survey,dialogue system","survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP","tensorflow","Tkinter","transformer","transformer,Highway Transformer,Gating Mechanism,Self-Dependency-Units (SDU)","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"page":1},"__N_SSG":true}