{"pageProps":{"postData":{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ce8ac11c-bb77-4047-aca2-b3bf53b16368/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.30.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181309Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=0301994b6faf8a478cc24bfc525e20d3f2287e7b133168e2065e9bdb19f52839&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>上の流れで学習して，メンタル状態を外部知識のEmbeddingを利用しながら捉える</p>\n<ol>\n<li>Data Preprocessing</li>\n</ol>\n<ul>\n<li>nltk sentence tokenizerを使ってpostを文区切にする</li>\n<li>→文ごとのmental stateを捉えるため</li>\n</ul>\n<ol start=\"2\">\n<li>Context-aware post (CAP) encoder</li>\n</ol>\n<p>RoBERTaをdomain-specificなデータで学習した<strong>MentalRoBERTa</strong>なるものがあるのでそれを使って，context-awareなエンコーダとして使用する</p>\n<ol start=\"3\">\n<li>Mental satte knowledge infusion</li>\n</ol>\n<p>mental stateの知識を捉えるため，ATOMICで学習されたGPTベースのCOMETを使用する</p>\n<p>理由：</p>\n<p>↑mental stateとmental health conditionの関係を捉えるために，ConceptNetではなくATOMICで学習されたものを使った</p>\n<ul>\n<li>ConceptNet：一般的な言語の概念を含む</li>\n<li>ATOMIC：human interactionを捉えたcommonsenseを含む</li>\n</ul>\n<ol>\n<li>Feature extraction</li>\n</ol>\n<p>以下の5つのaspectを使用した</p>\n<ul>\n<li>intent of S</li>\n<li>effect on S</li>\n<li>reaction of S</li>\n<li>effect on others</li>\n<li>reaction of others</li>\n</ul>\n<p><strong>面白ポイント：COMETのlm_headを削除し，Transformerの内部のみをEncoderとして扱う</strong></p>\n<p>直接的にpost representationをモデルに統合できて，mental-related variablesを適応することが期待できる</p>\n<p>CAP embeddingsによるtoken-level representationは，max poolingによってsentence-level representationとされる</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mover accent=\"true\"><mi>H</mi><mo>^</mo></mover><mi>j</mi><mi>i</mi></msubsup><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi mathvariant=\"normal\">_</mi><mi>p</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>H</mi><mo stretchy=\"false\">[</mo><msubsup><mi>P</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow><mi>i</mi></msubsup><mo>:</mo><msubsup><mi>P</mi><mi>j</mi><mi>i</mi></msubsup><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{H}_j^i = max\\_pooling(H[P_{j-1}^i : P_j^i])</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.3415em;vertical-align:-0.3948em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9468em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span></span><span style=\"top:-3.2523em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.0813em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2194em;vertical-align:-0.3948em;\"></span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">x</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">oo</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">in</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2194em;vertical-align:-0.3948em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mclose\">])</span></span></span></span></span></p>\n<ol start=\"2\">\n<li>Knowledge-aware mentalisation</li>\n</ol>\n<p>5つの独立したGRUを使用して，mentalのaspect毎に学習するスタイル</p>\n<p>これでpost-level representationになる</p>\n<p>その後GRUによるmental aspectごとのpost-level representationとmax poolingされたsentence-level representationをAttentionすることで統合する</p>\n<ol start=\"4\">\n<li>Supervised contrasive learning</li>\n</ol>\n<p>より文章のsemantic meaningに注意して学習するために，contrasive learningを使用した</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6aba2985-13d9-4484-bb9e-da2def220431/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.31.30.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181343Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2d72674319f5c0334a18317851132b44a572c8b43f9f10e79c978732d88bad93&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b6fa8c7b-2c69-4574-b317-258cc41aafc8/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.32.16.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181344Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a43e2c440e21ed2ee9f0d2e5b7093248861ea9dd0368df834bdc6d01c8eb1816&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>新規性</h2>\n<ul>\n<li>mental state knolwedgeを使うことでスピーカー（実験ではpostした人）のmental stateを明示的にモデル化する</li>\n<li>model state knowledgeを理解し，使うモデルの能力を強くするため，knowledge-aware dot-product attentionに基づくmentalisation moduleを導入</li>\n</ul>\n<h2>評価方法</h2>\n<p>baseline</p>\n<ul>\n<li>CNN</li>\n<li>GRU</li>\n<li>BiLSTM_Attn</li>\n<li>LR+Features (Logistic Regression)</li>\n<li>EMO_INF</li>\n<li>BERT</li>\n<li>RoBERTa</li>\n<li>MentalRoBERTa</li>\n</ul>\n<p>Precision / Recall / F1を比較</p>\n<h2>何がすごかった？</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9ae321b3-ac70-408f-8142-e261bac6ede1/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_10.16.17.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181403Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=4ab133115e59b20cb0a4e0d1797a72b51b5078476ef52c15550f4d76b9b1ad0f&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d095eb4-866b-499f-91ff-c36cd97e8669/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_10.16.36.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181407Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=916dcadc9833d97c90f75269bd90c412934b7a911f634cdf11eba3aae13dcc4c&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>label情報を完全に利用するためのsupervised contrasive learningを使用することでclass-specificな特徴量を捉える必要性を議論</li>\n<li>SOTAモデル on three stress and depression detection datasets</li>\n</ul>\n<h2>次に読みたい論文</h2>\n<p>CEM: Commonsense-aware Empathetic Response Generation</p>\n</body>\n</html>\n","Title":"【論文まとめ】A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media","Date":"2023-05-21","Category":"論文","Tags":"COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net","Authos":"ゆうぼう","Slug":"A-mental-state-Knowledge–aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bcd9cf65-a266-4729-a855-f08f28d9578e/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.30.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T181306Z&X-Amz-Expires=3600&X-Amz-Signature=bee4522c1b4c4915939a2f749e0fcab83ac7b62fd4b39ee8fe1038470174fba8&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social mediaのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net","conda","CSS","dialogue system","dialogue system,Internet-Augmented","dialogue system,knowledge-base","dialogue system,NLI","dialogue system,persona,Prompt-Tuning","dialogue system,survey,DST","DST","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","humor detection,multi-modal","JavaScript","JSON","Kaggle","laughter,shared laughter","Linux","Mac","make","map","MeCab","ML","MT,transformer,Multi-Hop Transformer","multi-modal","MySQL","NLP","Node","node.js","npm","Pandas","Poetry","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","SISR","subprocess","Super-Resolution","survey","survey,dialogue system","survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP","tensorflow","Tkinter","transformer","transformer,Highway Transformer,Gating Mechanism,Self-Dependency-Units (SDU)","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"]},"__N_SSG":true}