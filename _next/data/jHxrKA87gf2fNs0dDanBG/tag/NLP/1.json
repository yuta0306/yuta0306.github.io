{"pageProps":{"TaggedPostData":[{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>提案手法</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ce8ac11c-bb77-4047-aca2-b3bf53b16368/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.30.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181309Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=0301994b6faf8a478cc24bfc525e20d3f2287e7b133168e2065e9bdb19f52839&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>上の流れで学習して，メンタル状態を外部知識のEmbeddingを利用しながら捉える</p>\n<ol>\n<li>Data Preprocessing</li>\n</ol>\n<ul>\n<li>nltk sentence tokenizerを使ってpostを文区切にする</li>\n<li>→文ごとのmental stateを捉えるため</li>\n</ul>\n<ol start=\"2\">\n<li>Context-aware post (CAP) encoder</li>\n</ol>\n<p>RoBERTaをdomain-specificなデータで学習した<strong>MentalRoBERTa</strong>なるものがあるのでそれを使って，context-awareなエンコーダとして使用する</p>\n<ol start=\"3\">\n<li>Mental satte knowledge infusion</li>\n</ol>\n<p>mental stateの知識を捉えるため，ATOMICで学習されたGPTベースのCOMETを使用する</p>\n<p>理由：</p>\n<p>↑mental stateとmental health conditionの関係を捉えるために，ConceptNetではなくATOMICで学習されたものを使った</p>\n<ul>\n<li>ConceptNet：一般的な言語の概念を含む</li>\n<li>ATOMIC：human interactionを捉えたcommonsenseを含む</li>\n</ul>\n<ol>\n<li>Feature extraction</li>\n</ol>\n<p>以下の5つのaspectを使用した</p>\n<ul>\n<li>intent of S</li>\n<li>effect on S</li>\n<li>reaction of S</li>\n<li>effect on others</li>\n<li>reaction of others</li>\n</ul>\n<p><strong>面白ポイント：COMETのlm_headを削除し，Transformerの内部のみをEncoderとして扱う</strong></p>\n<p>直接的にpost representationをモデルに統合できて，mental-related variablesを適応することが期待できる</p>\n<p>CAP embeddingsによるtoken-level representationは，max poolingによってsentence-level representationとされる</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mover accent=\"true\"><mi>H</mi><mo>^</mo></mover><mi>j</mi><mi>i</mi></msubsup><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi mathvariant=\"normal\">_</mi><mi>p</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>H</mi><mo stretchy=\"false\">[</mo><msubsup><mi>P</mi><mrow><mi>j</mi><mo>−</mo><mn>1</mn></mrow><mi>i</mi></msubsup><mo>:</mo><msubsup><mi>P</mi><mi>j</mi><mi>i</mi></msubsup><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{H}_j^i = max\\_pooling(H[P_{j-1}^i : P_j^i])</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.3415em;vertical-align:-0.3948em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9468em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span></span><span style=\"top:-3.2523em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1944em;\"><span class=\"mord\">^</span></span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.0813em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2194em;vertical-align:-0.3948em;\"></span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">x</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">oo</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">in</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2194em;vertical-align:-0.3948em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.05724em;\">j</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3948em;\"><span></span></span></span></span></span></span><span class=\"mclose\">])</span></span></span></span></span></p>\n<ol start=\"2\">\n<li>Knowledge-aware mentalisation</li>\n</ol>\n<p>5つの独立したGRUを使用して，mentalのaspect毎に学習するスタイル</p>\n<p>これでpost-level representationになる</p>\n<p>その後GRUによるmental aspectごとのpost-level representationとmax poolingされたsentence-level representationをAttentionすることで統合する</p>\n<ol start=\"4\">\n<li>Supervised contrasive learning</li>\n</ol>\n<p>より文章のsemantic meaningに注意して学習するために，contrasive learningを使用した</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/6aba2985-13d9-4484-bb9e-da2def220431/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.31.30.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181343Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2d72674319f5c0334a18317851132b44a572c8b43f9f10e79c978732d88bad93&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b6fa8c7b-2c69-4574-b317-258cc41aafc8/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.32.16.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181344Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a43e2c440e21ed2ee9f0d2e5b7093248861ea9dd0368df834bdc6d01c8eb1816&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<h2>新規性</h2>\n<ul>\n<li>mental state knolwedgeを使うことでスピーカー（実験ではpostした人）のmental stateを明示的にモデル化する</li>\n<li>model state knowledgeを理解し，使うモデルの能力を強くするため，knowledge-aware dot-product attentionに基づくmentalisation moduleを導入</li>\n</ul>\n<h2>評価方法</h2>\n<p>baseline</p>\n<ul>\n<li>CNN</li>\n<li>GRU</li>\n<li>BiLSTM_Attn</li>\n<li>LR+Features (Logistic Regression)</li>\n<li>EMO_INF</li>\n<li>BERT</li>\n<li>RoBERTa</li>\n<li>MentalRoBERTa</li>\n</ul>\n<p>Precision / Recall / F1を比較</p>\n<h2>何がすごかった？</h2>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9ae321b3-ac70-408f-8142-e261bac6ede1/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_10.16.17.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181403Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=4ab133115e59b20cb0a4e0d1797a72b51b5078476ef52c15550f4d76b9b1ad0f&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8d095eb4-866b-499f-91ff-c36cd97e8669/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_10.16.36.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181407Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=916dcadc9833d97c90f75269bd90c412934b7a911f634cdf11eba3aae13dcc4c&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>label情報を完全に利用するためのsupervised contrasive learningを使用することでclass-specificな特徴量を捉える必要性を議論</li>\n<li>SOTAモデル on three stress and depression detection datasets</li>\n</ul>\n<h2>次に読みたい論文</h2>\n<p>CEM: Commonsense-aware Empathetic Response Generation</p>\n</body>\n</html>\n","Title":"【論文まとめ】A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social media","Date":"2023-05-21","Category":"論文","Tags":"COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net","Authos":"ゆうぼう","Slug":"A-mental-state-Knowledge–aware-and-Contrastive-Network-for-early-stress-and-depression-detection-on-social-media","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bcd9cf65-a266-4729-a855-f08f28d9578e/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-05-12_9.30.20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T181306Z&X-Amz-Expires=3600&X-Amz-Signature=bee4522c1b4c4915939a2f749e0fcab83ac7b62fd4b39ee8fe1038470174fba8&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"A mental state Knowledge–aware and Contrastive Network for early stress and depression detection on social mediaのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<p>まとめること</p>\n<ol>\n<li>Knowledge-Intensive NLPの概要</li>\n<li>Knowledge Sources</li>\n<li>Encyclopedic Knowledge</li>\n<li>Commonsense Knowledge</li>\n<li>最近のKnowledge Sourcesの特徴</li>\n<li>Knowledge-Intensive NLP Task</li>\n<li>Knowledge-Intensive NLP Taskの概要</li>\n<li>Knowledge-Intensive NLP Taskの特徴</li>\n<li>Knowledge Fusion Methodsについて</li>\n<li>Pre-Fusion Methods</li>\n<li>Post-Fusion Methods</li>\n<li>Hybrid-Fusion Methods</li>\n<li>代表的なモデルの紹介</li>\n<li>Challengingなことと今後の方向性</li>\n<li>Unified PLMKEs Across Tasks and Domains</li>\n<li>Reliability of Knowledge Sources</li>\n<li>Reasoning Module Design</li>\n</ol>\n<h2>概要</h2>\n<p>事前学習済みモデルにより，モデルのcapacityは増加傾向にあるが，encyclopedicやcommonsenseを用いた，knowledgeableなNLPモデルの需要の高まりが生じている</p>\n<p>**PLMKEs (Pre-trained Language Model-based Knowledge-Enhanced models)**についてまとめたsurvey論文</p>\n<p>linguistic or factual knowledgeは暗示的にモデルのパラメータに保存される</p>\n<p>→事前学習済みのNLPモデルがより汎用的な能力を持つことを一部ではあるが説明できる</p>\n<p>今のpre-trained LMは，明示的なencyclopedicやcommonsenseのレバレッジ能力に欠けている</p>\n<p>PLMKEsは，関連する外部知識を取り出すモジュールと知識を混ぜるモジュールがある</p>\n<p>PLMKEsに関連した重要な3つの要素がある</p>\n<ol>\n<li>Knowledge Sources</li>\n<li>Knowledge-Intensive NLP Tasks</li>\n<li>Knowledge Fusion Methods</li>\n</ol>\n<h2>Knowledge Sources</h2>\n<h3>Encyclopedic knowledge</h3>\n<p>エンティティに関する属性とエンティティ間の関係性をもった知識</p>\n<p>Entity: person → Attributes: age → Relations: educated at</p>\n<p>Wikipediaは大量のencyclopedicな知識を持っている</p>\n<p>人物の経歴やイベントの背景などを含んでいる</p>\n<p>一般的にはtripletsで構成されていることが多い</p>\n<p>e.g. &#x3C;Tom Hanks, occupation, actor></p>\n<p>Wikidataのような知識データがPLMKEsに広く使用されている</p>\n<h3>Commonsense Knowledge</h3>\n<p>日常生活のなかでの状況に関する知識</p>\n<p>イベントとその影響を記す</p>\n<p>e.g. mop up the floor if we split food over it / study hard to win scholarship / goat has four legs</p>\n<p>commonsenseの特徴</p>\n<p>多くの人の間で共有されている知識であり，コミュニケーションの中で暗示的に想定されている知識である</p>\n<p>commonsenseもtripletsで表現される</p>\n<p>最近のPLMKEsでは，ConceptNetとATOMICが外部知識として使用されることが多い</p>\n<h3>Knowledge Sourcesの特徴</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/30b21e96-66e9-4c93-b612-2a5ec35b43c9/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_16.42.16.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181930Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=a08e0cc46127ef5b006be5eca7349c3b4f203325cb4dd1c39cb9757131c24c8e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>large-scaleでdiverse</p>\n<p>現在のソースはより正確で安定的に作られている</p>\n<p>アノテーションのプロセスは部分的に自動化されていて，非エキスパートにもaccessibleになっている</p>\n<p>知識データがカバーするドメインは多様</p>\n<p>オープンドメインのものもあれば，specificなドメインのものも</p>\n<p>Wikipedia, DBPedia, Freebaseなどはオープンドメイン</p>\n<p>UMLSやAMinerなどはbiomedicineやscienceの特定ドメイン</p>\n<p>domain-specificなアプリケーションをブーストできる知識</p>\n<p>commonsenseに関しては</p>\n<p>ConceptNetやTransOMCSは複数のドメインのcommonsenseをカバー</p>\n<p>ATOMICやASERはある特定のタイプのcommonsenseにフォーカスした知識ソース</p>\n<h2>Knowledge-Intensive NLP Task</h2>\n<h3>概要</h3>\n<p>Knowledge-intensive NLP taskは必要とする知識ソースの種類で2つに分けられ，さらに詳細に分けることができる</p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ab23c756-9f8e-4f3c-a76c-cdd674276022/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.02.12.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181947Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b76560af21a3c08235665cc245c16fb63334660f36a2530535b06fa485395991&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>encyclopedic knowledge-intensive NLP task</li>\n</ul>\n<p>encyclopedicの知識ソースを利用する</p>\n<ul>\n<li>open-domain QA</li>\n<li>fact verification</li>\n<li>entity linking</li>\n</ul>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/28ba511c-8fa2-4031-9624-7a7460f25913/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.02.31.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T181952Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=b0c31adc0b4a7f7ea85b0fe08456ba8559910988866d93f039288cbd4421f3a6&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<ul>\n<li>commonsense knowledge-intensive NLP task</li>\n</ul>\n<p>commonsenseの知識ソースを利用する</p>\n<p>commonsenseの多様性のために，タスクのタイプ自体も多様化している</p>\n<p>モデルが正確に日常のシナリオを理解し，応答するか否かのテストにフォーカスしたタスク</p>\n<ul>\n<li>General Commonsense</li>\n<li>Social Commonsense</li>\n<li>Physical Commonsense</li>\n<li>Temporal Commonsense</li>\n</ul>\n<h3>Knowledge-Intensive Taskの特徴</h3>\n<p>実際は，モデルにとってだけではなく，人間にとってもいかなる知識の参照なしに問題に答えるのは難しい．（バラクオバマの誕生日はいつ？など</p>\n<p>しかも，外部知識が必要なのにinputとして必要な外部知識が渡されないため，とてもチャレンジングなタスクになっている</p>\n<p>そもそも必要な外部知識にグラウンディングするモジュールをPLMKEsの設計に加えることを考慮するようになっている</p>\n<h2>Knowledge Fusion Methods</h2>\n<p>モデルが知識を統合するステージは二箇所あり，</p>\n<ul>\n<li>Pre-fusion; pre-training</li>\n<li>Post-fusion; fine-tuning</li>\n</ul>\n<p>の二通りが考えられる（もしくはその両方のステージ</p>\n<h3>Pre-Fusion Methods</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ddeea37a-3062-47f7-b3ac-15057b8a1349/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.11.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182017Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=914d261462ed9d88bc35c4edfa5d080b2ffe29c48a555d3ffe8d9407c9fc70a8&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>pre-trainingのステージで知識を統合する手法</p>\n<p>モデルに知識を入力するため，構造化された知識データを非構造化データのテキストコーパスへと処理→モデルに入力</p>\n<p>テキストデータとして知識を入力するため，大きくモデルのアーキテクチャを変更する必要はない</p>\n<p>ただし，知識グラフのような構造化データを非構造化データへ変えることは難しいこともある</p>\n<p>簡単な対処法はエンティティと関係性を結合するか，流暢な文章をconditional text generation modelに生成させるか</p>\n<p>Zhang et al. 2019 | Agarwal et al. 2021 を参照（必要になれば読む</p>\n<h3>Post-Fusion Methods</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a978299c-4851-41c8-a702-a3aafb0f9323/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_17.37.53.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182027Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=e4e8f6a6703612a8f1118eb67304d93279f45d48fff78fd6f0b2c2d8b2b5a063&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>まず，関連知識をキャプチャする</p>\n<p>次に取得した関連知識をGNNなどのエンコーダでembeddingを得る</p>\n<ul>\n<li>それを追加特徴量としてpre-trained LMに与える（図でいうA）</li>\n<li>直接pre-trained LMに入力する（図でいうB）</li>\n</ul>\n<h3>Hybrid-Fusion Methods</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b696904a-be2b-4bd8-9d93-ca87a47ecc5e/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_19.38.22.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182031Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=8c309aba75c92d449b843fead794f87d2bd0340923faeef77c381a33ab5eb82e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>pre-trainingとfine-tuningの両方のステージで知識を統合する</p>\n<p>追加の学習されるretrieverによりaugmentされたpre-trained modelは，fine-tuningのステージでより効果的にretrieverからの知識を活用できる</p>\n<p>retrieval-augmented pre-trainingでhybrid-fusionが広く使われている</p>\n<h3>代表的なモデル</h3>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ce1f044a-ba15-4c30-8d61-eab525800d9d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-26_19.39.00.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182039Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=2bfc9853f1a4e6bff019baa7c3effe98a1c01a806e603f05131576021c53bf3e&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p><img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/81d13c12-2379-4709-bc00-97fd4185fd4b/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-31_12.00.11.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&#x26;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&#x26;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&#x26;X-Amz-Date=20230521T182039Z&#x26;X-Amz-Expires=3600&#x26;X-Amz-Signature=3f15cc31ed578332b99f8185529710bceec9e12123b9b990b31a909b1da89850&#x26;X-Amz-SignedHeaders=host&#x26;x-id=GetObject\" alt=\"\"></p>\n<p>Table4/5はSOTAモデルを示す</p>\n<p>encyclopedic knowledge-intensive taskにおいては，BOOLQをのぞき，全てpost-fusionを採用</p>\n<p>commonsense knowledge-intensive taskにおいては，CommonsenseQAをのぞき，全てpre-fusionを採用</p>\n<p>pre-fusionとpost-fusionの違いは何？</p>\n<p>pre-fusionは，知識を事前学習のパラメータに暗示的に保存数る</p>\n<p>最終的にどの知識がパラメータに保存するのかを決定するのは難しい</p>\n<p>知識の引き出しや利用の難しさが増す</p>\n</body>\n</html>\n","Title":"【論文まとめ】A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","Date":"2023-05-21","Category":"論文","Tags":"survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP","Authos":"ゆうぼう","Slug":"A-Survey-of-Knowledge-Intensive-NLP-with-Pre-Trained-Language-Models","Thumbnail":"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/72a3a885-7a2d-4363-ba6b-3371efd274e7/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2022-03-22_17.49.18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230521%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230521T181845Z&X-Amz-Expires=3600&X-Amz-Signature=4f2395f9c9ae855d53990b80015353bf52b3381b31b93d31fe5fd92cdd60b7a5&X-Amz-SignedHeaders=host&x-id=GetObject","Description":"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Modelsのまとめ","Published":true},{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>コーパスとは</h2>\n<p>**コーパス(corpus)**とは、集めた文書のことをいいます。</p>\n<p>もともとの原義としては、ある主題とかある作者に関する文書を集めたものがコーパスと呼ばれていたそうです。</p>\n<p>現在はもう少し広義で捉えられ、<strong>文書や音声を集めたデータそのもの、あるいはデータに情報を付与して加工したもの</strong>を総称してコーパスというそうです。</p>\n<p>最近の自然言語処理のタスクの進展は、このコーパスに活用による部分が多いです。</p>\n<h2>生コーパス(raw corpus)</h2>\n<p>前のセクションで話したように、コーパスには加工を加えたものと、そのまま生データのものと二通り考えられました。</p>\n<p>そこで、生データのままの文章や音声を「<strong>生コーパス(raw corpus)</strong>」と呼ぶことができます。</p>\n<h2>翻訳に関するコーパスの分類</h2>\n<p>生コーパスの中でも、その種はいくつか存在します。\nこのトピックでは機械翻訳で扱われるようなコーパスの分類についてお話します。</p>\n<h2>#対訳コーパス／パラレルコーパス</h2>\n<p>まずは、「<strong>対訳コーパス(bilingual corpus)</strong>」または「<strong>パラレルコーパス(parallel corpus)</strong>」です。</p>\n<p>この対訳コーパスとは、翻訳関係にある2言語の文書対を収集した生コーパスになります。このコーパスは、非常に貴重ではありますが、なかなか入手しにくい希少なデータです。しかし、この対訳コーパスは機械翻訳においてとても重要な知識源となっていることは確かです。</p>\n<h2>#コンパラブルコーパス</h2>\n<p>対訳コーパスでは、希少なコーパスであったのに対して、  「<strong>コンパラブルコーパス(comparable corpus)</strong>」は、しっかりとした対訳関係にないにしても、同じトピックに関して2言語の文書対のコーパスです。</p>\n<p>コンパラブルコーパスは、対訳コーパスほどきっちりとした対訳が制約されないので、このような文書は大量に存在します。これらの文書を収集したものがコンパラブルコーパスです。</p>\n<p>例としてわかりやすいのは、Wikipedeaでしょう。  Wikipediaでは言語リンクでつながった複数の言語でのページが存在します。これらの文書対ではきっちりとした対訳は保証されませんが、大量のデータを入手することができ、これも極めて重要な知識源となります。</p>\n<h2>まとめ</h2>\n<p>以上がコーパスに関する簡単な説明でした。他にも均衡コーパス(balanced corpus)や注釈コーパス(annotated corpus)といった分類もあります。</p>\n<p>ここで抑えるべき重要なことは、コーパスとは広義で<strong>文書や音声を集めたデータそのもの、あるいはデータに情報を付与して加工したもの</strong>ということでしょう。</p>\n<p>今回は主にコーパスの説明とともに生コーパスについての説明をしていきました。実際に加工を加えたコーパスに関しては、また別の記事にしたいと思います!</p>\n</body>\n</html>\n","Title":"自然言語処理(NLP)のコーパスって何なん？","Date":"2020-07-11","Category":"ML","Tags":["ML","NLP"],"Authors":"ゆうぼう","Slug":"corpus","Thumbnail":"/images/thumbnails/network.jpg","Description":"自然言語処理という機械学習のタスクにおいて「コーパス」という言葉が出てきます。そのコーパスについてお話をしていきます。","Published":true}],"tag":"NLP","categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET,mental health,NLP,mental state knowledge,mentalisation,Contrasive Learning,MentalRoBERTa,KC-Net","conda","CSS","dialogue system","dialogue system,Internet-Augmented","dialogue system,knowledge-base","dialogue system,NLI","dialogue system,persona,Prompt-Tuning","dialogue system,survey,DST","ESPNet","ffmpeg","Flask","Go","Google Colaboratory","Heroku","HTML","humor detection,multi-modal","JavaScript","JSON","Kaggle","laughter,shared laughter","Linux","Mac","make","map","MeCab","ML","MT,transformer,Multi-Hop Transformer","MySQL","NLP","Node","node.js","npm","Pandas","Poetry","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","SISR","subprocess","Super-Resolution","survey,dialogue system","survey,NLP,knowledge-base,PLMKE,commonsense,encyclopedic,Knowledge-Intensive NLP","tensorflow","Tkinter","transformer,Highway Transformer,Gating Mechanism,Self-Dependency-Units (SDU)","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"],"pages":1,"page":1},"__N_SSG":true}