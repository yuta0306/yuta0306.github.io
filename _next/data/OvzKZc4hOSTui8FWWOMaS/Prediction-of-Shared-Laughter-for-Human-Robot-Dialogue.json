{"pageProps":{"postData":{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>提案手法</h2>\n<p>会話ロボットがshared laughterを自動生成することを目的にする</p>\n<h3>Shared Laughter Model</h3>\n<p><img src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/ubc1bfll.png\" alt=\"\"></p>\n<p>ユーザの最初の笑いを検知して，システムが笑うモデル</p>\n<p>3種類のモジュールが存在する</p>\n<ol>\n<li>ユーザの最初の笑いを検出</li>\n<li>shared laughterを生成するかどうかを決定</li>\n<li>どのタイプの笑いをするべきか決定</li>\n</ol>\n<h3>Data Collection and Analysis</h3>\n<p>収集方法：ERICA</p>\n<p>teleoperateしたのは女性</p>\n<p>対象：61人の男性</p>\n<p>シナリオ：speed dating</p>\n<p>好きな趣味，好きなこと，嫌いなことに関してカジュアルなチャット</p>\n<p>アノテーション：</p>\n<p>2種類のタイプに笑いを分けた</p>\n<ol>\n<li>isolated laugh\n1. 笑い単体で起こる笑い</li>\n<li>speech laugh\n1. 話しながら起こる笑い\n<img src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/xjk3e31y.png\" alt=\"\"></li>\n</ol>\n<p><img src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/tlll3y5c.png\" alt=\"\"></p>\n<p>集まったデータの中で，1206件のinitial laughが確認</p>\n<p>698件がself laughで508件がshared laugh</p>\n<h3>Model Creation</h3>\n<p>特徴量2種類：</p>\n<p><strong>Audio-based features</strong></p>\n<p>40のacoustic メルフィルタバンクの平均と標準偏差</p>\n<p><strong>Prosodic features</strong></p>\n<p>全IPUにまたがるピッチとパワーの値を使った合計で14つの以下の指標</p>\n<p>平均／中央値／標準偏差／最大値／最小値／範囲</p>\n<p><strong>モデル</strong>：</p>\n<p>LR／SVM</p>\n<p>データサンプルが小さかったからか，deep learningの手法は弱かった</p>\n<h2>新規性</h2>\n<p>ユーザに合わせて毎回笑いを生成するのではなく，適切なタイミングでshared laughterを自動生成することをロボットに持たせたいという目的をもった研究</p>\n<h2>評価方法</h2>\n<p><img src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/9wovt6te.png\" alt=\"\"></p>\n<p>オフラインとオンラインの二つのタイプで評価</p>\n<p><img src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/uj5g5yqc.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue/hgmm1f5x.png\" alt=\"\"></p>\n<p>特徴量としてlaughter typeを加えることでrecallが改善する傾向</p>\n<p>負に歪んだピッチの分布の時は笑いがシェアされがちで笑いが長く続きがち</p>\n<p>laughter detectionとlaugh type classificationのエラーによってパフォーマンスが落ちることは明らかだが，それでもベースラインをoutperform</p>\n<p>最もよかったonline modelはacousticとprosodicの特徴量を両方使ったもの</p>\n<h2>何がすごかった？</h2>\n<p>prosodicの分析からわかったことが，initial laughのacousiticsはresponse laughを呼び起こすいくつかの特徴があること</p>\n<p>まだ改善の余地はあるものの，acousticとprosodicの特徴量の両方を使うことはパフォーマンスの改善に役立った</p>\n<p>shared laughterのタイミングについてはかけた研究である</p>\n<p>今後の課題である</p>\n<h2>次に読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】Prediction of Shared Laughter for Human-Robot Dialogue","Date":"2023-05-21","Category":"論文","Tags":["laughter","shared laughter"],"Authos":"ゆうぼう","Slug":"Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue","Thumbnail":"/images/thumbnails/Prediction-of-Shared-Laughter-for-Human-Robot-Dialogue.png","Description":"Prediction of Shared Laughter for Human-Robot Dialogueのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","CSS","dialogue system","DST","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"]},"__N_SSG":true}