{"pageProps":{"postData":{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<h2>概要</h2>\n<p>検索クエリを生成し，Bing検索の結果をもとに応答生成を行うことで，大規模言語モデルの抱えるhallucinationの問題を軽減しつつ，up-to-the-minute relavent informationを導入した生成を可能にする．</p>\n<p>インターネットによるaugmentationを行わないモデルやFAISSベースのモデルよりも，search-queryのモデルは優れた会話能力を達成した．</p>\n<h2>提案手法</h2>\n<p>提案手法 (Search Engine-Augmented Generation) の流れ</p>\n<ol>\n<li>コンテクストから検索クエリを生成</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span>個のドキュメントを取得</li>\n<li>FiD (Fusion in Decoder)モデルによって，個々のドキュメントをエンコードし，対話コンテクストと結合して，応答を生成</li>\n</ol>\n<p>インターネットへのアクセスの手法</p>\n<ol>\n<li><strong>FAISS: distributed approximate nearest-neighbor databaseにストアすることでページをキャッシュ</strong>\n<ol>\n<li>これがベースライン的な手法</li>\n<li>Common CrawlのデータをFAISSストアして検索をかける</li>\n<li>ベースライン手法\n<ol>\n<li>RAG (Retrieval Augmented Generation)</li>\n<li>FiD (Fusion in Decoder)</li>\n<li>FiD-RAG</li>\n<li>FAISS + Search Query-based Retrieval</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><strong>インターネットに直接アクセスしてページを取得</strong>\n<ol>\n<li>FAISS-basedの手法の課題を解決するため\n<ol>\n<li>リアルタイムなウェブ情報に更新するのが難しい</li>\n<li>ローカルのFAISSにストアできるウェブページの数には限界がある</li>\n<li>インターネット検索エンジンがチューニングしているハイクオリティなページのランキングの利点を活かせない</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2>新規性</h2>\n<ul>\n<li>インターネットにアクセスすることで，常に数え切れないほどの最新の情報にアクセスし，それを取り入れた応答生成を可能にする</li>\n<li>knowledge regulationなどを行うことで，dynamic state of the worldに対応する\n<ul>\n<li>大規模言語モデルは，知識をweightsの中で記憶してしまうため，hallucinationが起きやすい→これを正則化によってよりうまく情報をcopyするように学習させる</li>\n</ul>\n</li>\n<li>長い目で見れば機械学習の手法は実世界とのインタラクションが求められるが，まず自然な第一ステップとしてインターネットへのアクセスをモデル化してみた．</li>\n</ul>\n<h2>実験</h2>\n<p>Wizard of the Internet (WizInt)という新たなタスクで評価</p>\n<p>T5, BART-large, BlenderBotをファインチューニング</p>\n<p>Retrieval-augmented methodは5つのドキュメント (<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">N = 5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">5</span></span></span></span></span>) を使用</p>\n<p>デコーダ</p>\n<p>ビームサーチ with ビームサイズ = 3</p>\n<p>最小sequence length = 20</p>\n<p>beam blocking ngram = 3</p>\n<p>評価指標</p>\n<p>PPL</p>\n<p>F1</p>\n<p>gold responseとのオーバーラップを評価</p>\n<p>Knowledge F1 (KF1)</p>\n<p>モデルの応答と人間がデータ収集時に使った知識のオーバーラップを評価</p>\n<p>→ F1とKF1はトレードオフ</p>\n<p>KF1が高く，F1が低いと知識には富んでいるが，会話能力は低</p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/lt8850nl.png\" alt=\"\"></p>\n<p>Table 3からBART-largeを全てのモデルのPLMベースとして採用</p>\n<h2>まとめ</h2>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/tbyqxztp.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/wyjx5nat.png\" alt=\"\"></p>\n<p>対話生成のプロセスにインターネットの情報を与えると，人との対話においてより事実との不整合の少ない情報を生成することができる</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h3>Datasetの概要</h3>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/icteiwo8.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/mbvtnn6p.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/spel8pnl.png\" alt=\"\"></p>\n<p>Wizard vs apprentice (Figure 3がペルソナ設定のインターフェース)</p>\n<p>Wizardは対話しながらネット検索ができる</p>\n<p>→検索された結果をアノテーションし，適切な検索結果が得られなければもう一度検索でき，検索結果を無視することも可能</p>\n<p>Apprenticeはペルソナを選び，そのもとでチャット</p>\n<p>ペルソナはPersona-ChatとTopical-Chatデータセットに含まれるペルソナから選択</p>\n<h3>データ収集インターフェース</h3>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/22i3jadd.png\" alt=\"\"></p>\n<h3>対話例</h3>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/7mtbmihj.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/cnh8ewk2.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/rl5n1b19.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/isojpxom.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/ku1jmqb4.png\" alt=\"\"></p>\n<h2>次読みたい論文</h2>\n</body>\n</html>\n","Title":"【論文まとめ】Internet-Augmented Dialogue Generation","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","Internet-Augmented"],"Authos":"ゆうぼう","Slug":"Internet-Augmented-Dialogue-Generation","Thumbnail":"/images/thumbnails/Internet-Augmented-Dialogue-Generation.png","Description":"Internet-Augmented Dialogue Generationのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","CSS","dialogue system","DST","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"]},"__N_SSG":true}