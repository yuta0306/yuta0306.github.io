{"pageProps":{"postData":{"contentHtml":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.15.0/dist/katex.min.css\">\n</head>\n<body>\n<p>本記事において使用される図表は，原著論文内の図表を引用しています．</p>\n<p>また，本記事の内容は，著者が論文を読み，メモとして短くまとめたものになります．必ずしも内容が正しいとは限らないこと，ご了承ください．</p>\n<h2>論文情報</h2>\n<p>タイトル: Internet-Augmented Dialogue Generation</p>\n<p>研究会: ACL</p>\n<p>年度: 2022</p>\n<p>キーワード: dialogue system, Internet-Augmented</p>\n<p>URL: <a href=\"https://aclanthology.org/2022.acl-long.579.pdf\">https://aclanthology.org/2022.acl-long.579.pdf</a></p>\n<p>DOI: <a href=\"http://dx.doi.org/10.18653/v1/2022.acl-long.579\">http://dx.doi.org/10.18653/v1/2022.acl-long.579</a></p>\n<p>データセット: Topical-Chat, Wizard of Wikipedia</p>\n<h2>概要</h2>\n<p>検索クエリを生成し，Bing検索の結果をもとに応答生成を行うことで，大規模言語モデルの抱えるhallucinationの問題を軽減しつつ，up-to-the-minute relavent informationを導入した生成を可能にする．</p>\n<p>インターネットによるaugmentationを行わないモデルやFAISSベースのモデルよりも，search-queryのモデルは優れた会話能力を達成した．</p>\n<h2>提案手法</h2>\n<p>提案手法 (Search Engine-Augmented Generation) の流れ</p>\n<ol>\n<li>コンテクストから検索クエリを生成</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span>個のドキュメントを取得</li>\n<li>FiD (Fusion in Decoder)モデルによって，個々のドキュメントをエンコードし，対話コンテクストと結合して，応答を生成</li>\n</ol>\n<p>インターネットへのアクセスの手法</p>\n<ol>\n<li><strong>FAISS: distributed approximate nearest-neighbor databaseにストアすることでページをキャッシュ</strong>\n<ol>\n<li>これがベースライン的な手法</li>\n<li>Common CrawlのデータをFAISSストアして検索をかける</li>\n<li>ベースライン手法\n<ol>\n<li>RAG (Retrieval Augmented Generation)</li>\n<li>FiD (Fusion in Decoder)</li>\n<li>FiD-RAG</li>\n<li>FAISS + Search Query-based Retrieval</li>\n</ol>\n</li>\n</ol>\n</li>\n<li><strong>インターネットに直接アクセスしてページを取得</strong>\n<ol>\n<li>FAISS-basedの手法の課題を解決するため\n<ol>\n<li>リアルタイムなウェブ情報に更新するのが難しい</li>\n<li>ローカルのFAISSにストアできるウェブページの数には限界がある</li>\n<li>インターネット検索エンジンがチューニングしているハイクオリティなページのランキングの利点を活かせない</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2>新規性</h2>\n<ul>\n<li>インターネットにアクセスすることで，常に数え切れないほどの最新の情報にアクセスし，それを取り入れた応答生成を可能にする</li>\n<li>knowledge regulationなどを行うことで，dynamic state of the worldに対応する\n<ul>\n<li>大規模言語モデルは，知識をweightsの中で記憶してしまうため，hallucinationが起きやすい→これを正則化によってよりうまく情報をcopyするように学習させる</li>\n</ul>\n</li>\n<li>長い目で見れば機械学習の手法は実世界とのインタラクションが求められるが，まず自然な第一ステップとしてインターネットへのアクセスをモデル化してみた．</li>\n</ul>\n<h2>実験</h2>\n<p>Wizard of the Internet (WizInt)という新たなタスクで評価</p>\n<p>T5, BART-large, BlenderBotをファインチューニング</p>\n<p>Retrieval-augmented methodは5つのドキュメント (<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">N = 5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">5</span></span></span></span></span>) を使用</p>\n<p>デコーダ</p>\n<p>ビームサーチ with ビームサイズ = 3</p>\n<p>最小sequence length = 20</p>\n<p>beam blocking ngram = 3</p>\n<p>評価指標</p>\n<p>PPL</p>\n<p>F1</p>\n<p>gold responseとのオーバーラップを評価</p>\n<p>Knowledge F1 (KF1)</p>\n<p>モデルの応答と人間がデータ収集時に使った知識のオーバーラップを評価</p>\n<p>→ F1とKF1はトレードオフ</p>\n<p>KF1が高く，F1が低いと知識には富んでいるが，会話能力は低</p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/l7s7sphq.png\" alt=\"\"></p>\n<p>Table 3からBART-largeを全てのモデルのPLMベースとして採用</p>\n<h2>まとめ</h2>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/ixgpnink.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/128zhnye.png\" alt=\"\"></p>\n<p>対話生成のプロセスにインターネットの情報を与えると，人との対話においてより事実との不整合の少ない情報を生成することができる</p>\n<h2>その他（なぜ通ったか？等）</h2>\n<h3>Datasetの概要</h3>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/c1e96cpy.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/upaxz8vo.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/w6dyemsg.png\" alt=\"\"></p>\n<p>Wizard vs apprentice (Figure 3がペルソナ設定のインターフェース)</p>\n<p>Wizardは対話しながらネット検索ができる</p>\n<p>→検索された結果をアノテーションし，適切な検索結果が得られなければもう一度検索でき，検索結果を無視することも可能</p>\n<p>Apprenticeはペルソナを選び，そのもとでチャット</p>\n<p>ペルソナはPersona-ChatとTopical-Chatデータセットに含まれるペルソナから選択</p>\n<h3>データ収集インターフェース</h3>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/z4f9ivph.png\" alt=\"\"></p>\n<h3>対話例</h3>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/xaxs9n1p.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/7wk8s9an.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/gktrd3cq.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/5onmd3g5.png\" alt=\"\"></p>\n<p><img src=\"/images/article/Internet-Augmented-Dialogue-Generation/el45rvtq.png\" alt=\"\"></p>\n<h2>次読みたい論文</h2>\n<h2>引用</h2>\n<blockquote>\n<p>@inproceedings{komeili-etal-2022-internet,</p>\n</blockquote>\n<p>title = \"{I}nternet-Augmented Dialogue Generation\",\nauthor = \"Komeili, Mojtaba and\nShuster, Kurt and\nWeston, Jason\",\nbooktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\nmonth = may,\nyear = \"2022\",\naddress = \"Dublin, Ireland\",\npublisher = \"Association for Computational Linguistics\",\nurl = \"<a href=\"https://aclanthology.org/2022.acl-long.579\">https://aclanthology.org/2022.acl-long.579</a>\",\ndoi = \"10.18653/v1/2022.acl-long.579\",\npages = \"8460--8478\",\nabstract = \"The largest store of continually updating knowledge on our planet can be accessed via internet search. In this work we study giving access to this information to conversational agents. Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue (Shuster et al., 2021); moreover, those facts are frozen in time at the point of model training. In contrast, we propose an approach that learns to generate an internet search query based on the context, and then conditions on the search results to finally generate a response, a method that can employ up-to-the-minute relevant information. We train and evaluate such models on a newly collected dataset of human-human conversations whereby one of the speakers is given access to internet search during knowledgedriven discussions in order to ground their responses. We find that search-query based access of the internet in conversation provides superior performance compared to existing approaches that either use no augmentation or FAISS-based retrieval (Lewis et al., 2020b).\",\n}</p>\n</body>\n</html>\n","Title":"【論文まとめ】Internet-Augmented Dialogue Generation","Date":"2023-05-21","Category":"論文","Tags":["dialogue system","Internet-Augmented"],"Authos":"ゆうぼう","Slug":"Internet-Augmented-Dialogue-Generation","Thumbnail":"/images/thumbnails/Internet-Augmented-Dialogue-Generation.png","Description":"Internet-Augmented Dialogue Generationのまとめ","Published":true},"categories":["論文","Web","JavaScript","Competition","Cloud","Linux","Python","ML","Go","SQL"],"tags":["Apache","Appium","atmaCup","AWS","CentOS7","CentOS8","Colab","COMET","commonsense","conda","Contrasive Learning","CSS","dialogue system","DST","empathetic dialogue system","encyclopedic","ESPNet","ffmpeg","Flask","Gating Mechanism","Go","Google Colaboratory","Heroku","Highway Transformer","HTML","humor detection","Internet-Augmented","JavaScript","JSON","Kaggle","KC-Net","knowledge-base","Knowledge-Intensive NLP","laughter","Linux","Mac","make","map","MeCab","mental health","mental state knowledge","mentalisation","MentalRoBERTa","ML","MT","Multi-Hop Transformer","multi-modal","MySQL","NLI","NLP","Node","node.js","npm","Pandas","persona","PLMKE","Poetry","Prompt-Tuning","Python","Pytorch","pytorch-lightning","Scikit-learn","Selenium","Self-Dependency-Units (SDU)","shared laughter","SISR","subprocess","Super-Resolution","survey","tensorflow","Tkinter","transformer","zsh","オブジェクト指向","デコレータ","データ分析","特殊メソッド","超解像"]},"__N_SSG":true}