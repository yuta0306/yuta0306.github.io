---
Title: 'atmaCup#10大反省会(Public: 137位/Private: 130位)'
Date: '2021-03-14'
Category: Competition
Tags: [Python, データ分析, atmaCup]
Authors: ゆうぼう
Slug: atmacup10-feedback
Thumbnail: /images/thumbnails/atma%2310.png
Description: 'atmaCup#10に参加しました。しっかりとコンペにフルコミットしたのは今回が初めてなので、ほぼ初参加と言っていいでしょう。しかし、結果はPublic: 137位でPrivate: 130位(+7)というクソ雑魚結果に...。これは大反省会をして次に生かすことに他ならないということで久々にブログに記します。誰かのお役に立てれば嬉しいかなと思いながら、大反省をしていきます。'
Published: true
---

atmaCup#10に参加しました。しっかりとコンペにフルコミットしたのは今回が初めてなので、ほぼ初参加と言っていいでしょう。しかし、結果はPublic: 137位でPrivate: 130位(+7)というクソ雑魚結果に...。

これは大反省会をして次に生かすことに他ならないということで久々にブログに記します。誰かのお役に立てれば嬉しいかなと思いながら、大反省をしていきます。

## とりあえず結果から

|  | RANKING | RMSLE SCORE |
| :--- | :--- | :--- |
| Public | 137 | 1.0213 |
| Private | 130(+7) | 1.0354(-0.0141) |

詳細な結果はご覧の通りです。

めっちゃクソ雑魚すぎて...。反省点は永遠に出てきそうですが、

- どこで負けたのか。敗因はなんなのか？
- 参考になったディスカッション
- これから対策すること

この辺に沿って大反省をしていこうと思います。


## MyModel

### モデル

反省するために、自分のモデルと特徴量を整理していきます。

まず、僕の作成したモデルが以下になっています。

- Model: LightGBM (10 FoldのAverage)
- KFold: Stratified 10-Fold
- parameters:
    - 'boosting_type': 'gbdt',
    - 'feature_pre_filter': False,
    - 'lambda_l1': 0.00024503835566927994,
    - 'lambda_l2': 9.900190817327861e-07,
    - 'num_leaves': 56,
    - 'feature_fraction': 0.8999999999999999,
    - 'bagging_fraction': 1.0,
    - 'bagging_freq': 0,
    - 'min_child_samples': 20,
    - 'num_iterations': 100000,
    - 'early_stopping_round': 200,
    - 'learning_rate': 0.02,

上記パラメータはoptunaでチューニングしました。チューニングで上がったCVスコアは*0.002*くらいでしたね(笑)

ほとんど寄与していないですが、気持ちチューニングしたって感じです。

### 特徴量

使用した特徴量をまとめます。  
一応効いた順に並べていきます。

| 特徴量 | 寄与度 | 労力 |
| ---- | ---- | ---- |
| collection, techniques, material<br>のWord2Vec => PCA2次元 | **絶大** | [アライさんのディスカッション](https://www.guruguru.science/competitions/16/discussions/2fafef06-5a26-4d33-b535-a94cc9549ac4/)により小 |
| principal_makerのカテゴリ | **絶大** | astype('category)なので小 |
| subtitle => W,H,T,D | **絶大** | 中 |
| subtitle => WxH | 大 | 中 |
| more_title, titleのTF-IDF => PCA2次元 | 大 | 大 |
| principal_makerの出現回数 | 大 | 小 |
| datingのUNIX時間 / 1E6 | 大 | 中 |
| aquisition_dating - year_late | 大 | 中 |
| dating_timeのカテゴリ変数化| 大 | 小 |
| その他諸のカテゴリ変数 | 皆無 | 大 |
| paletteの平均,分散,Top色 | ほぼなし | **絶大** |

**テキスト系**の特徴量がとても効いていたという印象があります。カラー系はそもそも絵画ということから、テーブルデータであることから離れて考えて、色々仮説は立てましたが、ほぼほぼ意味なかったというね。。。(笑)

色系統で立てた仮説は、こんな感じでした。

- 色の統一感があった方が印象が一定? (分散を見ればわかるのでは)
- 割合上位色の平均とか分散に依存するのでは?
- 逆に割合下位色は差し色として効果があるのでは?

どれも工夫して結構特徴量に入れたのですが、ほとんどが効いていなくて半ば泣きそうでした(笑)

後半にディスカッションからピックアップしてきたテキスト系がうまいこと効いてくれて、最後の最後にスコアがなんと**0.02**も飛躍するということに...。

「おい、なんでお前はテキスト系にdeadline前日に目をつけてるんだよ」とかいうお気持ちになりましたが(笑)

ま、それはそれで良い経験でした。


## 敗因と今後の展望

悲惨な結果になりましたので、ここでしっかり敗因を考えていこうと思います。

とにかく敗因は多いと思うので、列挙していこうと思います。この辺は同じような結果の人なら同じこと考えているんじゃないかな。。。

- 自分なりのパイプラインがない(Kaggle routine的な)
- 実験管理が甘々(ファイル管理雑 => 前やったこととCV,LBがわからん)
- 関数とかクラスを用意しないから再利用生にかける
- EDAが雑雑雑雑......
- 仮説と実験、立証の思考が浅い(仮説が正しくない時の次がない)
- **テキスト特徴量**の効果に気づいたのが前日の金曜日()
- ディスカッションをみた後実装すぐしない
- 単純に経験と学習量が足りない

無限に出てきそうですが、とりあえず主要な原因は上記にあると思います。

最後の単純に経験と学習量に関しては気持ち程度の言い訳で、自分よりも経験が浅いだろう人は上位にたくさんいるので、やり方が悪いとしか思えません。というわけで、最も敗因になったであろうことを深ぼってみようと思います。

### EDAが雑

EDAって一番地味だけど、仮説立てたり、相関をみつたりと各情報の作用を考える最も重要な時間になります。

今回はEDAが大事ということを肝に銘じた上でEDAを行ったつもりでしたが、それも「つもり」で終わってしまったような気がします。

色々変換したりグラフ化したりしてみましたが、今回はリレーショナルな情報が多かったです。例えば、principal_makerとかmaterialとか。メインのデータにあった特徴量や数値、時間と言った数値の連続値に変換しやすいデータに関しては結構データを読み込んだ感じでした。

しかし、テキストなどスパースで離散的なデータに関しては実験ベースでしっかり分析できていなかったです。特に、それを感じたのがこれもまた*アライさんのディスカッション*でした。[タイトルの言語判定特徴](https://www.guruguru.science/competitions/16/discussions/f463dac2-4233-42d2-8629-ca99a9689987/)ってやつですね。こんな情報まで気づくというのは、しっかり時間かけてEDAしているんだろうなぁ。自分は浅はかな分析しかできていないじゃないか。と思ったわけです。

YouTube講座第二回の時にも、RainCloudとかいうのもありましたし、もっと詳しく直感的なEDAをしていかないといけません。今回それができなかったのが大きな敗因でした。

### パイプライン的なのがない

パイプライン的な物を持っていないというのが敗因というよりは、ライブラリを知らないという方がこの反省には近いかもしれません。

パイプラインはこれから作ろうと思いますし、今回のディスカッションの中でも今後パイプラインとなりうるのが沢山見つかっているので、これからそれらを自分の懐に隠していこうと思います(笑)

ライブラリの使い方、なければ自分なりのモジュールを作る、それらを一連の流れとして蓄える。

このフローを身につければ、労力がだんだん少なくなっていき、より深い思考フェーズに時間を割けるのだろうなと感じました。

### 実験管理が甘々

僕はとりわけ記憶力にかけているのにもかかわらず、特にメモもせずにおおよそ一つのnotebookで管理していました。

そりゃぁごっちゃになるに決まってるよ...。

管理の仕方は人それぞれだと思いますし、やりながら身につけていかなければならないでしょう。しかし、意識してやらないとベストプラクティスは見つからないわけで。。。

参考になるディスカッションがあったので、[こちら](https://www.guruguru.science/competitions/16/discussions/cc793380-410d-413e-bac4-f46d4aa836fd/)を参考に自分なりの手法を探るのが近道な気がします。

ちなみに、昨日atmaCup#10が終わり、新しくコンペに参戦していますが、  
tokaiさんの「自分も1実験1ノートブックで、それぞれの実験に番号をつけてます。また特徴量にも番号をつけています。Google スプレッドシートでスコア管理していて、その際に、①model、②使用した特徴量（番号）③スコアを入力しています。」というコメントを参考にしています。

やりながら探っていこうと思います。

### **テキスト特徴量**の効果に気づいたのが前日の金曜日

これはいうまでもなくディスカッションをしっかりやらなかった自分が悪いです。

閉会式でもおっしゃられていましたが、**とにかくディスカッションは参考にやってみる**というのは確かにそうだなと思いました。

自分の仮説に拘るよりも、他の人が見つけた良い特徴量を試してみて、その後自分のやるもいいし、ディスカッションの中身を魔改造するもいいし、  
まずはディスカッションをやってみるのはベターな考え方だなと感心しました。

次からそうしよっと。


## これから意識することとは

ここまで大反省会をしてきて(記事を書きながら自分の中のモヤモヤを精査する中で)、自分に足りない物が多すぎるということに直面しました。

ただ、それでもやるべきことは決まってきたので、良い経験になったと思います。自分の課題は自分だけのものではないと思いますので、意識することをまた列挙していきます(ただ面倒臭くなっただけ)(笑)

- EDAはとにかく丁寧に。モデリングなんて二の次でいいくらい
- 実験管理をしよう!!! (とりあえずGoogle SpreadSheet試す)
- ディスカッションの内容はなるだけ拾い上げる!
- ベストプラクティスを見つけたら、すぐパイプライン化する

当面コンペに対して、経験を身に付けるまでは上記の内容を自然とできるように意識的に取り組んでいきます。

そして、これから意識することは多分この記事をみてくださった方にも共通することもあると思いますので、皆さんの反省会にも影響を与えられたらという淡い期待を持ちながら反省会を締めたいと思います。

とても楽しく学びになるコンペを設計してくださったことに感謝しつつ、次のatmaCupもすごく期待しております。

atmaCupの開催ありがとうございました、そして参加者のみなさまお疲れ様でした!!!!!**((感謝 + 労り) * inf)**
